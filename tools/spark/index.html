<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Project Nessie: A Git-like Experience for your Data Lake"><link rel="shortcut icon" href=../../images/fav2.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-6.0.1"><title>Spark - Project Nessie: A Git-like Experience for your Data Lake</title><link rel=stylesheet href=../../assets/stylesheets/main.38780c08.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.3f72e892.min.css><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-177850801-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview",document.location.pathname)})</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=none data-md-color-accent=none> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#spark class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid" aria-label=Header> <a href=../.. title="Project Nessie: A Git-like Experience for your Data Lake" class="md-header-nav__button md-logo" aria-label="Project Nessie: A Git-like Experience for your Data Lake"> <img src=../../img/small.svg alt=logo> </a> <label class="md-header-nav__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header-nav__title data-md-component=header-title> <div class=md-header-nav__ellipsis> <span class="md-header-nav__topic md-ellipsis"> Project Nessie: A Git-like Experience for your Data Lake </span> <span class="md-header-nav__topic md-ellipsis"> Spark </span> </div> </div> <label class="md-header-nav__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear data-md-component=search-reset tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header-nav__source> <a href=https://github.com/projectnessie/nessie title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class="md-tabs md-tabs--active" aria-label=Tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../features/ class=md-tabs__link> Features </a> </li> <li class=md-tabs__item> <a href=../../tables/ class=md-tabs__link> Table & Views </a> </li> <li class=md-tabs__item> <a href=../ class="md-tabs__link md-tabs__link--active"> Tools & Integrations </a> </li> <li class=md-tabs__item> <a href=../../develop/ class=md-tabs__link> Develop </a> </li> <li class=md-tabs__item> <a href=../../try/ class=md-tabs__link> Try Now </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Project Nessie: A Git-like Experience for your Data Lake" class="md-nav__button md-logo" aria-label="Project Nessie: A Git-like Experience for your Data Lake"> <img src=../../img/small.svg alt=logo> </a> Project Nessie: A Git-like Experience for your Data Lake </label> <div class=md-nav__source> <a href=https://github.com/projectnessie/nessie title="Go to repository" class=md-source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg> </div> <div class=md-source__repository> GitHub </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. title=Home class=md-nav__link> Home </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-2 type=checkbox id=nav-2> <label class=md-nav__link for=nav-2> Features <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Features data-md-level=1> <label class=md-nav__title for=nav-2> <span class="md-nav__icon md-icon"></span> Features </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../features/ title=Introduction class=md-nav__link> Introduction </a> </li> <li class=md-nav__item> <a href=../../features/transactions/ title=Transactions class=md-nav__link> Transactions </a> </li> <li class=md-nav__item> <a href=../../features/management/ title="Management Services" class=md-nav__link> Management Services </a> </li> <li class=md-nav__item> <a href=../../features/security/ title=Security class=md-nav__link> Security </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-3 type=checkbox id=nav-3> <label class=md-nav__link for=nav-3> Table & Views <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Table & Views" data-md-level=1> <label class=md-nav__title for=nav-3> <span class="md-nav__icon md-icon"></span> Table & Views </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../tables/ title=Overview class=md-nav__link> Overview </a> </li> <li class=md-nav__item> <a href=../../tables/iceberg/ title="Apache Iceberg" class=md-nav__link> Apache Iceberg </a> </li> <li class=md-nav__item> <a href=../../tables/deltalake/ title="Delta Lake" class=md-nav__link> Delta Lake </a> </li> <li class=md-nav__item> <a href=../../tables/hive/ title="Hive Tables" class=md-nav__link> Hive Tables </a> </li> <li class=md-nav__item> <a href=../../tables/views/ title="SQL Views" class=md-nav__link> SQL Views </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-4 type=checkbox id=nav-4 checked> <label class=md-nav__link for=nav-4> Tools & Integrations <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Tools & Integrations" data-md-level=1> <label class=md-nav__title for=nav-4> <span class="md-nav__icon md-icon"></span> Tools & Integrations </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ title=Overview class=md-nav__link> Overview </a> </li> <li class=md-nav__item> <a href=../cli/ title="Nessie CLI" class=md-nav__link> Nessie CLI </a> </li> <li class=md-nav__item> <a href=../hive/ title=Hive class=md-nav__link> Hive </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Spark <span class="md-nav__icon md-icon"></span> </label> <a href=./ title=Spark class="md-nav__link md-nav__link--active"> Spark </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#iceberg-client class=md-nav__link> Iceberg client </a> <nav class=md-nav aria-label="Iceberg client"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#writing class=md-nav__link> Writing </a> <nav class=md-nav aria-label=Writing> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark2 class=md-nav__link> Spark2 </a> </li> <li class=md-nav__item> <a href=#spark3 class=md-nav__link> Spark3 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#reading class=md-nav__link> Reading </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#delta-lake class=md-nav__link> Delta Lake </a> <nav class=md-nav aria-label="Delta Lake"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#writing_1 class=md-nav__link> Writing </a> <nav class=md-nav aria-label=Writing> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark2_1 class=md-nav__link> Spark2 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#reading_1 class=md-nav__link> Reading </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-5 type=checkbox id=nav-5> <label class=md-nav__link for=nav-5> Develop <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Develop data-md-level=1> <label class=md-nav__title for=nav-5> <span class="md-nav__icon md-icon"></span> Develop </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../develop/ title=Community class=md-nav__link> Community </a> </li> <li class=md-nav__item> <a href=../../develop/architecture/ title=Architecture class=md-nav__link> Architecture </a> </li> <li class=md-nav__item> <a href=../../develop/kernel/ title="Commit Kernel" class=md-nav__link> Commit Kernel </a> </li> <li class=md-nav__item> <a href=../../develop/nessie_vs_git/ title="Nessie vs Git" class=md-nav__link> Nessie vs Git </a> </li> <li class=md-nav__item> <a href=../../develop/rest/ title="Rest API" class=md-nav__link> Rest API </a> </li> <li class=md-nav__item> <a href=../../develop/python/ title=Python class=md-nav__link> Python </a> </li> <li class=md-nav__item> <a href=../../develop/java/ title=Java class=md-nav__link> Java </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=nav-6 type=checkbox id=nav-6> <label class=md-nav__link for=nav-6> Try Now <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Try Now" data-md-level=1> <label class=md-nav__title for=nav-6> <span class="md-nav__icon md-icon"></span> Try Now </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../try/ title="Getting Started" class=md-nav__link> Getting Started </a> </li> <li class=md-nav__item> <a href=../../try/configuration/ title=Configuration class=md-nav__link> Configuration </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#iceberg-client class=md-nav__link> Iceberg client </a> <nav class=md-nav aria-label="Iceberg client"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#writing class=md-nav__link> Writing </a> <nav class=md-nav aria-label=Writing> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark2 class=md-nav__link> Spark2 </a> </li> <li class=md-nav__item> <a href=#spark3 class=md-nav__link> Spark3 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#reading class=md-nav__link> Reading </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#delta-lake class=md-nav__link> Delta Lake </a> <nav class=md-nav aria-label="Delta Lake"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#writing_1 class=md-nav__link> Writing </a> <nav class=md-nav aria-label=Writing> <ul class=md-nav__list> <li class=md-nav__item> <a href=#spark2_1 class=md-nav__link> Spark2 </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#reading_1 class=md-nav__link> Reading </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <h1 id=spark>Spark<a class=headerlink href=#spark title="Permanent link">&para;</a></h1> <p>Nessie can be used with Spark in several different ways. These include:</p> <h2 id=iceberg-client>Iceberg client<a class=headerlink href=#iceberg-client title="Permanent link">&para;</a></h2> <p>Nessie works seamlessly with Iceberg in Spark2 and Spark3. Nessie is implemented as a custom iceberg <a href=http://iceberg.apache.org/custom-catalog/ >catalog</a> and therefore supports all features available to any Iceberg client. This includes Spark structured streaming, Presto and Flink. See the <a href=https://iceberg.apache.org>iceberg docs</a> for more info. We update soon with instructions to use these technologies with Nessie.</p> <div class="admonition note"> <p class=admonition-title>Note</p> </div> <p>You can follow along interactively in a Jupyter notebook by following the instructions <a href=https://github.com/projectnessie/nessie/python/demo>here</a>.</p> <p>To access Nessie from a spark cluster make sure the <code>spark.jars</code> spark option is set to include the <a href=https://repo.maven.apache.org/maven2/org/projectnessie/nessie-iceberg-spark2/0.1.0/nessie-iceberg-spark2-0.1.0.jar>Spark 2</a> or <a href=https://repo.maven.apache.org/maven2/org/projectnessie/nessie-iceberg-spark3/0.1.0/nessie-iceberg-spark3-0.1.0.jar>Spark 3</a> Nessie plugin jar. This fat jar has all the required Nessie <strong>and</strong> Apache Iceberg in it. </p> <div class="admonition note"> <p class=admonition-title>Note</p> <p>The Nessie team is working to incorporate Nessie support directly into the Iceberg project moving forward.</p> </div> <p>In pyspark this would look like</p> <div class=highlight><pre><span></span><code><span class=n>SparkSession</span><span class=o>.</span><span class=n>builder</span>
            <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s1>&#39;spark.jars&#39;</span><span class=p>,</span> <span class=s1>&#39;path/to/nessie-iceberg-spark3-0.1.0.jar&#39;</span><span class=p>)</span>
            <span class=o>...</span> <span class=n>rest</span> <span class=n>of</span> <span class=n>spark</span> <span class=n>config</span>
            <span class=o>.</span><span class=n>getOrCreate</span><span class=p>()</span>
</code></pre></div> <p>The docs for the <a href=https://iceberg.apache.org/java-api-quickstart>Java api</a> in Iceberg explain how to use a <code>Catalog</code>. The only change is that a Nessie catalog should be instantiated</p> <div class=tabbed-set data-tabs=1:2><input checked=checked id=__tabbed_1_1 name=__tabbed_1 type=radio><label for=__tabbed_1_1>Java</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>Catalog</span> <span class=n>catalog</span> <span class=o>=</span> <span class=k>new</span> <span class=n>NessieCatalog</span><span class=p>(</span><span class=n>spark</span><span class=p>.</span><span class=na>sparkContext</span><span class=p>().</span><span class=na>hadoopConfiguration</span><span class=p>())</span>
</code></pre></div> </div> <input id=__tabbed_1_2 name=__tabbed_1 type=radio><label for=__tabbed_1_2>Python</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>catalog</span> <span class=o>=</span> <span class=n>jvm</span><span class=o>.</span><span class=n>NessieCatalog</span><span class=p>(</span><span class=n>sc</span><span class=o>.</span><span class=n>_jsc</span><span class=o>.</span><span class=n>hadoopConfiguration</span><span class=p>())</span>
</code></pre></div> </div> </div> <div class="admonition note"> <p class=admonition-title>Note</p> <p>Iceberg&rsquo;s python libraries are still under active development. Actions against catalogs in pyspark still have to go through the jvm objects. See the <a href=https://github.com/projectnessie/nessie/python/demo>demo</a> directory for details.</p> </div> <p>The Nessie Catalog needs the following parameters set in the Spark/Hadoop config.</p> <div class=highlight><pre><span></span><code>nessie.url = full url to nessie
nessie.username = username if using basic auth, omitted otherwise
nessie.password = password if using basic auth, omitted otherwise
nessie.auth.type = authentication type (BASIC, NONE or AWS)
</code></pre></div> <p>These are set as follows in code (or through other methods as described <a href=https://spark.apache.org/docs/latest/configuration.html>here</a>)</p> <div class=tabbed-set data-tabs=2:2><input checked=checked id=__tabbed_2_1 name=__tabbed_2 type=radio><label for=__tabbed_2_1>Java</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=c1>//for a local spark instance</span>
<span class=n>conf</span><span class=p>.</span><span class=na>set</span><span class=p>(</span><span class=s>&quot;spark.hadoop.nessie.url&quot;</span><span class=p>,</span> <span class=n>url</span><span class=p>)</span>
    <span class=p>.</span><span class=na>set</span><span class=p>(</span><span class=s>&quot;spark.hadoop.nessie.ref&quot;</span><span class=p>,</span> <span class=n>branch</span><span class=p>)</span>
    <span class=p>.</span><span class=na>set</span><span class=p>(</span><span class=s>&quot;spark.hadoop.nessie.auth_type&quot;</span><span class=p>,</span> <span class=n>authType</span><span class=p>);</span>
<span class=n>spark</span> <span class=o>=</span> <span class=n>SparkSession</span><span class=p>.</span><span class=na>builder</span><span class=p>()</span>
                    <span class=p>.</span><span class=na>master</span><span class=p>(</span><span class=s>&quot;local[2]&quot;</span><span class=p>)</span>
                    <span class=p>.</span><span class=na>config</span><span class=p>(</span><span class=n>conf</span><span class=p>)</span>
                    <span class=p>.</span><span class=na>getOrCreate</span><span class=p>();</span>
</code></pre></div> </div> <input id=__tabbed_2_2 name=__tabbed_2 type=radio><label for=__tabbed_2_2>Python</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=c1># here we are assuming NONE authorisation</span>
<span class=n>spark</span> <span class=o>=</span> <span class=n>SparkSession</span><span class=o>.</span><span class=n>builder</span> \
        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&quot;spark.jars&quot;</span><span class=p>,</span> <span class=s2>&quot;../../clients/iceberg-spark3/target/nessie-iceberg-spark3-0.1.0.jar&quot;</span><span class=p>)</span> \
        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&quot;spark.hadoop.nessie.url&quot;</span><span class=p>,</span> <span class=s2>&quot;http://localhost:19120/api/v1&quot;</span><span class=p>)</span> \
        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&quot;spark.hadoop.nessie.ref&quot;</span><span class=p>,</span> <span class=s2>&quot;main&quot;</span><span class=p>)</span> \
        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&quot;spark.sql.catalog.nessie&quot;</span><span class=p>,</span> <span class=s2>&quot;com.dremio.nessie.iceberg.spark.NessieIcebergSparkCatalog&quot;</span><span class=p>)</span> \
        <span class=o>.</span><span class=n>getOrCreate</span><span class=p>()</span>
</code></pre></div> </div> </div> <p>Note above we specified the option <code>spark.hadoop.nessie.ref</code>. This value sets the default branch that the iceberg catalog will use. This can be changed by changing the <code>hadoopConfiguration</code> however best practice would be to use a single write context (branch) for the duration of the spark session. Read context can be changed dynamically as shown below.</p> <p>We have also specified <code>spark.sql.catalog.nessie</code> to point to our <code>NessieIcebergSparkCatalog</code>. This is a Spark3 only option to set the catalog <code>nessie</code> to be managed by Nessie&rsquo;s Catalog implementation.</p> <h3 id=writing>Writing<a class=headerlink href=#writing title="Permanent link">&para;</a></h3> <p>Spark support is constantly evolving and the differences in Spark3 vs Spark2.4 are considerable. See the <a href=https://iceberg.apache.org/spark/#spark>iceberg</a> docs for an up to date support table.</p> <h4 id=spark2>Spark2<a class=headerlink href=#spark2 title="Permanent link">&para;</a></h4> <p>Spark2.4 supports reads, appends, overwrites in Iceberg. Nessie tables in iceberg can be written via the Nessie Iceberg Catalog instantiated above. Iceberg in Spark2.4 has no ability to create tables so before a table can be appended to or overwritten the table must be first created via an Iceberg Catalog. This is straightforward in Java but requires addressing jvm objects directly in Python (until the python library for iceberg is released).</p> <div class=tabbed-set data-tabs=3:2><input checked=checked id=__tabbed_3_1 name=__tabbed_3 type=radio><label for=__tabbed_3_1>Java</label><div class=tabbed-content> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=c1>// first instantiate the catalog</span>
<span class=n>NessieCatalog</span> <span class=n>catalog</span> <span class=o>=</span> <span class=k>new</span> <span class=n>NessieCatalog</span><span class=p>(</span><span class=n>sc</span><span class=p>.</span><span class=na>hadoopConfiguration</span><span class=p>())</span>

<span class=c1>// Creating table by first creating a table name with namespace</span>
<span class=n>TableIdentifier</span> <span class=n>region_name</span> <span class=o>=</span> <span class=n>TableIdentifier</span><span class=p>.</span><span class=na>parse</span><span class=p>(</span><span class=s>&quot;testing.region&quot;</span><span class=p>)</span>

<span class=c1>// next create the schema</span>
<span class=n>Schema</span> <span class=n>region_schema</span> <span class=o>=</span> <span class=n>Schema</span><span class=p>(</span><span class=o>[</span>
  <span class=n>Types</span><span class=p>.</span><span class=na>NestedField</span><span class=p>.</span><span class=na>optional</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=s>&quot;R_REGIONKEY&quot;</span><span class=p>,</span> <span class=n>Types</span><span class=p>.</span><span class=na>LongType</span><span class=p>.</span><span class=na>get</span><span class=p>()),</span>
  <span class=n>Types</span><span class=p>.</span><span class=na>NestedField</span><span class=p>.</span><span class=na>optional</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=s>&quot;R_NAME&quot;</span><span class=p>,</span> <span class=n>Types</span><span class=p>.</span><span class=na>StringType</span><span class=p>.</span><span class=na>get</span><span class=p>()),</span>
  <span class=n>Types</span><span class=p>.</span><span class=na>NestedField</span><span class=p>.</span><span class=na>optional</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=s>&quot;R_COMMENT&quot;</span><span class=p>,</span> <span class=n>Types</span><span class=p>.</span><span class=na>StringType</span><span class=p>.</span><span class=na>get</span><span class=p>()),</span>
<span class=o>]</span><span class=p>)</span>

<span class=c1>// and the partition</span>
<span class=n>PartitionSpec</span> <span class=n>region_spec</span> <span class=o>=</span> <span class=n>PartitionSpec</span><span class=p>.</span><span class=na>unpartitioned</span><span class=p>()</span>

<span class=c1>// finally create the table</span>
<span class=n>catalog</span><span class=p>.</span><span class=na>createTable</span><span class=p>(</span><span class=n>region_name</span><span class=p>,</span> <span class=n>region_schema</span><span class=p>,</span> <span class=n>region_spec</span><span class=p>)</span>
</code></pre></div> </td></tr></table> </div> <input id=__tabbed_3_2 name=__tabbed_3 type=radio><label for=__tabbed_3_2>Python</label><div class=tabbed-content> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=n>sc</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>sparkContext</span>
<span class=n>jvm</span> <span class=o>=</span> <span class=n>sc</span><span class=o>.</span><span class=n>_gateway</span><span class=o>.</span><span class=n>jvm</span>

<span class=c1># import jvm libraries for iceberg catalogs and schemas</span>
<span class=n>java_import</span><span class=p>(</span><span class=n>jvm</span><span class=p>,</span> <span class=s2>&quot;com.dremio.nessie.iceberg.NessieCatalog&quot;</span><span class=p>)</span>
<span class=n>java_import</span><span class=p>(</span><span class=n>jvm</span><span class=p>,</span> <span class=s2>&quot;org.apache.iceberg.catalog.TableIdentifier&quot;</span><span class=p>)</span>
<span class=n>java_import</span><span class=p>(</span><span class=n>jvm</span><span class=p>,</span> <span class=s2>&quot;org.apache.iceberg.Schema&quot;</span><span class=p>)</span>
<span class=n>java_import</span><span class=p>(</span><span class=n>jvm</span><span class=p>,</span> <span class=s2>&quot;org.apache.iceberg.types.Types&quot;</span><span class=p>)</span>
<span class=n>java_import</span><span class=p>(</span><span class=n>jvm</span><span class=p>,</span> <span class=s2>&quot;org.apache.iceberg.PartitionSpec&quot;</span><span class=p>)</span>

<span class=c1># first instantiate the catalog</span>
<span class=n>catalog</span> <span class=o>=</span> <span class=n>jvm</span><span class=o>.</span><span class=n>NessieCatalog</span><span class=p>(</span><span class=n>sc</span><span class=o>.</span><span class=n>_jsc</span><span class=o>.</span><span class=n>hadoopConfiguration</span><span class=p>())</span>

<span class=c1># Creating table by first creating a table name with namespace</span>
<span class=n>region_name</span> <span class=o>=</span> <span class=n>jvm</span><span class=o>.</span><span class=n>TableIdentifier</span><span class=o>.</span><span class=n>parse</span><span class=p>(</span><span class=s2>&quot;testing.region&quot;</span><span class=p>)</span>

<span class=c1># next create the schema</span>
<span class=n>region_schema</span> <span class=o>=</span> <span class=n>jvm</span><span class=o>.</span><span class=n>Schema</span><span class=p>([</span>
  <span class=n>jvm</span><span class=o>.</span><span class=n>Types</span><span class=o>.</span><span class=n>NestedField</span><span class=o>.</span><span class=n>optional</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=s2>&quot;R_REGIONKEY&quot;</span><span class=p>,</span> <span class=n>jvm</span><span class=o>.</span><span class=n>Types</span><span class=o>.</span><span class=n>LongType</span><span class=o>.</span><span class=n>get</span><span class=p>()),</span>
  <span class=n>jvm</span><span class=o>.</span><span class=n>Types</span><span class=o>.</span><span class=n>NestedField</span><span class=o>.</span><span class=n>optional</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=s2>&quot;R_NAME&quot;</span><span class=p>,</span> <span class=n>jvm</span><span class=o>.</span><span class=n>Types</span><span class=o>.</span><span class=n>StringType</span><span class=o>.</span><span class=n>get</span><span class=p>()),</span>
  <span class=n>jvm</span><span class=o>.</span><span class=n>Types</span><span class=o>.</span><span class=n>NestedField</span><span class=o>.</span><span class=n>optional</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=s2>&quot;R_COMMENT&quot;</span><span class=p>,</span> <span class=n>jvm</span><span class=o>.</span><span class=n>Types</span><span class=o>.</span><span class=n>StringType</span><span class=o>.</span><span class=n>get</span><span class=p>()),</span>
<span class=p>])</span>

<span class=c1># and the partition</span>
<span class=n>region_spec</span> <span class=o>=</span> <span class=n>jvm</span><span class=o>.</span><span class=n>PartitionSpec</span><span class=o>.</span><span class=n>unpartitioned</span><span class=p>()</span>

<span class=c1># finally create the table</span>
<span class=n>region_table</span> <span class=o>=</span> <span class=n>catalog</span><span class=o>.</span><span class=n>createTable</span><span class=p>(</span><span class=n>region_name</span><span class=p>,</span> <span class=n>region_schema</span><span class=p>,</span> <span class=n>region_spec</span><span class=p>)</span>
</code></pre></div> </td></tr></table> </div> </div> <p>When looking at the Python code above, lines 1-10 are importing jvm objects into pyspark. Lines 11-25 create the table name, schema and partition spec. These actions will be familiar to seasoned iceberg users and are wholly iceberg operations. Line 28 is where our initial iceberg metadata is finally written to disk and a commit takes place on Nessie.</p> <p>Now that we have created an Iceberg table in nessie we can write to it. The iceberg <code>DataSourceV2</code> allows for either <code>overwrite</code> or <code>append</code> mode in a standard <code>spark.write</code>.</p> <div class=tabbed-set data-tabs=4:2><input checked=checked id=__tabbed_4_1 name=__tabbed_4 type=radio><label for=__tabbed_4_1>Java</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>regionDf</span> <span class=o>=</span> <span class=n>spark</span><span class=p>.</span><span class=na>read</span><span class=p>().</span><span class=na>load</span><span class=p>(</span><span class=s>&quot;data/region.parquet&quot;</span><span class=p>)</span>
<span class=n>regionDf</span><span class=p>.</span><span class=na>write</span><span class=p>().</span><span class=na>format</span><span class=p>(</span><span class=s>&quot;iceberg&quot;</span><span class=p>).</span><span class=na>mode</span><span class=p>(</span><span class=s>&quot;overwrite&quot;</span><span class=p>).</span><span class=na>save</span><span class=p>(</span><span class=s>&quot;testing.region&quot;</span><span class=p>)</span>
</code></pre></div> </div> <input id=__tabbed_4_2 name=__tabbed_4 type=radio><label for=__tabbed_4_2>Python</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>region_df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;data/region.parquet&quot;</span><span class=p>)</span>
<span class=n>region_df</span><span class=o>.</span><span class=n>write</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&quot;iceberg&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>mode</span><span class=p>(</span><span class=s2>&quot;overwrite&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>&quot;testing.region&quot;</span><span class=p>)</span>
</code></pre></div> </div> </div> <p>Here we simply read a file from the default filesystem and write it to an existing nessie iceberg table. This will trigger a commit on current context&rsquo;s branch.</p> <p>For the examples above we have performed commits on the branch specified when we set our spark configuration. Had we not specified the context in our spark configuration all operations would have defaulted to the default branch defined by the server. This is a strong pattern for a spark job which is for example writing data as part of a wider ETL job. It will only ever need one context or branch to write to. If however you are running an interactive session and would like to write to a specific branch without changing context the following works as well.</p> <div class=tabbed-set data-tabs=5:2><input checked=checked id=__tabbed_5_1 name=__tabbed_5 type=radio><label for=__tabbed_5_1>Java</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>regionDf</span> <span class=o>=</span> <span class=n>spark</span><span class=p>.</span><span class=na>read</span><span class=p>().</span><span class=na>load</span><span class=p>(</span><span class=s>&quot;data/region.parquet&quot;</span><span class=p>)</span>
<span class=n>regionDf</span><span class=p>.</span><span class=na>write</span><span class=p>().</span><span class=na>format</span><span class=p>(</span><span class=s>&quot;iceberg&quot;</span><span class=p>).</span><span class=na>option</span><span class=p>(</span><span class=s>&quot;nessie.ref&quot;</span><span class=p>,</span> <span class=s>&quot;dev&quot;</span><span class=p>).</span><span class=na>mode</span><span class=p>(</span><span class=s>&quot;overwrite&quot;</span><span class=p>).</span><span class=na>save</span><span class=p>(</span><span class=s>&quot;testing.region&quot;</span><span class=p>)</span>
</code></pre></div> </div> <input id=__tabbed_5_2 name=__tabbed_5 type=radio><label for=__tabbed_5_2>Python</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>region_df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;data/region.parquet&quot;</span><span class=p>)</span>
<span class=n>region_df</span><span class=o>.</span><span class=n>write</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&quot;iceberg&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>option</span><span class=p>(</span><span class=s2>&quot;nessie.ref&quot;</span><span class=p>,</span> <span class=s2>&quot;dev&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>mode</span><span class=p>(</span><span class=s2>&quot;overwrite&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>&quot;testing.region&quot;</span><span class=p>)</span>
</code></pre></div> </div> </div> <p>Note the extra <code>option</code> clause in the write command. This will ensure the commit happens on the <code>dev</code> branch rather than the default branch.</p> <h4 id=spark3>Spark3<a class=headerlink href=#spark3 title="Permanent link">&para;</a></h4> <p>The write path for Spark3 is slightly different and easier to work with. These changes haven&rsquo;t made it to pyspark yet so writing dataframes looks much the same there, including having to create the table. Spark3 table creation/insertion is as follows:</p> <div class=tabbed-set data-tabs=6:3><input checked=checked id=__tabbed_6_1 name=__tabbed_6 type=radio><label for=__tabbed_6_1>Java</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>regionDf</span> <span class=o>=</span> <span class=n>spark</span><span class=p>.</span><span class=na>read</span><span class=p>().</span><span class=na>load</span><span class=p>(</span><span class=err>&#39;</span><span class=n>data</span><span class=o>/</span><span class=n>region</span><span class=p>.</span><span class=na>parquet</span><span class=err>&#39;</span><span class=p>)</span>
<span class=c1>//create</span>
<span class=n>regionDf</span><span class=p>.</span><span class=na>writeTo</span><span class=p>(</span><span class=s>&quot;nessie.testing.region&quot;</span><span class=p>).</span><span class=na>create</span><span class=p>()</span>
<span class=c1>//append</span>
<span class=n>regionDf</span><span class=p>.</span><span class=na>writeTo</span><span class=p>(</span><span class=s>&quot;nessie.testing.region&quot;</span><span class=p>).</span><span class=na>append</span><span class=p>()</span>
<span class=c1>//overwrite partition</span>
<span class=n>regionDf</span><span class=p>.</span><span class=na>writeTo</span><span class=p>(</span><span class=s>&quot;nessie.testing.region&quot;</span><span class=p>).</span><span class=na>overwritePartitions</span><span class=p>()</span>
</code></pre></div> </div> <input id=__tabbed_6_2 name=__tabbed_6 type=radio><label for=__tabbed_6_2>Python</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=c1># same code as the spark2 section above to create the testing.region table</span>
<span class=n>region_df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;data/region.parquet&quot;</span><span class=p>)</span>
<span class=n>region_df</span><span class=o>.</span><span class=n>write</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&quot;iceberg&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>mode</span><span class=p>(</span><span class=s2>&quot;overwrite&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>&quot;testing.region&quot;</span><span class=p>)</span>
</code></pre></div> </div> <input id=__tabbed_6_3 name=__tabbed_6 type=radio><label for=__tabbed_6_3>SQL</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=k>CREATE</span> <span class=k>TABLE</span> <span class=n>nessie</span><span class=p>.</span><span class=n>testing</span><span class=p>.</span><span class=n>city</span> <span class=p>(</span><span class=n>C_CITYKEY</span> <span class=nb>BIGINT</span><span class=p>,</span> <span class=n>C_NAME</span> <span class=n>STRING</span><span class=p>,</span> <span class=n>N_NATIONKEY</span> <span class=nb>BIGINT</span><span class=p>,</span> <span class=n>C_COMMENT</span> <span class=n>STRING</span><span class=p>)</span> <span class=k>USING</span> <span class=n>iceberg</span> <span class=n>PARTITIONED</span> <span class=k>BY</span> <span class=p>(</span><span class=n>N_NATIONKEY</span><span class=p>)</span>
<span class=c1>-- AS SELECT .. can be added to the sql statement to perform a CTAS</span>
<span class=k>INSERT</span> <span class=k>INTO</span> <span class=n>nessie</span><span class=p>.</span><span class=n>testing</span><span class=p>.</span><span class=n>city</span> <span class=k>VALUES</span> <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;a&#39;</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;comment&#39;</span><span class=p>)</span>
</code></pre></div> </div> </div> <p>The full list of operations can be found <a href=https://iceberg.apache.org/spark/#create-table>here</a>. Everything that Iceberg supports the Nessie Iceberg Catalog also supports.</p> <h3 id=reading>Reading<a class=headerlink href=#reading title="Permanent link">&para;</a></h3> <p>Reading is more straightforward between spark 2 and spark 3. We will look at both versions together in this section. To read a Nessie table in iceberg simply:</p> <div class=tabbed-set data-tabs=7:3><input checked=checked id=__tabbed_7_1 name=__tabbed_7 type=radio><label for=__tabbed_7_1>Java</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>regionDf</span> <span class=o>=</span> <span class=n>spark</span><span class=p>.</span><span class=na>read</span><span class=p>().</span><span class=na>format</span><span class=p>(</span><span class=s>&quot;iceberg&quot;</span><span class=p>).</span><span class=na>load</span><span class=p>(</span><span class=s>&quot;testing.region&quot;</span><span class=p>)</span> <span class=c1>// Spark2</span>
<span class=n>regionDf</span> <span class=o>=</span> <span class=n>spark</span><span class=p>.</span><span class=na>table</span><span class=p>(</span><span class=s>&quot;nessie.testing.region&quot;</span><span class=p>)</span> <span class=c1>// Spark3</span>
</code></pre></div> </div> <input id=__tabbed_7_2 name=__tabbed_7 type=radio><label for=__tabbed_7_2>Python</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=c1># same code as above to create the testing.region table</span>
<span class=n>region_df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&quot;iceberg&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;testing.region&quot;</span><span class=p>)</span>
</code></pre></div> </div> <input id=__tabbed_7_3 name=__tabbed_7 type=radio><label for=__tabbed_7_3>SQL</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=k>SELECT</span> <span class=o>*</span> <span class=k>FROM</span> <span class=n>nessie</span><span class=p>.</span><span class=n>testing</span><span class=p>.</span><span class=n>city</span> <span class=c1>-- Spark3 only</span>
</code></pre></div> </div> </div> <p>The examples above all use the default branch defined on initialisation. There are several ways to reference specific branches or hashes from within a read statement. We will take a look at a few now from pyspark3, the rules are the same across all environments though. The general pattern is <code>&lt;table&gt;@&lt;branch&gt;</code>. Table must be present and either branch and/or hash are optional. We will throw an error if branch or hash don&rsquo;t exist. Branch or hash references in the table name will override passed <code>option</code>s and the settings in the Spark/Hadoop configs.</p> <table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span>1
2
3
4
5
6</pre></div></td><td class=code><div class=highlight><pre><span></span><code><span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=p>()</span><span class=o>.</span><span class=n>option</span><span class=p>(</span><span class=s2>&quot;nessie.ref&quot;</span><span class=p>,</span> <span class=s2>&quot;dev&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&quot;iceberg&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;testing.region&quot;</span><span class=p>)</span> <span class=c1># read from dev branch</span>
<span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=p>()</span><span class=o>.</span><span class=n>option</span><span class=p>(</span><span class=s2>&quot;nessie.ref&quot;</span><span class=p>,</span> <span class=s2>&quot;&lt;hash&gt;&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&quot;iceberg&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;testing.region&quot;</span><span class=p>)</span> <span class=c1># read from branch at specific point in time</span>
<span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=p>()</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&quot;iceberg&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;testing.region@dev&quot;</span><span class=p>)</span> <span class=c1># read from branch dev</span>
<span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=p>()</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&quot;iceberg&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;testing.region@&lt;hash&gt;&quot;</span><span class=p>)</span> <span class=c1># read specifically from hash</span>
<span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&quot;SELECT * FROM nessie.testing.`region@dev`&quot;</span><span class=p>)</span>
<span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&quot;SELECT * FROM nessie.testing.`region@&lt;hash&gt;`&quot;</span><span class=p>)</span>
</code></pre></div> </td></tr></table> <p>Notice in the SQL statements the <code>table@branch</code> must be escaped separately from namespace or catalog arguments.</p> <p>Future versions may add the ability to specify a timestamp to query the data at a specific point in time (time-travel). In the meantime the history can be viewed on the command line or via the python client and a specific hash based on commit time can be extracted for use in the spark catalog. It is recommended to use the time-travel features of Nessie over the Iceberg features as Nessie history is consistent across the entire database.</p> <h2 id=delta-lake>Delta Lake<a class=headerlink href=#delta-lake title="Permanent link">&para;</a></h2> <div class="admonition note"> <p class=admonition-title>Note</p> </div> <p>You can follow along interactively in a Jupyter notebook by following the instructions <a href=https://github.com/projectnessie/nessie/python/demo>here</a>.</p> <p>Delta Lake support in Nessie requires some minor modifications to the core Delta libraries. This patch is still ongoing, in the meantime Nessie will not work on Databricks and must be used with the open source Delta. Nessie is able to interact with Delta Lake by implementing a custom version of Delta&rsquo;s LogStore <a href=https://github.com/delta-io/delta/blob/master/src/main/scala/org/apache/spark/sql/delta/storage/LogStore.scala>interface</a>. This ensures that all filesystem changes are recorded by Nessie as commits. The benefit of this approach is the core ACID primitives are handled by Nessie. The limitations around <a href=https://docs.delta.io/latest/delta-storage.html>concurrency</a> that Delta would normally have are removed, any number of readers and writers can simultaneously interact with a Nessie managed Delta Lake table.</p> <p>To access Nessie from a spark cluster make sure the <code>spark.jars</code> spark option is set to include the <a href=https://repo.maven.apache.org/maven2/org/projectnessie/nessie-deltalake-spark2/0.1.0/nessie-deltalake-spark2-0.1.0.jar>Spark 2</a> or <a href=https://repo.maven.apache.org/maven2/org/projectnessie/nessie-deltalake-spark3/0.1.0/nessie-deltalake-spark3-0.1.0.jar>Spark 3</a> jar. This jar has all the required Nessie <strong>and</strong> Delta Lake libraries in it. </p> <div class="admonition note"> <p class=admonition-title>Note</p> <p>the <code>spark3</code> jar is for Delta versions &gt;7.0 on Spark3 and the <code>spark2</code> jar is for Delta versions 6.x on Spark2.4</p> </div> <p>In pyspark this would look like</p> <div class=highlight><pre><span></span><code><span class=n>SparkSession</span><span class=o>.</span><span class=n>builder</span>
            <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s1>&#39;spark.jars&#39;</span><span class=p>,</span> <span class=s1>&#39;path/to/nessie-deltalake-spark2-0.1.0.jar&#39;</span><span class=p>)</span>
            <span class=o>...</span> <span class=n>rest</span> <span class=n>of</span> <span class=n>spark</span> <span class=n>config</span>
            <span class=o>.</span><span class=n>getOrCreate</span><span class=p>()</span>
</code></pre></div> <p>The Nessie LogStore needs the following parameters set in the Spark/Hadoop config.</p> <div class=highlight><pre><span></span><code>nessie.url = full url to nessie
nessie.username = username if using basic auth, omitted otherwise
nessie.password = password if using basic auth, omitted otherwise
nessie.auth.type = authentication type (BASIC, NONE or AWS)
spark.delta.logFileHandler.class=com.dremio.nessie.deltalake.NessieLogFileMetaParser
spark.delta.logStore.class=com.dremio.nessie.deltalake.NessieLogStore
</code></pre></div> <p>These are set as follows in code (or through other methods as described <a href=https://spark.apache.org/docs/latest/configuration.html>here</a>)</p> <div class=tabbed-set data-tabs=8:1><input checked=checked id=__tabbed_8_1 name=__tabbed_8 type=radio><label for=__tabbed_8_1>Python</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=c1># here we are assuming NONE authorisation</span>
<span class=n>spark</span> <span class=o>=</span> <span class=n>SparkSession</span><span class=o>.</span><span class=n>builder</span> \
        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&quot;spark.jars&quot;</span><span class=p>,</span> <span class=s2>&quot;../../clients/iceberg-spark3/target/nessie-iceberg-spark3-0.1.0.jar&quot;</span><span class=p>)</span> \
        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&quot;spark.hadoop.nessie.url&quot;</span><span class=p>,</span> <span class=s2>&quot;http://localhost:19120/api/v1&quot;</span><span class=p>)</span> \
        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&quot;spark.hadoop.nessie.ref&quot;</span><span class=p>,</span> <span class=s2>&quot;main&quot;</span><span class=p>)</span> \
        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&quot;spark.sql.catalog.spark_catalog&quot;</span><span class=p>,</span> <span class=s2>&quot;org.apache.spark.sql.delta.catalog.DeltaCatalog&quot;</span><span class=p>)</span> \
        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&quot;spark.sql.extensions&quot;</span><span class=p>,</span> <span class=s2>&quot;io.delta.sql.DeltaSparkSessionExtension&quot;</span><span class=p>)</span> \
        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&quot;spark.delta.logFileHandler.class&quot;</span><span class=p>,</span> <span class=s2>&quot;com.dremio.nessie.deltalake.NessieLogFileMetaParser&quot;</span><span class=p>)</span> \
        <span class=o>.</span><span class=n>config</span><span class=p>(</span><span class=s2>&quot;spark.delta.logStore.class&quot;</span><span class=p>,</span> <span class=s2>&quot;com.dremio.nessie.deltalake.NessieLogStore&quot;</span><span class=p>)</span> \
        <span class=o>.</span><span class=n>getOrCreate</span><span class=p>()</span>
</code></pre></div> </div> </div> <p>Note above we specified the option <code>spark.hadoop.nessie.ref</code>. This value sets the default branch that the iceberg catalog will use. This can be changed by changing the <code>hadoopConfiguration</code> however best practice would be to use a single write context (branch) for the duration of the spark session. </p> <p>The key to enabling Nessie is to instruct Delta to use the Nessie specific <code>LogStore</code> and <code>LogFileHandler</code>. With these enabled the Delta core library will delegate transaction handling to Nessie.</p> <p>Finally, note we have explicitly enabled Delta&rsquo;s SQL extensions which enable Delta specific SQL in Spark3.</p> <div class="admonition warning"> <p class=admonition-title>Warning</p> <p>Currently Delta metadata operations like <code>VACUUM</code> are descructive to Nessie managed Delta tables. <strong>Do not</strong> run these operations. Future versions of Nessie will disable these commands when Nessie is activated.</p> </div> <h3 id=writing_1>Writing<a class=headerlink href=#writing_1 title="Permanent link">&para;</a></h3> <p>Spark support is constantly evolving and the differences in Spark3 vs Spark2.4 is considerable. See the <a href=https://docs.delta.io/https://docs.delta.io/latest/delta-batch.html>delta</a> docs for an up to date support table.</p> <h4 id=spark2_1>Spark2<a class=headerlink href=#spark2_1 title="Permanent link">&para;</a></h4> <p>Spark2.4 supports reads, appends, overwrites in Delta via data frames. Spark 3 additionally supports SQL syntax. Nessie tables in delta can be written via the Nessi enabled Delta client. The Delta writer allows for either <code>overwrite</code> or <code>append</code> mode in a standard <code>spark.write</code>.</p> <div class=tabbed-set data-tabs=9:2><input checked=checked id=__tabbed_9_1 name=__tabbed_9 type=radio><label for=__tabbed_9_1>Java</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>regionDf</span> <span class=o>=</span> <span class=n>spark</span><span class=p>.</span><span class=na>read</span><span class=p>().</span><span class=na>load</span><span class=p>(</span><span class=s>&quot;data/region.parquet&quot;</span><span class=p>)</span>
<span class=n>regionDf</span><span class=p>.</span><span class=na>write</span><span class=p>().</span><span class=na>format</span><span class=p>(</span><span class=s>&quot;delta&quot;</span><span class=p>).</span><span class=na>mode</span><span class=p>(</span><span class=s>&quot;overwrite&quot;</span><span class=p>).</span><span class=na>save</span><span class=p>(</span><span class=s>&quot;/location/to/delta/testing/region&quot;</span><span class=p>)</span>
</code></pre></div> </div> <input id=__tabbed_9_2 name=__tabbed_9 type=radio><label for=__tabbed_9_2>Python</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>region_df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;data/region.parquet&quot;</span><span class=p>)</span>
<span class=n>region_df</span><span class=o>.</span><span class=n>write</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&quot;delta&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>mode</span><span class=p>(</span><span class=s2>&quot;overwrite&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>&quot;/location/to/delta/testing/region&quot;</span><span class=p>)</span>
</code></pre></div> </div> </div> <p>=== &ldquo;SQL&rdquo; <div class=highlight><pre><span></span><code><span class=k>CREATE</span> <span class=k>TABLE</span> <span class=n>nessie</span><span class=p>.</span><span class=n>testing</span><span class=p>.</span><span class=n>city</span> <span class=p>(</span><span class=n>C_CITYKEY</span> <span class=nb>BIGINT</span><span class=p>,</span> <span class=n>C_NAME</span> <span class=n>STRING</span><span class=p>,</span> <span class=n>N_NATIONKEY</span> <span class=nb>BIGINT</span><span class=p>,</span> <span class=n>C_COMMENT</span> <span class=n>STRING</span><span class=p>)</span> <span class=k>USING</span> <span class=n>delta</span> <span class=n>PARTITIONED</span> <span class=k>BY</span> <span class=p>(</span><span class=n>N_NATIONKEY</span><span class=p>)</span> <span class=k>LOCATION</span> <span class=s1>&#39;path/to/delta/testing/city&#39;</span>
<span class=c1>-- SELECT .. can be added to the sql statement to perform a CTAS</span>
<span class=k>INSERT</span> <span class=p>[</span><span class=n>OVERWRITE</span><span class=p>]</span> <span class=k>INTO</span> <span class=n>nessie</span><span class=p>.</span><span class=n>testing</span><span class=p>.</span><span class=n>city</span> <span class=k>VALUES</span> <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;a&#39;</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;comment&#39;</span><span class=p>)</span>
</code></pre></div></p> <p>Here we simply read a file from the default filesystem and write it to a new nessie Delta table. This will trigger a commit on current context&rsquo;s branch.</p> <p>For the examples above we have performed commits on the branch specified when we set our spark configuration. Had we not specified the context in our spark configuration all operations would have defaulted to the default branch defined by the server. This is a strong pattern for a spark job which is for example writing data as part of a wider ETL job. It will only ever need one context or branch to write to. If however you are running an interactive session and would like to write to a specific branch without changing context the following should be used to change the context.</p> <div class=tabbed-set data-tabs=10:3><input checked=checked id=__tabbed_10_1 name=__tabbed_10 type=radio><label for=__tabbed_10_1>Java</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>spark</span><span class=p>.</span><span class=na>sparkContext</span><span class=p>().</span><span class=na>hadoopConfiguration</span><span class=p>().</span><span class=na>set</span><span class=p>(</span><span class=s>&quot;nessie.ref&quot;</span><span class=p>,</span> <span class=s>&quot;dev&quot;</span><span class=p>)</span>
<span class=n>regionDf</span> <span class=o>=</span> <span class=n>spark</span><span class=p>.</span><span class=na>read</span><span class=p>().</span><span class=na>load</span><span class=p>(</span><span class=s>&quot;data/region.parquet&quot;</span><span class=p>)</span>
<span class=n>regionDf</span><span class=p>.</span><span class=na>write</span><span class=p>().</span><span class=na>format</span><span class=p>(</span><span class=s>&quot;delta&quot;</span><span class=p>).</span><span class=na>mode</span><span class=p>(</span><span class=s>&quot;overwrite&quot;</span><span class=p>).</span><span class=na>save</span><span class=p>(</span><span class=s>&quot;/location/to/delta/testing/region&quot;</span><span class=p>)</span>
</code></pre></div> </div> <input id=__tabbed_10_2 name=__tabbed_10 type=radio><label for=__tabbed_10_2>Python</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>spark</span><span class=o>.</span><span class=n>sparkContext</span><span class=o>.</span><span class=n>_jsc</span><span class=o>.</span><span class=n>hadoopConfiguration</span><span class=p>()</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=s2>&quot;nessie.ref&quot;</span><span class=p>,</span> <span class=s2>&quot;dev&quot;</span><span class=p>)</span>
<span class=n>region_df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;data/region.parquet&quot;</span><span class=p>)</span>
<span class=n>region_df</span><span class=o>.</span><span class=n>write</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&quot;delta&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>mode</span><span class=p>(</span><span class=s2>&quot;overwrite&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>&quot;/location/to/delta/testing/region&quot;</span><span class=p>)</span>
</code></pre></div> </div> <input id=__tabbed_10_3 name=__tabbed_10 type=radio><label for=__tabbed_10_3>SQL</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=c1>-- change hadoop configuration externally using the Java or Python syntax</span>
<span class=k>CREATE</span> <span class=k>TABLE</span> <span class=n>nessie</span><span class=p>.</span><span class=n>testing</span><span class=p>.</span><span class=n>city</span> <span class=p>(</span><span class=n>C_CITYKEY</span> <span class=nb>BIGINT</span><span class=p>,</span> <span class=n>C_NAME</span> <span class=n>STRING</span><span class=p>,</span> <span class=n>N_NATIONKEY</span> <span class=nb>BIGINT</span><span class=p>,</span> <span class=n>C_COMMENT</span> <span class=n>STRING</span><span class=p>)</span> <span class=k>USING</span> <span class=n>iceberg</span> <span class=n>PARTITIONED</span> <span class=k>BY</span> <span class=p>(</span><span class=n>N_NATIONKEY</span><span class=p>)</span>
<span class=c1>-- AS SELECT .. can be added to the sql statement to perform a CTAS</span>
<span class=k>INSERT</span> <span class=k>INTO</span> <span class=n>nessie</span><span class=p>.</span><span class=n>testing</span><span class=p>.</span><span class=n>city</span> <span class=k>VALUES</span> <span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;a&#39;</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=s1>&#39;comment&#39;</span><span class=p>)</span>
</code></pre></div> </div> </div> <p>We have to manually change the <code>hadoopConfiguration</code> for the <code>SparkContext</code> for a Delta table to be initialised with the correct reference. This will change in the near future when it will be possible to use the same <code>branch@ref</code> syntax as <a href=/tools/spark/#writing>Iceberg</a> inside of delta. Currently it isn&rsquo;t possible to change the ref from SQL directly. This should be fixed in an upcomming release.</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p>Delta by default caches tables internally. If an action has to happen on the same table but a different branch the cache first should be cleared. <code>DeltaLog.clearCache()</code>.</p> </div> <h3 id=reading_1>Reading<a class=headerlink href=#reading_1 title="Permanent link">&para;</a></h3> <p>Reading is similar between Spark2 and Spark3. We will look at both versions together in this section. To read a Nessie table in Delta Lake simply:</p> <div class=tabbed-set data-tabs=11:3><input checked=checked id=__tabbed_11_1 name=__tabbed_11 type=radio><label for=__tabbed_11_1>Java</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>regionDf</span> <span class=o>=</span> <span class=n>spark</span><span class=p>.</span><span class=na>read</span><span class=p>().</span><span class=na>format</span><span class=p>(</span><span class=s>&quot;delta&quot;</span><span class=p>).</span><span class=na>load</span><span class=p>(</span><span class=s>&quot;/path/to/delta/testing/region&quot;</span><span class=p>)</span> 
</code></pre></div> </div> <input id=__tabbed_11_2 name=__tabbed_11 type=radio><label for=__tabbed_11_2>Python</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=n>region_df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=s2>&quot;delta&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&quot;/path/to/delta/testing/region&quot;</span><span class=p>)</span>
</code></pre></div> </div> <input id=__tabbed_11_3 name=__tabbed_11 type=radio><label for=__tabbed_11_3>SQL</label><div class=tabbed-content> <div class=highlight><pre><span></span><code><span class=k>SELECT</span> <span class=o>*</span> <span class=k>FROM</span> <span class=s1>&#39;/path/to/delta/testing/region&#39;</span> 
</code></pre></div> </div> </div> <p>The examples above all use the default branch defined on initialisation. Future versions will add the ability to specify a branch and timestamp similar to Iceberg. Currently to switch branches a similar technique as writing is required (manually changing the hadoopConfiguration). History can be viewed on the command line or via the python client and a specific hash based on commit time can be extracted for use in the spark config. It is recommended to use the time-travel features of Nessie over the Delta features as Nessie history is consistent across the entire database.</p> </article> </div> </div> </main> <!--
  Copyright (c) 2016-2020 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
--> <!-- Application footer --> <footer class=md-footer> <!-- Link to previous and/or next page --> <div class=md-footer-nav> <nav class="md-footer-nav__inner md-grid" aria-label=Footer> <!-- Link to previous page --> <a href=../hive/ title=Hive class="md-footer-nav__link md-footer-nav__link--prev" rel=prev> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Previous </span> Hive </div> </div> </a> <!-- Link to next page --> <a href=../../develop/ title=Community class="md-footer-nav__link md-footer-nav__link--next" rel=next> <div class=md-footer-nav__title> <div class=md-ellipsis> <span class=md-footer-nav__direction> Next </span> Community </div> </div> <div class="md-footer-nav__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> </div> <!-- Further information --> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <!-- Copyright and theme information --> <div class=md-footer-copyright> </div> <!-- Social links --> <div class=md-footer-social> <a href=https://twitter.com/projectnessie target=_blank rel=noopener title=twitter.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> </a> <a href=https://hub.docker.com/r/projectnessie/nessie target=_blank rel=noopener title=hub.docker.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><path d="M349.9 236.3h-66.1v-59.4h66.1v59.4zm0-204.3h-66.1v60.7h66.1V32zm78.2 144.8H362v59.4h66.1v-59.4zm-156.3-72.1h-66.1v60.1h66.1v-60.1zm78.1 0h-66.1v60.1h66.1v-60.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1l-13.3-8.9zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1v-59.4zm-78.1-72.1h-66.1v60.1h66.1v-60.1z"/></svg> </a> <a href="https://www.youtube.com/channel/UC5xjzYuGGuGPCY9FNtqZMsQ?view_as=subscriber" target=_blank rel=noopener title=www.youtube.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg> </a> </div> </div> </div> </footer> </div> <script src=../../assets/javascripts/vendor.77e55a48.min.js></script> <script src=../../assets/javascripts/bundle.aa3f9871.min.js></script><script id=__lang type=application/json>{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script> <script>
        app = initialize({
          base: "../..",
          features: ['navigation.tabs', 'navigation.expand', 'navigation.instant'],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script> </body> </html>