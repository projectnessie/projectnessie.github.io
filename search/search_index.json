{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Git-inspired data version control Cross-table transactions and visibility Open data lake approach, supporting Hive, Spark, Dremio, AWS Athena, etc. Works with Apache Iceberg and Delta Lake tables Run as a docker image, AWS Lambda or fork it on GitHub Get in touch via our Google Group and our Slack Channel and follow us on Twitter . Nessie source code, code contributions and bug reports are on GitHub .","title":"Home"},{"location":"community/","text":"Community \u00b6 Nessie is developed as a consensus-driven open source product under the Apache 2.0 license. Development is done in the open leveraging GitHub issues, PRs and using Google Groups as a mailing list. Get In Touch \u00b6 Slack Channel The developers on Nessie frequent the nessie-public Slack channel. You can get an invite to the channel by emailing slack-subscribe@projectnessie.org . If you want your organization invited to the channel, please state that in the request. Whether you\u2019re super excited about development or just want to hear what is happening, everyone is welcome to join. Google Group If long form is more your thing, we also have created a mailing list on Google groups that you can subscribe to. GitHub Issues Nessie is developed via GitHub issues and pull requests. If you see a problem or want to enhance the product, we suggest you file a GitHub issue for developers to review. Twitter The @projectnessie account on Twitter is our official account. Follow-up to keep to date on what is happening with Project Nessie! YouTube Channel Video content for Nessie will be hosted on our YouTube channel. Docs Our website is all maintained in our source repository. If there is something you think can be improved, feel free to fork our repository and post a pull request. Contribution \u00b6 All contributors are welcome to Project Nessie. To get started, feel free to introduce yourself on Slack or our Google Group. Nessie is open to everyone! Please see the CONTRIBUTING.md guide for more information on how to contribute.","title":"Community"},{"location":"community/#community","text":"Nessie is developed as a consensus-driven open source product under the Apache 2.0 license. Development is done in the open leveraging GitHub issues, PRs and using Google Groups as a mailing list.","title":"Community"},{"location":"community/#get-in-touch","text":"Slack Channel The developers on Nessie frequent the nessie-public Slack channel. You can get an invite to the channel by emailing slack-subscribe@projectnessie.org . If you want your organization invited to the channel, please state that in the request. Whether you\u2019re super excited about development or just want to hear what is happening, everyone is welcome to join. Google Group If long form is more your thing, we also have created a mailing list on Google groups that you can subscribe to. GitHub Issues Nessie is developed via GitHub issues and pull requests. If you see a problem or want to enhance the product, we suggest you file a GitHub issue for developers to review. Twitter The @projectnessie account on Twitter is our official account. Follow-up to keep to date on what is happening with Project Nessie! YouTube Channel Video content for Nessie will be hosted on our YouTube channel. Docs Our website is all maintained in our source repository. If there is something you think can be improved, feel free to fork our repository and post a pull request.","title":"Get In Touch"},{"location":"community/#contribution","text":"All contributors are welcome to Project Nessie. To get started, feel free to introduce yourself on Slack or our Google Group. Nessie is open to everyone! Please see the CONTRIBUTING.md guide for more information on how to contribute.","title":"Contribution"},{"location":"blog/","text":"Nessie Blog \u00b6 Highlights Rolling upgrade issue to 0.26.0 (May 2022)","title":"Nessie Blog"},{"location":"blog/#nessie-blog","text":"Highlights Rolling upgrade issue to 0.26.0 (May 2022)","title":"Nessie Blog"},{"location":"blog/incident-2022-05/","text":"Rolling upgrade issue to 0.26.0 \u00b6 Symptom \u00b6 During or after a rolling upgrade from Nessie version <= 0.25.0 to >= 0.26.0, exceptions/errors like org.projectnessie.versioned.ReferenceNotFoundException: Global log entry '<hex>\u2019 not does not exist. and/or Iceberg content from reference must have global state, but has none may occur. Background \u00b6 When Nessie runs against non-transactional databases, it uses a \u201cglobal pointer\u201d , which holds the mapping of all named references to their HEAD commit IDs, the HEAD of the ref-log and the HEAD of the global-log. Every update to the Nessie repository ends in a CAS 1 on that single global pointer. If the CAS is successful, the change, for example a commit or merge operation, was atomically & consistently applied. 2 The approach to maintain these three HEADs in a single \u201crow\u201d works, but it does not scale well. This \u201csingle point of contention\u201d was never meant to stay forever, just as long as we need it and/or do not have a better solution for it. We implemented Nessie using this concrete global pointer mechanism, because certain decisions haven\u2019t been made at that time, and we wanted to be on the \u201csafe side\u201d and then see what can be improved. Analysis \u00b6 Recently we were certain that having the so-called \u201cglobal state\u201d for Iceberg tables and views is actually not such a great thing. So the team decided that the \u201cglobal state\u201d can go away. This was implemented in the Nessie PR #3866 . Since that change reduced the amount of global-log-entries to nearly 0, we could also get rid of the fact that every single change to the Nessie repository, even creating a branch or tag, creates a potentially empty global-log-entry. Not writing unnecessary global-log-entries was implemented in the Nessie PR #3909 . Both PRs, 3866 and 3909, were released together as Nessie 0.26.0. All Nessie tests were passing and nobody realised that a little devil sneaked into these code changes, waiting to be woken up in production. The situation that the global-pointer contains a \u201cbroken\u201d list of global-log parent IDs is definitely confusing and cannot be explained by only looking at the code base of the target 0.26.0 release. It does not even help to only look at the code base of the source 0.25.0 release. Both code bases are completely fine, when only considering those in isolation. The \u201cfun part\u201d happens, when both versions are active at the same time and requests against the same Nessie repository are served by both versions. Involved parts in the code base \u00b6 The GlobalStatePointer before PR #3909 has a single field called global_id , which served two purposes. First, it served as the \u201ccondition field\u201d for the CAS 1 operation. The same field global_id also pointed to the HEAD of the global-log. PR #3909 changed this. The global_id field only serves as the \u201ccondition field\u201d for the CAS operation, the HEAD of the global log is held in global_log_head . Since global_id is no longer related to the HEAD of the global log, its value is a random value . As you may already guess, if a Nessie version before PR #3909 performs an update, it interprets the value of global_id as the HEAD of the global log . The linked part of the code then evaluates this if-condition to true, which is some other backwards compatibility code, and fills the list of global-log parents only with the value of global_id , because currentEntry is always null , because global_id does not point to a global log entry. Later, the function updateGlobalStatePointer populates the list of global-log-entries with the ID of the new global-log-entry and the collected parents, which is just that random global-id. So the list of global-log IDs in the global-pointer contains two entries - one that points to a \u201cvalid\u201d global log entry and one that does not seem to exist. This is exactly what has been seen . Identification of the issue and mitigation in the live system \u00b6 Whether the symptom is actually caused by Nessie global pointer corruption can be validated by accessing the Nessie storage data directly. Some tooling is required for this because Nessie stores its data as binary blobs. The servers/quarkus-cli module is to be enhanced (in a follow-up PR) with additional commands so that these operations could be performed without additional coding work. Meanwhile, here\u2019s the outline of how to confirm and fix the problem in a live system. How to confirm the symptom: Fetch the Nessie Global Pointer For each global_log_head Parse it as a Nessie hash Check whether there\u2019s an entry in the Global Log table keyed by this hash If at least one of the parent hashes does not have a corresponding global log entry, that will mean that the Global Pointer data has been corrupted How to fix the problem: Do a full scan of the Global Log table Find the last good Global Log entry Normally, if Nessie has substantial history good global log entries will have 20 parents (or whatever was configured) Use log entry timestamps and common sense to identify the last good entry Check all global log entries referred to from the Global Pointer directly Check whether they have any \u201cputs\u201d , i.e. contain Iceberg metadata information If those entries have \u201cputs\u201d construct a new entry that collectively contains their \u201cput\u201d data and refers to the last good parent as its parent. Now this new entry becomes the last good log entry. If the entries from step 4 do not have \u201cputs\u201d they can be ignored. Construct a new Global Pointer using its all of its current data, but put the hash of the last good global log entry as the only element in the global_log_head list. Store the new Global Pointer overwriting the old (broken) Global Pointer data. Re-run the verification procedure (above) to validate the new Global Pointer and Global Log. Additional testing effort \u00b6 Nessie already had a bunch of tests regarding compatibility and upgrades. There are tests exercising older Nessie API versions against current in-tree Nessie server, current in-tree Nessie API against older Nessie server versions, and tests exercising single-instance upgrade paths. Sadly, there were no tests that exercised rolling upgrade scenarios, especially none that exercised the case that hit both the old and new versions for multiple requests. For example, create a branch against the server running the \u201cold\u201d Nessie version, then a commit to that branch against the server running the \u201cnew\u201d Nessie version, and other situations. Today, Nessie has a test suite to validate rolling upgrades, implemented via Nessie PR #4350 . As all compatibility tests, the new rolling upgrade tests are now part of the normal CI workflows for all PRs and the main branch. Upgrade paths are now documented on projectnessie.org here Nessie Server upgrade notes (via PR #4364 + issue #4348 ). Big changes in upcoming releases \u00b6 Heads up: there will be more big changes coming in the next releases, that are already known to be not safe for a rolling upgrade. The Nessie PR #4234 eliminates the remaining contention issues in the global pointer. Because it does fundamentally change how named references and the ref-log are maintained, a rolling upgrade from Nessie <= 0.30.0 would definitely cause issues and is therefore not supported. Future releases \u00b6 The actual problem at play was not really the fact that upgrading Nessie <= 0.25.0 to Nessie >= 0.26.0 can cause global-pointer corruption, which is bad, no question. The actual issue is that this fact was not noticed earlier. Learnings from this escalation: Implement regularly run rolling-upgrade tests in CI ( #4350 ) Clearly document which versions do support rolling upgrades and which combinations do not work CAS means \u201ccompare and swap\u201d. See Wikipedia article \u21a9 \u21a9 If the CAS operation was not successful, Nessie will retry using a exponential backoff, configured here . \u21a9","title":"Rolling upgrade issue to 0.26.0"},{"location":"blog/incident-2022-05/#rolling-upgrade-issue-to-0260","text":"","title":"Rolling upgrade issue to 0.26.0"},{"location":"blog/incident-2022-05/#symptom","text":"During or after a rolling upgrade from Nessie version <= 0.25.0 to >= 0.26.0, exceptions/errors like org.projectnessie.versioned.ReferenceNotFoundException: Global log entry '<hex>\u2019 not does not exist. and/or Iceberg content from reference must have global state, but has none may occur.","title":"Symptom"},{"location":"blog/incident-2022-05/#background","text":"When Nessie runs against non-transactional databases, it uses a \u201cglobal pointer\u201d , which holds the mapping of all named references to their HEAD commit IDs, the HEAD of the ref-log and the HEAD of the global-log. Every update to the Nessie repository ends in a CAS 1 on that single global pointer. If the CAS is successful, the change, for example a commit or merge operation, was atomically & consistently applied. 2 The approach to maintain these three HEADs in a single \u201crow\u201d works, but it does not scale well. This \u201csingle point of contention\u201d was never meant to stay forever, just as long as we need it and/or do not have a better solution for it. We implemented Nessie using this concrete global pointer mechanism, because certain decisions haven\u2019t been made at that time, and we wanted to be on the \u201csafe side\u201d and then see what can be improved.","title":"Background"},{"location":"blog/incident-2022-05/#analysis","text":"Recently we were certain that having the so-called \u201cglobal state\u201d for Iceberg tables and views is actually not such a great thing. So the team decided that the \u201cglobal state\u201d can go away. This was implemented in the Nessie PR #3866 . Since that change reduced the amount of global-log-entries to nearly 0, we could also get rid of the fact that every single change to the Nessie repository, even creating a branch or tag, creates a potentially empty global-log-entry. Not writing unnecessary global-log-entries was implemented in the Nessie PR #3909 . Both PRs, 3866 and 3909, were released together as Nessie 0.26.0. All Nessie tests were passing and nobody realised that a little devil sneaked into these code changes, waiting to be woken up in production. The situation that the global-pointer contains a \u201cbroken\u201d list of global-log parent IDs is definitely confusing and cannot be explained by only looking at the code base of the target 0.26.0 release. It does not even help to only look at the code base of the source 0.25.0 release. Both code bases are completely fine, when only considering those in isolation. The \u201cfun part\u201d happens, when both versions are active at the same time and requests against the same Nessie repository are served by both versions.","title":"Analysis"},{"location":"blog/incident-2022-05/#involved-parts-in-the-code-base","text":"The GlobalStatePointer before PR #3909 has a single field called global_id , which served two purposes. First, it served as the \u201ccondition field\u201d for the CAS 1 operation. The same field global_id also pointed to the HEAD of the global-log. PR #3909 changed this. The global_id field only serves as the \u201ccondition field\u201d for the CAS operation, the HEAD of the global log is held in global_log_head . Since global_id is no longer related to the HEAD of the global log, its value is a random value . As you may already guess, if a Nessie version before PR #3909 performs an update, it interprets the value of global_id as the HEAD of the global log . The linked part of the code then evaluates this if-condition to true, which is some other backwards compatibility code, and fills the list of global-log parents only with the value of global_id , because currentEntry is always null , because global_id does not point to a global log entry. Later, the function updateGlobalStatePointer populates the list of global-log-entries with the ID of the new global-log-entry and the collected parents, which is just that random global-id. So the list of global-log IDs in the global-pointer contains two entries - one that points to a \u201cvalid\u201d global log entry and one that does not seem to exist. This is exactly what has been seen .","title":"Involved parts in the code base"},{"location":"blog/incident-2022-05/#identification-of-the-issue-and-mitigation-in-the-live-system","text":"Whether the symptom is actually caused by Nessie global pointer corruption can be validated by accessing the Nessie storage data directly. Some tooling is required for this because Nessie stores its data as binary blobs. The servers/quarkus-cli module is to be enhanced (in a follow-up PR) with additional commands so that these operations could be performed without additional coding work. Meanwhile, here\u2019s the outline of how to confirm and fix the problem in a live system. How to confirm the symptom: Fetch the Nessie Global Pointer For each global_log_head Parse it as a Nessie hash Check whether there\u2019s an entry in the Global Log table keyed by this hash If at least one of the parent hashes does not have a corresponding global log entry, that will mean that the Global Pointer data has been corrupted How to fix the problem: Do a full scan of the Global Log table Find the last good Global Log entry Normally, if Nessie has substantial history good global log entries will have 20 parents (or whatever was configured) Use log entry timestamps and common sense to identify the last good entry Check all global log entries referred to from the Global Pointer directly Check whether they have any \u201cputs\u201d , i.e. contain Iceberg metadata information If those entries have \u201cputs\u201d construct a new entry that collectively contains their \u201cput\u201d data and refers to the last good parent as its parent. Now this new entry becomes the last good log entry. If the entries from step 4 do not have \u201cputs\u201d they can be ignored. Construct a new Global Pointer using its all of its current data, but put the hash of the last good global log entry as the only element in the global_log_head list. Store the new Global Pointer overwriting the old (broken) Global Pointer data. Re-run the verification procedure (above) to validate the new Global Pointer and Global Log.","title":"Identification of the issue and mitigation in the live system"},{"location":"blog/incident-2022-05/#additional-testing-effort","text":"Nessie already had a bunch of tests regarding compatibility and upgrades. There are tests exercising older Nessie API versions against current in-tree Nessie server, current in-tree Nessie API against older Nessie server versions, and tests exercising single-instance upgrade paths. Sadly, there were no tests that exercised rolling upgrade scenarios, especially none that exercised the case that hit both the old and new versions for multiple requests. For example, create a branch against the server running the \u201cold\u201d Nessie version, then a commit to that branch against the server running the \u201cnew\u201d Nessie version, and other situations. Today, Nessie has a test suite to validate rolling upgrades, implemented via Nessie PR #4350 . As all compatibility tests, the new rolling upgrade tests are now part of the normal CI workflows for all PRs and the main branch. Upgrade paths are now documented on projectnessie.org here Nessie Server upgrade notes (via PR #4364 + issue #4348 ).","title":"Additional testing effort"},{"location":"blog/incident-2022-05/#big-changes-in-upcoming-releases","text":"Heads up: there will be more big changes coming in the next releases, that are already known to be not safe for a rolling upgrade. The Nessie PR #4234 eliminates the remaining contention issues in the global pointer. Because it does fundamentally change how named references and the ref-log are maintained, a rolling upgrade from Nessie <= 0.30.0 would definitely cause issues and is therefore not supported.","title":"Big changes in upcoming releases"},{"location":"blog/incident-2022-05/#future-releases","text":"The actual problem at play was not really the fact that upgrading Nessie <= 0.25.0 to Nessie >= 0.26.0 can cause global-pointer corruption, which is bad, no question. The actual issue is that this fact was not noticed earlier. Learnings from this escalation: Implement regularly run rolling-upgrade tests in CI ( #4350 ) Clearly document which versions do support rolling upgrades and which combinations do not work CAS means \u201ccompare and swap\u201d. See Wikipedia article \u21a9 \u21a9 If the CAS operation was not successful, Nessie will retry using a exponential backoff, configured here . \u21a9","title":"Future releases"},{"location":"develop/","text":"Architecture \u00b6 Nessie builds on the recent ecosystem developments around table formats. The rise of very large metadata and eventually consistent cloud data lakes (S3 specifically) drove the need for an updated model around metadata management. Where consistent directory listings in HDFS used to be sufficient, there were many features lacking. This includes snapshotting, consistency and fast planning. Apache Iceberg and Delta Lake were both created to help alleviate those problems. For more insight into why we created Nessie, you can read the founding blog post by one of Nessie\u2019s creators. Inspiration \u00b6 The Iceberg format (as well as the Delta Lake format) relies on a set of metadata files stored with (or near) the actual data tables. This allows Iceberg to fulfill the same role as the Hive Metastore for transactions without the need for expensive metadata scans or centralized planning (see Iceberg performance ). This includes things such as partitioning (including hidden partitions), schema migrations, appends and deletes. It does however require a pointer to the active metadata set to function. This pointer allows the Iceberg client to acquire and read the current schema, files and partitions in the dataset. Iceberg currently relies on the Hive metastore or hdfs to perform this role. The requirements for this root pointer store is it must hold (at least) information about the location of the current up-to-date metadata file, and it must be able to update this location atomically. In Hive this is accomplished by locks and in hdfs by using atomic file swap operations. These operations don\u2019t exist in eventually consistent cloud object stores, necessitating a Hive metastore for cloud data lakes. The Nessie system is designed to store the root metadata pointer and perform atomic updates to this pointer, obviating the need for a Hive metastore. Removing the need for a Hive metastore simplifies deployment and broadens the reach of tools that can work with Iceberg tables. The above is specific to how Iceberg behaves however Delta Lake operates in a near identical way. The Nessie service is a lightweight Java-based REST API server. It uses a standard optimistic locking strategy to ensure atomic transactions. This relies on every operation carrying an expected hash state for the store and allows for a very light weight and scalable implementation. The implementation uses configurable authentication (e.g. IAM on AWS, JWT elsewhere) and a configurable backend (currently supporting RocksDB for single-node, and DynamoDB or MongoDB) and uses the optimistic locking features of cloud based key value stores to ensure scalability across servers. This architecture allows for Nessie to run in a docker container, as a Lambda function or in a number of other configurations.","title":"Architecture"},{"location":"develop/#architecture","text":"Nessie builds on the recent ecosystem developments around table formats. The rise of very large metadata and eventually consistent cloud data lakes (S3 specifically) drove the need for an updated model around metadata management. Where consistent directory listings in HDFS used to be sufficient, there were many features lacking. This includes snapshotting, consistency and fast planning. Apache Iceberg and Delta Lake were both created to help alleviate those problems. For more insight into why we created Nessie, you can read the founding blog post by one of Nessie\u2019s creators.","title":"Architecture"},{"location":"develop/#inspiration","text":"The Iceberg format (as well as the Delta Lake format) relies on a set of metadata files stored with (or near) the actual data tables. This allows Iceberg to fulfill the same role as the Hive Metastore for transactions without the need for expensive metadata scans or centralized planning (see Iceberg performance ). This includes things such as partitioning (including hidden partitions), schema migrations, appends and deletes. It does however require a pointer to the active metadata set to function. This pointer allows the Iceberg client to acquire and read the current schema, files and partitions in the dataset. Iceberg currently relies on the Hive metastore or hdfs to perform this role. The requirements for this root pointer store is it must hold (at least) information about the location of the current up-to-date metadata file, and it must be able to update this location atomically. In Hive this is accomplished by locks and in hdfs by using atomic file swap operations. These operations don\u2019t exist in eventually consistent cloud object stores, necessitating a Hive metastore for cloud data lakes. The Nessie system is designed to store the root metadata pointer and perform atomic updates to this pointer, obviating the need for a Hive metastore. Removing the need for a Hive metastore simplifies deployment and broadens the reach of tools that can work with Iceberg tables. The above is specific to how Iceberg behaves however Delta Lake operates in a near identical way. The Nessie service is a lightweight Java-based REST API server. It uses a standard optimistic locking strategy to ensure atomic transactions. This relies on every operation carrying an expected hash state for the store and allows for a very light weight and scalable implementation. The implementation uses configurable authentication (e.g. IAM on AWS, JWT elsewhere) and a configurable backend (currently supporting RocksDB for single-node, and DynamoDB or MongoDB) and uses the optimistic locking features of cloud based key value stores to ensure scalability across servers. This architecture allows for Nessie to run in a docker container, as a Lambda function or in a number of other configurations.","title":"Inspiration"},{"location":"develop/java/","text":"Java \u00b6 Java Client \u00b6 Nessie has a thin client designed to be incorporated into existing projects with minimum difficulty. The client is a thin layer over Nessie\u2019s openapi Rest APIs . To use the Nessie client, you can add it as a dependency to your Java project using Maven. The coordinates are: <dependency> <groupId>org.projectnessie</groupId> <artifactId>nessie-client</artifactId> <version>0.30.0</version> </dependency> For ease of integration with tools that carry many dependencies, the Nessie client\u2019s dependencies are declared as optional . It is designed to work with any recent version of JAX-RS client (Jersey and Resteasy are both tested inside Nessie\u2019s tests) + Jackson\u2019s DataBinding and JAX-RS modules (any version from the last ~3+ years). API \u00b6 The NessieClientBuilder and concrete builder implementations (such as HttpClientBuilder ) provide an easy way of configuring and building a NessieApi . The currently stable API that should be used is NessieApiV1 , which can be instantiated as shown below: import java.net.URI ; import java.util.List ; import org.projectnessie.client.api.NessieApiV1 ; import org.projectnessie.client.http.HttpClientBuilder ; import org.projectnessie.model.Reference ; NessieApiV1 api = HttpClientBuilder . builder () . withUri ( URI . create ( \"http://localhost:19121/api/v1\" )) . build ( NessieApiV1 . class ); List < Reference > references = api . getAllReferences (). get (); references . stream () . map ( Reference :: getName ) . forEach ( System . out :: println ); The following subsections will outline how different actions can be done via that Nessie API. Fetching details about a particular Reference \u00b6 Fetches the Reference object of the main branch and then gets its hash api . getReference (). refName ( \"main\" ). get (). getHash (); Creating a Reference \u00b6 Creates a new branch dev that points to the main branch Reference main = api . getReference (). refName ( \"main\" ). get (); Reference branch = api . createReference () . sourceRefName ( main . getName ()) . reference ( Branch . of ( \"dev\" , main . getHash ())) . create (); Creates a new tag dev-tag that points to the main branch Reference main = api . getReference (). refName ( \"main\" ). get (); Reference tag = api . createReference () . sourceRefName ( main . getName ()) . reference ( Tag . of ( \"dev-tag\" , main . getHash ())) . create (); Assigning a Reference \u00b6 Assigns a previously created devBranch2 to the dev branch Reference dev = api . getReference (). refName ( \"dev\" ). get (); api . assignBranch () . branchName ( \"devBranch2\" ) . hash ( dev . getHash ()) . assignTo ( dev ) . assign (); Assigns a previously created dev-tag to the dev branch Reference dev = api . getReference (). refName ( \"dev\" ). get (); api . assignTag () . tagName ( \"dev-tag\" ) . hash ( dev . getHash ()) . assignTo ( dev ) . assign (); Deleting a Reference \u00b6 Deletes a previously created branch api . deleteBranch () . branchName ( dev . getName ()) . hash ( dev . getHash ()) . delete (); Deletes a previously created tag api . deleteTag () . tagName ( devTag . getName ()) . hash ( devTag . getHash ()) . delete (); Fetching the Server Configuration \u00b6 NessieConfiguration config = api . getConfig (); config . getDefaultBranch (); config . getVersion (); Committing \u00b6 Creates a new commit by adding metadata for an IcebergTable under the specified ContentKey instance represented by key and deletes content represented by key2 ContentKey key = ContentKey . of ( \"table.name.space\" , \"name\" ); ContentKey key2 = ContentKey . of ( \"other.name.space\" , \"name2\" ); IcebergTable icebergTable = IcebergTable . of ( \"path1\" , 42L ); api . commitMultipleOperations () . branchName ( branch ) . hash ( main . getHash ()) . operation ( Put . of ( key , icebergTable )) . operation ( Delete . of ( key2 )) . commitMeta ( CommitMeta . fromMessage ( \"commit 1\" )) . commit (); Fetching Content \u00b6 Fetches the content for a single ContentKey ContentKey key = ContentKey . of ( \"table.name.space\" , \"name\" ); Map < ContentKey , Content > map = api . getContent (). key ( key ). refName ( \"dev\" ). get (); Fetches the content for multiple ContentKey instances List < ContentKey > keys = Arrays . asList ( ContentKey . of ( \"table.name.space\" , \"name1\" ), ContentKey . of ( \"table.name.space\" , \"name2\" ), ContentKey . of ( \"table.name.space\" , \"name3\" )); Map < ContentKey , Content > allContent = api . getContent (). keys ( keys ). refName ( \"dev\" ). get (); Fetching the Commit Log \u00b6 Fetches the commit log for the dev reference LogResponse log = api . getCommitLog (). refName ( \"dev\" ). get (); Fetching Entries \u00b6 Fetches the entries for the dev reference EntriesResponse entries = api . getEntries (). refName ( \"dev\" ). get (); Merging \u00b6 This merges fromBranch into the given intoBranch api . mergeRefIntoBranch () . branchName ( \"intoBranch\" ) . hash ( intoBranchHash ) . fromRefName ( \"fromBranch\" ) . fromHash ( fromHash ) . merge (); Transplanting \u00b6 Transplant/cherry-pick a bunch of commits from main into the dev branch Branch dev = ... api . transplantCommitsIntoBranch () . branchName ( dev . getName ()) . hash ( dev . getHash ()) . fromRefName ( \"main\" ) . hashesToTransplant ( Collections . singletonList ( api . getReference (). refName ( \"main\" ). get (). getHash ())) . transplant () Authentication \u00b6 Nessie has multiple NessieAuthenticationProvider implementations that allow different client authentication mechanisms as can be seen below. The documentation for how to configure Nessie server authentication can be found here . The BasicAuthenticationProvider allows connecting to a Nessie server that has BASIC authentication enabled. Note that BASIC is not supported in production and should only be used for development/testing. NessieApiV1 api = HttpClientBuilder . builder () . withUri ( URI . create ( \"http://localhost:19121/api/v1\" )) . withAuthentication ( BasicAuthenticationProvider . create ( \"my_username\" , \"very_secret\" )) . build ( NessieApiV1 . class ); The BearerAuthenticationProvider allows connecting to a Nessie server that has BEARER authentication enabled. NessieApiV1 api = HttpClientBuilder . builder () . withUri ( URI . create ( \"http://localhost:19121/api/v1\" )) . withAuthentication ( BearerAuthenticationProvider . create ( \"bearerToken\" )) . build ( NessieApiV1 . class );","title":"Java"},{"location":"develop/java/#java","text":"","title":"Java"},{"location":"develop/java/#java-client","text":"Nessie has a thin client designed to be incorporated into existing projects with minimum difficulty. The client is a thin layer over Nessie\u2019s openapi Rest APIs . To use the Nessie client, you can add it as a dependency to your Java project using Maven. The coordinates are: <dependency> <groupId>org.projectnessie</groupId> <artifactId>nessie-client</artifactId> <version>0.30.0</version> </dependency> For ease of integration with tools that carry many dependencies, the Nessie client\u2019s dependencies are declared as optional . It is designed to work with any recent version of JAX-RS client (Jersey and Resteasy are both tested inside Nessie\u2019s tests) + Jackson\u2019s DataBinding and JAX-RS modules (any version from the last ~3+ years).","title":"Java Client"},{"location":"develop/java/#api","text":"The NessieClientBuilder and concrete builder implementations (such as HttpClientBuilder ) provide an easy way of configuring and building a NessieApi . The currently stable API that should be used is NessieApiV1 , which can be instantiated as shown below: import java.net.URI ; import java.util.List ; import org.projectnessie.client.api.NessieApiV1 ; import org.projectnessie.client.http.HttpClientBuilder ; import org.projectnessie.model.Reference ; NessieApiV1 api = HttpClientBuilder . builder () . withUri ( URI . create ( \"http://localhost:19121/api/v1\" )) . build ( NessieApiV1 . class ); List < Reference > references = api . getAllReferences (). get (); references . stream () . map ( Reference :: getName ) . forEach ( System . out :: println ); The following subsections will outline how different actions can be done via that Nessie API.","title":"API"},{"location":"develop/java/#fetching-details-about-a-particular-reference","text":"Fetches the Reference object of the main branch and then gets its hash api . getReference (). refName ( \"main\" ). get (). getHash ();","title":"Fetching details about a particular Reference"},{"location":"develop/java/#creating-a-reference","text":"Creates a new branch dev that points to the main branch Reference main = api . getReference (). refName ( \"main\" ). get (); Reference branch = api . createReference () . sourceRefName ( main . getName ()) . reference ( Branch . of ( \"dev\" , main . getHash ())) . create (); Creates a new tag dev-tag that points to the main branch Reference main = api . getReference (). refName ( \"main\" ). get (); Reference tag = api . createReference () . sourceRefName ( main . getName ()) . reference ( Tag . of ( \"dev-tag\" , main . getHash ())) . create ();","title":"Creating a Reference"},{"location":"develop/java/#assigning-a-reference","text":"Assigns a previously created devBranch2 to the dev branch Reference dev = api . getReference (). refName ( \"dev\" ). get (); api . assignBranch () . branchName ( \"devBranch2\" ) . hash ( dev . getHash ()) . assignTo ( dev ) . assign (); Assigns a previously created dev-tag to the dev branch Reference dev = api . getReference (). refName ( \"dev\" ). get (); api . assignTag () . tagName ( \"dev-tag\" ) . hash ( dev . getHash ()) . assignTo ( dev ) . assign ();","title":"Assigning a Reference"},{"location":"develop/java/#deleting-a-reference","text":"Deletes a previously created branch api . deleteBranch () . branchName ( dev . getName ()) . hash ( dev . getHash ()) . delete (); Deletes a previously created tag api . deleteTag () . tagName ( devTag . getName ()) . hash ( devTag . getHash ()) . delete ();","title":"Deleting a Reference"},{"location":"develop/java/#fetching-the-server-configuration","text":"NessieConfiguration config = api . getConfig (); config . getDefaultBranch (); config . getVersion ();","title":"Fetching the Server Configuration"},{"location":"develop/java/#committing","text":"Creates a new commit by adding metadata for an IcebergTable under the specified ContentKey instance represented by key and deletes content represented by key2 ContentKey key = ContentKey . of ( \"table.name.space\" , \"name\" ); ContentKey key2 = ContentKey . of ( \"other.name.space\" , \"name2\" ); IcebergTable icebergTable = IcebergTable . of ( \"path1\" , 42L ); api . commitMultipleOperations () . branchName ( branch ) . hash ( main . getHash ()) . operation ( Put . of ( key , icebergTable )) . operation ( Delete . of ( key2 )) . commitMeta ( CommitMeta . fromMessage ( \"commit 1\" )) . commit ();","title":"Committing"},{"location":"develop/java/#fetching-content","text":"Fetches the content for a single ContentKey ContentKey key = ContentKey . of ( \"table.name.space\" , \"name\" ); Map < ContentKey , Content > map = api . getContent (). key ( key ). refName ( \"dev\" ). get (); Fetches the content for multiple ContentKey instances List < ContentKey > keys = Arrays . asList ( ContentKey . of ( \"table.name.space\" , \"name1\" ), ContentKey . of ( \"table.name.space\" , \"name2\" ), ContentKey . of ( \"table.name.space\" , \"name3\" )); Map < ContentKey , Content > allContent = api . getContent (). keys ( keys ). refName ( \"dev\" ). get ();","title":"Fetching Content"},{"location":"develop/java/#fetching-the-commit-log","text":"Fetches the commit log for the dev reference LogResponse log = api . getCommitLog (). refName ( \"dev\" ). get ();","title":"Fetching the Commit Log"},{"location":"develop/java/#fetching-entries","text":"Fetches the entries for the dev reference EntriesResponse entries = api . getEntries (). refName ( \"dev\" ). get ();","title":"Fetching Entries"},{"location":"develop/java/#merging","text":"This merges fromBranch into the given intoBranch api . mergeRefIntoBranch () . branchName ( \"intoBranch\" ) . hash ( intoBranchHash ) . fromRefName ( \"fromBranch\" ) . fromHash ( fromHash ) . merge ();","title":"Merging"},{"location":"develop/java/#transplanting","text":"Transplant/cherry-pick a bunch of commits from main into the dev branch Branch dev = ... api . transplantCommitsIntoBranch () . branchName ( dev . getName ()) . hash ( dev . getHash ()) . fromRefName ( \"main\" ) . hashesToTransplant ( Collections . singletonList ( api . getReference (). refName ( \"main\" ). get (). getHash ())) . transplant ()","title":"Transplanting"},{"location":"develop/java/#authentication","text":"Nessie has multiple NessieAuthenticationProvider implementations that allow different client authentication mechanisms as can be seen below. The documentation for how to configure Nessie server authentication can be found here . The BasicAuthenticationProvider allows connecting to a Nessie server that has BASIC authentication enabled. Note that BASIC is not supported in production and should only be used for development/testing. NessieApiV1 api = HttpClientBuilder . builder () . withUri ( URI . create ( \"http://localhost:19121/api/v1\" )) . withAuthentication ( BasicAuthenticationProvider . create ( \"my_username\" , \"very_secret\" )) . build ( NessieApiV1 . class ); The BearerAuthenticationProvider allows connecting to a Nessie server that has BEARER authentication enabled. NessieApiV1 api = HttpClientBuilder . builder () . withUri ( URI . create ( \"http://localhost:19121/api/v1\" )) . withAuthentication ( BearerAuthenticationProvider . create ( \"bearerToken\" )) . build ( NessieApiV1 . class );","title":"Authentication"},{"location":"develop/kernel/","text":"Commit Kernel \u00b6 Nessie\u2019s production commit kernel is optimized to provide high commit throughput against a distributed key value store that provides record level CAS (compare-and-swap) capability or transactional/relational databases. The commit kernel is the heart of Nessie\u2019s operations and enables it to provide lightweight creation of new tags/branches, merges, and rebases, all with very high concurrent commit rate. High level abstract \u00b6 Nessie 1.0 comes with a version store (aka commit kernel) implementation that is different from both Git and older Nessie version store implementations in Nessie versions before 1.0 and is abstracted as illustrated below. Nessie generally supports both non-transactional key-value databases and transactional databases (relational). The goal of all implementations is to spread the keys as much as possible, so data can be properly distributed, and to keep the number of operations against a database low to reduce operation time. Contention by itself is not avoidable, because operations against Nessie are guaranteed to be atomic and consistent. Nessie Content Types \u00b6 The state of so called Content objects like IcebergTable or DeltaLakeTable represents the current state of a table in a data lake. Whenever a table has changed via for example Iceberg, a so-called commit operation instructs Nessie to record the new state in a Nessie commit, which carries the Content object(s). IcebergTable contains the pointer to Iceberg\u2019s table metadata plus the IDs of the snapshot, schema, partition spec, sort order defined in the table metadata. - Iceberg\u2019s table metadata manages information is stored in the Nessie commit. - The value of the snapshot-ID, schema-ID, partition-spec-ID, sort-order-ID is stored per Nessie named reference (branch or tag). For more information, please refer the spec On Reference State vs Global State Updating global-state and on-reference-state are technically operations against two different entities in Nessie\u2019s backend database. Classic, relational databases (usually) come with a transaction manager, which ensures that changes to different tables appear atomically to other users. Much more scalable key-value stores do not have a transaction manager, but usually only provide so-called \u201cCompare-and-Swap\u201d (CAS) operations, which conditionally update a single key-value pair. This means, that the data model has to be fundamentally different for non-transactional key-value stores and transactional databases. Support for non-transactional databases, the data model, is designed in a way that only requires a single CAS operation to ensure atomicity and consistency even when committing two logical entities, namely the global-state and the on-reference-state , respectively the update to the \u201cHEAD\u201d of the updated branch. Some more details are outlined below. Version Store and Database Adapters \u00b6 Nessie\u2019s REST API implementation works against the VersionStore interface, which defines the contract for the REST API, deals with concrete contents objects like IcebergTable or DeltaLakeTable . PersistVersionStore is an implementation of VersionStore and translates between the content type objects like IcebergTable or DeltaLakeTable and the \u201cbinary\u201d (think: \u201cBLOB\u201d) representation in the database adapters. DatabaseAdapter interface defining the content type independent mechanisms to perform Nessie operations like commit, transplants and merges as well as retrieving data. AbstractDatabaseAdapter implements the commit logic, commit conflict detection and operations to retrieve information. There are these subclasses: * NonTransactionalDatabaseAdapter is used as a base for key-value stores. * Implementation for DynamoDB * Implementation for MongoDB * Implementation for RocksDB * Implementation for InMemory * TransactionalDatabaseAdapter JDBC based implementation relying on relational database transactions for conflict resolution (rollback). * SQL/DDL/type definitions for Postgres, Cockroach, H2 Non-transactional key-value databases \u00b6 The data model for non-transactional key-value databases relies on a single global-state-pointer , which is technically a table with a single row pointing to the current entry in the global-log , current entry in the ref-log and the \u201cHEAD\u201ds of all named references (branches and tags). The global-log contains changes to global-state , which is needed for backwards compatibility. The ref-log contains the history with details of operations like COMMIT, MERGE, TRANSPLANT, CREATE_REFERENCE, DELETE_REFERENCE, ASSIGN_REFERENCE. The commit-log contains the individual Nessie commits. All commit, transplant and merge operations as well as other write operations like creating, reassigning or deleting a named reference work inside a so-called \u201cCAS loop\u201d, which technically works like the following pseudocode. A CAS operation can be imagined as an SQL like UPDATE global_pointer SET value = :new_value WHERE primary_key = 1 AND value = :expected_value . // Pseudo definition of a Nessie write operation like a commit, merge, transplant, createReference, // assignReference, deleteReference. FunctionResult nessieWriteOperation ( parameters ...) { while ( true ) { globalPointer = loadGlobalPointer (); // Try the actual operation. // // Return the keys of the optimistically written rows in the commit log and global log, // the changes to the global pointer and the result to be returned to the caller. optimisticallyWrittenRows , updatesToGlobalPointer , functionResult = performNessieWriteOperation ( globalPointer , parameters ); // Try the CAS operation on the global pointer. success = tryUpdateGlobalPointer ( globalPointer , updatesToGlobalPointer ); if ( success ) { // If the CAS oepration was successfully applied, return the function's result to the user. return functionResult ; } // CAS was not successful deleteOptimisticallyWrittenRows ( optimisticallyWrittenRows ); if ( ! retryPolicy . allowsRetry ()) { throw new RetryFailureException (); } } } Transactional databases \u00b6 The data model for transactional databases defines tables for * the global-state , where the primary key is the globally unique content-id and the value of the global-state , * the named-references , which define the commit hash/id of the \u201cHEAD\u201d of each named reference, * the commit-log , which contains all commits * the ref-log contains the history with details of operations like COMMIT, MERGE, TRANSPLANT, CREATE_REFERENCE, DELETE_REFERENCE, ASSIGN_REFERENCE. * the ref-log-head contains current head of the ref_log entry. All commit, transplant and merge operations as well as other write operations like creating, reassigning or deleting a named reference work inside a so-called \u201coperation loop\u201d, which is rather somewhat similar to the \u201cCAS loop\u201d for non-transactional databases, but does not need to keep track of optimistically written data and can directly use conditional SQL DML statements like UPDATE table SET col = :value WHERE key = :key AND col = :expected_value resp. INSERT INTO... . The database then comes back with either an update count > 0 to indicate success or an update count = 0 to indicate failure or an integrity constraint violation error. Tracing & Metrics \u00b6 Two delegating implementations of the VersionStore interface exist to provide metrics and tracing using Micrometer and OpenTracing. Implemented database adapters \u00b6 All current implementations are based on the abstractions in the Maven modules :nessie-versioned-persist-adapter + either :nessie-versioned-persist-non-transactional (for key-value stores) or :nessie-versioned-persist-transactional (for relational/transactional databases). Non-transactional InMemory (testing and prototyping) RocksDB MongoDB DynamoDB (planned) Transactional H2 Postgres Note: not all database adapters are available via Nessie running via Quarkus! Nessie logic vs database specific adapters \u00b6 The whole logic around commits, merges, transplants, fetching keys and values resides in AbstractDatabaseAdapter and is shared across all kinds of database adapters. Database adapters, for both transactional and non-transactional databases, have the database specific implementations around the CAS loop for non-transactional, catching integrity constraint violations for transactional, the concrete physical data model and the concrete read & write implementations. Logical Data model \u00b6 The DatabaseAdapter interface defines the functions needed by the version store implementation to access the data. Implementations of DatabaseAdapter are free to implement their own optimizations. Non-transactional \u00b6 Implementations are based on NonTransactionalDatabaseAdapter and only implement the database specific \u201cprimitives\u201d to unconditionally read and write records and perform the mandatory CAS (compare-and-swap) operation. Key-value stores are all non-transactional as those are built for scale-out. Most key-value stores support atomic CAS (compare-and-swap) operations against a single row/record, but atomic and conditional updates to multiple rows/records is either not supported at all or extremely slow. Nessie differentiates between content types that do require so called global-state and those that do not. Global-state is maintained globally and evaluated when a content value object is being retrieved, combined with the requested on-reference state on a Nessie commit. For Nessie commits , which are atomic, this means that Nessie has to update both the global-state and the on-reference-state for a content type that requires global state . While this is not an issue with a relational/transactional database, it is an issue in a key-value store. Nessie solves this with a single \u201cglobal pointer\u201d, which is updated using a CAS operation. Nessie commits (and similar operations like \u201ctransplant\u201d and \u201cmerge\u201d) optimistically write all the data to the commit log and global state log first and then try to perform the CAS operation against the global pointer. If the CAS operation succeeds, the Nessie commit operation has succeeded. If the CAS operation failed, all optimistically written rows are deleted and the whole Nessie commit is retried. The logical data model shared by all non-transactional database adapters consists of five entities: Global-pointer a single \u201ctable row\u201d that points to the current global-state-log and all HEADs for all named references. Consistent updates are guaranteed via a CAS operation on this entity comparing the HEAD of the global-state-log . Commit-log contains all commit log entries, identified by a deterministic hash. This is the same as for transactional databases. Global-state-log contains all changes to the global state for content types that do require global state. The row keys are random IDs. Key-lists acts as an \u201coverflow\u201d for large key lists that do not fit entirely into a single commit log entry\u2019s embedded key list. Ref-log contains the history with details of operations like COMMIT, MERGE, TRANSPLANT, CREATE_REFERENCE, DELETE_REFERENCE, ASSIGN_REFERENCE. Transactional \u00b6 Implementations are based on TxDatabaseAdapter and currently only implement the database specific nuances in the SQL syntax and Nessie data type mappings. The data for transactional database adapters consists of six tables: Named-references contains all named references and their current HEAD, the latter is used to guarantee consistent updates. Global-state contains the current global state for a contents ID for content types that require global state. Consistent changes are guaranteed by tracking a checksum value of the contents of the value representing the global state. Commit-log contains all commit log entries, identified by a deterministic hash. This is the same as for non-transactional databases. Key-lists acts as an \u201coverflow\u201d for large key lists that do not fit entirely into a single commit log entry\u2019s embedded key list. Ref-log contains the history with details of operations like COMMIT, MERGE, TRANSPLANT, CREATE_REFERENCE, DELETE_REFERENCE, ASSIGN_REFERENCE. Ref-log-head contains current head of the ref_log entry. Performance \u00b6 The non-transactional and transactional variants have different performance characteristics. As outlined above, the non-transactional variant uses a central global pointer and the transactional variant leverages the transaction manager of the database. The implementation can perform many hundred to many thousand commits per second, depending on the performance of the backend database and the characteristics of the use case. The two important factors are: Concurrent commits against different branches are \u201cfaster\u201d than concurrent commits against a single branch Concurrent commits against the same table (think: Iceberg or Deltalake table) are slower than concurrent commits against different tables. Gatling Benchmarks \u00b6 Nessie has a framework to simulate \u201chigher level use cases\u201d using Gatling. See the readmes here and here . Please note that all kinds of performance tests are only meaningful in production-like environments using production-like use cases. Microbenchmarks \u00b6 There are microbenchmarks available, which can be useful to investigate the overall performance of a database. Please note that performance tests, even microbenchmarks, are only meaningful in production-like environments using production-like use cases. See Nessie Persistence Microbenchmarks README.me . Retry Mechanism \u00b6 All write operations do support retries. Retries happen, if a non-transactional CAS operation failed or a transactional DML operation ran into an \u201cintegrity constraint violation\u201d. Both the number of retries and total time for the operation are bounded. There is an (exponentially increasing) sleep time between two tries. The actual values for the retry mechanism are configurable.","title":"Commit Kernel"},{"location":"develop/kernel/#commit-kernel","text":"Nessie\u2019s production commit kernel is optimized to provide high commit throughput against a distributed key value store that provides record level CAS (compare-and-swap) capability or transactional/relational databases. The commit kernel is the heart of Nessie\u2019s operations and enables it to provide lightweight creation of new tags/branches, merges, and rebases, all with very high concurrent commit rate.","title":"Commit Kernel"},{"location":"develop/kernel/#high-level-abstract","text":"Nessie 1.0 comes with a version store (aka commit kernel) implementation that is different from both Git and older Nessie version store implementations in Nessie versions before 1.0 and is abstracted as illustrated below. Nessie generally supports both non-transactional key-value databases and transactional databases (relational). The goal of all implementations is to spread the keys as much as possible, so data can be properly distributed, and to keep the number of operations against a database low to reduce operation time. Contention by itself is not avoidable, because operations against Nessie are guaranteed to be atomic and consistent.","title":"High level abstract"},{"location":"develop/kernel/#nessie-content-types","text":"The state of so called Content objects like IcebergTable or DeltaLakeTable represents the current state of a table in a data lake. Whenever a table has changed via for example Iceberg, a so-called commit operation instructs Nessie to record the new state in a Nessie commit, which carries the Content object(s). IcebergTable contains the pointer to Iceberg\u2019s table metadata plus the IDs of the snapshot, schema, partition spec, sort order defined in the table metadata. - Iceberg\u2019s table metadata manages information is stored in the Nessie commit. - The value of the snapshot-ID, schema-ID, partition-spec-ID, sort-order-ID is stored per Nessie named reference (branch or tag). For more information, please refer the spec On Reference State vs Global State Updating global-state and on-reference-state are technically operations against two different entities in Nessie\u2019s backend database. Classic, relational databases (usually) come with a transaction manager, which ensures that changes to different tables appear atomically to other users. Much more scalable key-value stores do not have a transaction manager, but usually only provide so-called \u201cCompare-and-Swap\u201d (CAS) operations, which conditionally update a single key-value pair. This means, that the data model has to be fundamentally different for non-transactional key-value stores and transactional databases. Support for non-transactional databases, the data model, is designed in a way that only requires a single CAS operation to ensure atomicity and consistency even when committing two logical entities, namely the global-state and the on-reference-state , respectively the update to the \u201cHEAD\u201d of the updated branch. Some more details are outlined below.","title":"Nessie Content Types"},{"location":"develop/kernel/#version-store-and-database-adapters","text":"Nessie\u2019s REST API implementation works against the VersionStore interface, which defines the contract for the REST API, deals with concrete contents objects like IcebergTable or DeltaLakeTable . PersistVersionStore is an implementation of VersionStore and translates between the content type objects like IcebergTable or DeltaLakeTable and the \u201cbinary\u201d (think: \u201cBLOB\u201d) representation in the database adapters. DatabaseAdapter interface defining the content type independent mechanisms to perform Nessie operations like commit, transplants and merges as well as retrieving data. AbstractDatabaseAdapter implements the commit logic, commit conflict detection and operations to retrieve information. There are these subclasses: * NonTransactionalDatabaseAdapter is used as a base for key-value stores. * Implementation for DynamoDB * Implementation for MongoDB * Implementation for RocksDB * Implementation for InMemory * TransactionalDatabaseAdapter JDBC based implementation relying on relational database transactions for conflict resolution (rollback). * SQL/DDL/type definitions for Postgres, Cockroach, H2","title":"Version Store and Database Adapters"},{"location":"develop/kernel/#non-transactional-key-value-databases","text":"The data model for non-transactional key-value databases relies on a single global-state-pointer , which is technically a table with a single row pointing to the current entry in the global-log , current entry in the ref-log and the \u201cHEAD\u201ds of all named references (branches and tags). The global-log contains changes to global-state , which is needed for backwards compatibility. The ref-log contains the history with details of operations like COMMIT, MERGE, TRANSPLANT, CREATE_REFERENCE, DELETE_REFERENCE, ASSIGN_REFERENCE. The commit-log contains the individual Nessie commits. All commit, transplant and merge operations as well as other write operations like creating, reassigning or deleting a named reference work inside a so-called \u201cCAS loop\u201d, which technically works like the following pseudocode. A CAS operation can be imagined as an SQL like UPDATE global_pointer SET value = :new_value WHERE primary_key = 1 AND value = :expected_value . // Pseudo definition of a Nessie write operation like a commit, merge, transplant, createReference, // assignReference, deleteReference. FunctionResult nessieWriteOperation ( parameters ...) { while ( true ) { globalPointer = loadGlobalPointer (); // Try the actual operation. // // Return the keys of the optimistically written rows in the commit log and global log, // the changes to the global pointer and the result to be returned to the caller. optimisticallyWrittenRows , updatesToGlobalPointer , functionResult = performNessieWriteOperation ( globalPointer , parameters ); // Try the CAS operation on the global pointer. success = tryUpdateGlobalPointer ( globalPointer , updatesToGlobalPointer ); if ( success ) { // If the CAS oepration was successfully applied, return the function's result to the user. return functionResult ; } // CAS was not successful deleteOptimisticallyWrittenRows ( optimisticallyWrittenRows ); if ( ! retryPolicy . allowsRetry ()) { throw new RetryFailureException (); } } }","title":"Non-transactional key-value databases"},{"location":"develop/kernel/#transactional-databases","text":"The data model for transactional databases defines tables for * the global-state , where the primary key is the globally unique content-id and the value of the global-state , * the named-references , which define the commit hash/id of the \u201cHEAD\u201d of each named reference, * the commit-log , which contains all commits * the ref-log contains the history with details of operations like COMMIT, MERGE, TRANSPLANT, CREATE_REFERENCE, DELETE_REFERENCE, ASSIGN_REFERENCE. * the ref-log-head contains current head of the ref_log entry. All commit, transplant and merge operations as well as other write operations like creating, reassigning or deleting a named reference work inside a so-called \u201coperation loop\u201d, which is rather somewhat similar to the \u201cCAS loop\u201d for non-transactional databases, but does not need to keep track of optimistically written data and can directly use conditional SQL DML statements like UPDATE table SET col = :value WHERE key = :key AND col = :expected_value resp. INSERT INTO... . The database then comes back with either an update count > 0 to indicate success or an update count = 0 to indicate failure or an integrity constraint violation error.","title":"Transactional databases"},{"location":"develop/kernel/#tracing-metrics","text":"Two delegating implementations of the VersionStore interface exist to provide metrics and tracing using Micrometer and OpenTracing.","title":"Tracing &amp; Metrics"},{"location":"develop/kernel/#implemented-database-adapters","text":"All current implementations are based on the abstractions in the Maven modules :nessie-versioned-persist-adapter + either :nessie-versioned-persist-non-transactional (for key-value stores) or :nessie-versioned-persist-transactional (for relational/transactional databases). Non-transactional InMemory (testing and prototyping) RocksDB MongoDB DynamoDB (planned) Transactional H2 Postgres Note: not all database adapters are available via Nessie running via Quarkus!","title":"Implemented database adapters"},{"location":"develop/kernel/#nessie-logic-vs-database-specific-adapters","text":"The whole logic around commits, merges, transplants, fetching keys and values resides in AbstractDatabaseAdapter and is shared across all kinds of database adapters. Database adapters, for both transactional and non-transactional databases, have the database specific implementations around the CAS loop for non-transactional, catching integrity constraint violations for transactional, the concrete physical data model and the concrete read & write implementations.","title":"Nessie logic vs database specific adapters"},{"location":"develop/kernel/#logical-data-model","text":"The DatabaseAdapter interface defines the functions needed by the version store implementation to access the data. Implementations of DatabaseAdapter are free to implement their own optimizations.","title":"Logical Data model"},{"location":"develop/kernel/#non-transactional","text":"Implementations are based on NonTransactionalDatabaseAdapter and only implement the database specific \u201cprimitives\u201d to unconditionally read and write records and perform the mandatory CAS (compare-and-swap) operation. Key-value stores are all non-transactional as those are built for scale-out. Most key-value stores support atomic CAS (compare-and-swap) operations against a single row/record, but atomic and conditional updates to multiple rows/records is either not supported at all or extremely slow. Nessie differentiates between content types that do require so called global-state and those that do not. Global-state is maintained globally and evaluated when a content value object is being retrieved, combined with the requested on-reference state on a Nessie commit. For Nessie commits , which are atomic, this means that Nessie has to update both the global-state and the on-reference-state for a content type that requires global state . While this is not an issue with a relational/transactional database, it is an issue in a key-value store. Nessie solves this with a single \u201cglobal pointer\u201d, which is updated using a CAS operation. Nessie commits (and similar operations like \u201ctransplant\u201d and \u201cmerge\u201d) optimistically write all the data to the commit log and global state log first and then try to perform the CAS operation against the global pointer. If the CAS operation succeeds, the Nessie commit operation has succeeded. If the CAS operation failed, all optimistically written rows are deleted and the whole Nessie commit is retried. The logical data model shared by all non-transactional database adapters consists of five entities: Global-pointer a single \u201ctable row\u201d that points to the current global-state-log and all HEADs for all named references. Consistent updates are guaranteed via a CAS operation on this entity comparing the HEAD of the global-state-log . Commit-log contains all commit log entries, identified by a deterministic hash. This is the same as for transactional databases. Global-state-log contains all changes to the global state for content types that do require global state. The row keys are random IDs. Key-lists acts as an \u201coverflow\u201d for large key lists that do not fit entirely into a single commit log entry\u2019s embedded key list. Ref-log contains the history with details of operations like COMMIT, MERGE, TRANSPLANT, CREATE_REFERENCE, DELETE_REFERENCE, ASSIGN_REFERENCE.","title":"Non-transactional"},{"location":"develop/kernel/#transactional","text":"Implementations are based on TxDatabaseAdapter and currently only implement the database specific nuances in the SQL syntax and Nessie data type mappings. The data for transactional database adapters consists of six tables: Named-references contains all named references and their current HEAD, the latter is used to guarantee consistent updates. Global-state contains the current global state for a contents ID for content types that require global state. Consistent changes are guaranteed by tracking a checksum value of the contents of the value representing the global state. Commit-log contains all commit log entries, identified by a deterministic hash. This is the same as for non-transactional databases. Key-lists acts as an \u201coverflow\u201d for large key lists that do not fit entirely into a single commit log entry\u2019s embedded key list. Ref-log contains the history with details of operations like COMMIT, MERGE, TRANSPLANT, CREATE_REFERENCE, DELETE_REFERENCE, ASSIGN_REFERENCE. Ref-log-head contains current head of the ref_log entry.","title":"Transactional"},{"location":"develop/kernel/#performance","text":"The non-transactional and transactional variants have different performance characteristics. As outlined above, the non-transactional variant uses a central global pointer and the transactional variant leverages the transaction manager of the database. The implementation can perform many hundred to many thousand commits per second, depending on the performance of the backend database and the characteristics of the use case. The two important factors are: Concurrent commits against different branches are \u201cfaster\u201d than concurrent commits against a single branch Concurrent commits against the same table (think: Iceberg or Deltalake table) are slower than concurrent commits against different tables.","title":"Performance"},{"location":"develop/kernel/#gatling-benchmarks","text":"Nessie has a framework to simulate \u201chigher level use cases\u201d using Gatling. See the readmes here and here . Please note that all kinds of performance tests are only meaningful in production-like environments using production-like use cases.","title":"Gatling Benchmarks"},{"location":"develop/kernel/#microbenchmarks","text":"There are microbenchmarks available, which can be useful to investigate the overall performance of a database. Please note that performance tests, even microbenchmarks, are only meaningful in production-like environments using production-like use cases. See Nessie Persistence Microbenchmarks README.me .","title":"Microbenchmarks"},{"location":"develop/kernel/#retry-mechanism","text":"All write operations do support retries. Retries happen, if a non-transactional CAS operation failed or a transactional DML operation ran into an \u201cintegrity constraint violation\u201d. Both the number of retries and total time for the operation are bounded. There is an (exponentially increasing) sleep time between two tries. The actual values for the retry mechanism are configurable.","title":"Retry Mechanism"},{"location":"develop/nessie_vs_git/","text":"Nessie vs Git \u00b6 Git is awesome. Nessie was inspired by Git but makes very different tradeoffs. Nessie focuses on the specific use case of data version control. By narrowing our focus, we were able to better serve the needs of the data ops experience while continuing to support a general git metaphor. The key difference between the two is that Nessie does not support disconnected copies. This allows several other dimensions to be substantially more powerful. Key differences \u00b6 Dimension Git Nessie Rationale Clones Allowed Not Allowed This is the biggest difference between Nessie and Git. Git is a distributed version control system, Nessie is not. This is appropriate in the context of Nessie\u2019s role as an RPS . When talking about Cloud Data ops, everyone does not get their own copy of data\u2013the datasets are typically large and centralized. Because Nessie is layered on top of those shared datasets, clones make less sense. In the Nessie world, using personal branches provides a similar mechanism while keeping a shared world view of what can be managed for GC policies, etc. Speed (commits/second)) <1 hundreds to thousands When we started working on Nessie, we actually tried to use Git. We evaluated Git directly, implemented a version that used JGit (used by tools like Gerrit and Eclipse) as well as explored the capabilities of GitHub, Azure Git and AWS Git. What we saw was a fairly expensive operation. Typically, a single commit operation took on the order of a few seconds. Scale 100s MB Unconstrained While there are multiple examples of larger or higher performance Git implementations ( 1 , 2 ) , in general Git repositories are fairly small in size. Things like Git LFS were created to help accommodate this but given the nature of clones, large repositories are frowned upon. Because Nessie provides a centralized repository, typical repository constraints do not apply. History Thousands Billions Nessie supports optional garbage collection of historical commits based on user-defined rules to reduce storage consumption. Committer Human Human & Machine Git was designed for human time: commits happen 100-1000s of times a day, not 100x per second. Data in many systems is changing very frequently (especially when you consider a large number of tables). These systems are frequently driven by automated scripts Objects Files Tables & Views Nessie is focused on tracking versions of tables using a well-known set of open table formats. Nessie\u2019s capabilities are integrated into the particular properties of these formats. Git is focused on the generalized problem of tracking arbitrary files (buckets of bytes). Nessie on Git? \u00b6 While we describe the reasoning and differences above, we actually support running Nessie on top of Git. In fact, the first version of Nessie was built on top of Git. Once implemented, we then evaluated it against one of our key design criterion. This design criterion was to support commits in the situation where there are 100,000 tables and each table is changing every 5 minutes. (For reference, the 5 minutes comes from community guidance on commit speed per table for Iceberg. The 100,000 tables comes from various users we\u2019ve worked with before.) The math for this comes out to ~333 commits/second. 333 Commits/second? \u00b6 Using the design goal above, we looked at the major Git service providers to evaluate their performance. We saw an average commit turn-around speed of 1-5/s for most services (GitHub, Azure Git, AWS Git, etc.). Worse case commit latency were >20s for a single commit. Given this initial result, things were not looking good. We took one more attempt to try to achieve the performance requirements using Git. We built a custom storage mechanism for the awesome JGit library . This showed better promise, providing up to 20/commits second when run against DynamoDB. However, it was still insufficient. As such, we ultimately built our own commit kernel to power Nessie. In Nessie, we do not continue to include a backing store built on top of JGit. So Which is Better \u00b6 Like all engineering solutions, this isn\u2019t about what is better, only what is better for a certain use case. Git is good at generalized version control. Nessie is good at data version control. Nessie vs DVC \u00b6 DVC is a popular package within ML community that is described as \u201cVersion Control System for Machine Learning Projects\u201d it presents. While both Nessie and DVC are focused on data, DVC is focused on smaller datasets and maintaining the distributed capabilities of Git. This works great for individual projects that are typically run on single workstations where datasets can be replicated. Nessie works at a table and metadata level specifically focused on data management problems.","title":"Nessie vs Git"},{"location":"develop/nessie_vs_git/#nessie-vs-git","text":"Git is awesome. Nessie was inspired by Git but makes very different tradeoffs. Nessie focuses on the specific use case of data version control. By narrowing our focus, we were able to better serve the needs of the data ops experience while continuing to support a general git metaphor. The key difference between the two is that Nessie does not support disconnected copies. This allows several other dimensions to be substantially more powerful.","title":"Nessie vs Git"},{"location":"develop/nessie_vs_git/#key-differences","text":"Dimension Git Nessie Rationale Clones Allowed Not Allowed This is the biggest difference between Nessie and Git. Git is a distributed version control system, Nessie is not. This is appropriate in the context of Nessie\u2019s role as an RPS . When talking about Cloud Data ops, everyone does not get their own copy of data\u2013the datasets are typically large and centralized. Because Nessie is layered on top of those shared datasets, clones make less sense. In the Nessie world, using personal branches provides a similar mechanism while keeping a shared world view of what can be managed for GC policies, etc. Speed (commits/second)) <1 hundreds to thousands When we started working on Nessie, we actually tried to use Git. We evaluated Git directly, implemented a version that used JGit (used by tools like Gerrit and Eclipse) as well as explored the capabilities of GitHub, Azure Git and AWS Git. What we saw was a fairly expensive operation. Typically, a single commit operation took on the order of a few seconds. Scale 100s MB Unconstrained While there are multiple examples of larger or higher performance Git implementations ( 1 , 2 ) , in general Git repositories are fairly small in size. Things like Git LFS were created to help accommodate this but given the nature of clones, large repositories are frowned upon. Because Nessie provides a centralized repository, typical repository constraints do not apply. History Thousands Billions Nessie supports optional garbage collection of historical commits based on user-defined rules to reduce storage consumption. Committer Human Human & Machine Git was designed for human time: commits happen 100-1000s of times a day, not 100x per second. Data in many systems is changing very frequently (especially when you consider a large number of tables). These systems are frequently driven by automated scripts Objects Files Tables & Views Nessie is focused on tracking versions of tables using a well-known set of open table formats. Nessie\u2019s capabilities are integrated into the particular properties of these formats. Git is focused on the generalized problem of tracking arbitrary files (buckets of bytes).","title":"Key differences"},{"location":"develop/nessie_vs_git/#nessie-on-git","text":"While we describe the reasoning and differences above, we actually support running Nessie on top of Git. In fact, the first version of Nessie was built on top of Git. Once implemented, we then evaluated it against one of our key design criterion. This design criterion was to support commits in the situation where there are 100,000 tables and each table is changing every 5 minutes. (For reference, the 5 minutes comes from community guidance on commit speed per table for Iceberg. The 100,000 tables comes from various users we\u2019ve worked with before.) The math for this comes out to ~333 commits/second.","title":"Nessie on Git?"},{"location":"develop/nessie_vs_git/#333-commitssecond","text":"Using the design goal above, we looked at the major Git service providers to evaluate their performance. We saw an average commit turn-around speed of 1-5/s for most services (GitHub, Azure Git, AWS Git, etc.). Worse case commit latency were >20s for a single commit. Given this initial result, things were not looking good. We took one more attempt to try to achieve the performance requirements using Git. We built a custom storage mechanism for the awesome JGit library . This showed better promise, providing up to 20/commits second when run against DynamoDB. However, it was still insufficient. As such, we ultimately built our own commit kernel to power Nessie. In Nessie, we do not continue to include a backing store built on top of JGit.","title":"333 Commits/second?"},{"location":"develop/nessie_vs_git/#so-which-is-better","text":"Like all engineering solutions, this isn\u2019t about what is better, only what is better for a certain use case. Git is good at generalized version control. Nessie is good at data version control.","title":"So Which is Better"},{"location":"develop/nessie_vs_git/#nessie-vs-dvc","text":"DVC is a popular package within ML community that is described as \u201cVersion Control System for Machine Learning Projects\u201d it presents. While both Nessie and DVC are focused on data, DVC is focused on smaller datasets and maintaining the distributed capabilities of Git. This works great for individual projects that are typically run on single workstations where datasets can be replicated. Nessie works at a table and metadata level specifically focused on data management problems.","title":"Nessie vs DVC"},{"location":"develop/python/","text":"Python \u00b6 # using python 3 pip install pynessie Configuration \u00b6 When you install pynessie, you get the Python client along with a Python CLI. Configuration for both is covered in our reference for the command line interface . Usage \u00b6 To instantiate a client simply run from pynessie import init client = init () # this will look for the client config as per above branches = client . list_branches () print ( branches ) All endpoint options are available from this client. Spark usage from Python \u00b6 A common way to interact with Nessie is via Spark. You can read more about working with Nessie, Spark and Iceberg together on our Iceberg Client docs page. API Documentation \u00b6 API docs are hosted on readthedocs","title":"Python"},{"location":"develop/python/#python","text":"# using python 3 pip install pynessie","title":"Python"},{"location":"develop/python/#configuration","text":"When you install pynessie, you get the Python client along with a Python CLI. Configuration for both is covered in our reference for the command line interface .","title":"Configuration"},{"location":"develop/python/#usage","text":"To instantiate a client simply run from pynessie import init client = init () # this will look for the client config as per above branches = client . list_branches () print ( branches ) All endpoint options are available from this client.","title":"Usage"},{"location":"develop/python/#spark-usage-from-python","text":"A common way to interact with Nessie is via Spark. You can read more about working with Nessie, Spark and Iceberg together on our Iceberg Client docs page.","title":"Spark usage from Python"},{"location":"develop/python/#api-documentation","text":"API docs are hosted on readthedocs","title":"API Documentation"},{"location":"develop/rest/","text":"Rest API \u00b6 Nessie\u2019s REST APIs are how all applications interact with Nessie. The APIs are specified according to the openapi v3 standard and are available when running the server by going to localhost:19120/q/openapi . You can also peruse the set of operations our APIs support by going to SwaggerHub . If you are working in development, our Quarkus server will automatically start with the swagger-ui for experimentation. You can find that at localhost:19120/q/swagger-ui/","title":"Rest API"},{"location":"develop/rest/#rest-api","text":"Nessie\u2019s REST APIs are how all applications interact with Nessie. The APIs are specified according to the openapi v3 standard and are available when running the server by going to localhost:19120/q/openapi . You can also peruse the set of operations our APIs support by going to SwaggerHub . If you are working in development, our Quarkus server will automatically start with the swagger-ui for experimentation. You can find that at localhost:19120/q/swagger-ui/","title":"Rest API"},{"location":"develop/spec/","text":"Nessie Specification \u00b6 This page documents the complete Nessie specification. This includes: API and its constraints Contract for value objects API contract \u00b6 The Nessie API is used by Nessie integrations within for example Apache Iceberg or Delta Lake and user facing applications like Web UIs. Nessie defines a REST API (OpenAPI) and implementations for Java and Python . Content managed by Nessie \u00b6 General Contract \u00b6 Content Objects describe the state of a data lake object like a table or view. Nessie currently provides types for Iceberg tables, Delta Lake tables and Iceberg views. Nessie uses two identifiers for a single Content object: The Content Id is used to identify a content object across all branches even if the content object is being referred to using different table or view names. The Content Key is used to look up a content object by name, like a table name or view name. The Content Key changes when the associated table or view is renamed. Content Key \u00b6 The Content Key consists of multiple strings and is used to resolve a symbolic name, like a table name or a view name used in SQL statements, to a Content object. When a table or view is renamed using for example an SQL ALTER TABLE RENAME operation, Nessie will record this operation using a remove operation on the old key plus a put operation on the new key ( see below ). On Reference State vs Global State \u00b6 Nessie is designed to support multiple table formats like Apache Iceberg or Delta Lake. Since different Nessie commits, think: on different branches in Nessie, can refer to the same physical table but with different state of the data and potentially different schema, some table formats require Nessie to refer to a single Global State . IDs of the Iceberg snapshot , Iceberg schema , Iceberg partition spec , Iceberg sort order within the Iceberg table metadata are also stored per Nessie named reference (branch or tag), as the so-called on-reference-state . Note The term all information in all Nessie commits used above precisely means all information in all Nessie commits that are considered \u201clive\u201d , have not been garbage-collected by Nessie. See also Management Services . Content Id \u00b6 All contents object must have an id field. This field is unique to the object and immutable once created. By convention, it is a UUID though this is not enforced by this Specification. There are several expectations on this field: Content Ids are immutable. Once created the object will keep the same id for its entire lifetime. If the object is moved (e.g. stored under a different Key ) it will keep the id. The same content object, i.e. the same content-id, can be referred to using different keys on different branches. There is no API to look up an object by id and the intention of an id is not to serve in that capacity. An example usage of the id field might be storing auxiliary data on an object in a local cache and using id to look up that auxiliary data. Note A note about caching: The Content objects or the values of the referred information (e.g. schema, partitions etc.) might be cached locally by services using Nessie. For content types that do not track Global State , the hash of the contents object does uniquely reference an object in the Nessie history and is a suitable key to identify an object at a particular point in its history. Evolution of the Global State is performed in a way that keeps old contents resp. contents on different branches (and tags) available. This is the case for Apache Iceberg. Content types that do track Global State , the Content Id must be included in the cache key. For simplicity, it is recommeded to always include the Content Id. Since the Content object is immutable, the hash is stable and since it is disconnected from Nessie\u2019s version store properties it exists across commits/branches and survives GC and other table maintenance operations. The commit hash on the other hand makes a poor cache key because multiple commits can refer to the same state of a Content object, e.g. a merge or transplant will change the commit hash but not the state of the Content object. Content Types \u00b6 Nessie is designed to support various table formats, and currently supports the following types. See also Tables & Views . Iceberg Table \u00b6 Apache Iceberg describes any table using the so called table metadata , see Iceberg Table Spec . Each Iceberg operation that modifies data, for example an append or rewrite operation or more generally each Iceberg transaction, creates a new Iceberg snapshot. Any Nessie commit refers to a particular Iceberg snapshot for an Iceberg table, which translates to the state of an Iceberg table for a particular Nessie commit. The Nessie IcebergTable object passed to Nessie in a Put operation therefore consists of the pointer to the Iceberg table metadata and the IDs of the Iceberg snapshot , Iceberg schema , Iceberg partition spec , Iceberg sort order within the Iceberg table metadata . (so-called On Reference State ) Note This model puts a strong restriction on the Iceberg table. All metadata JSON documents must be stored and none of the built-in iceberg maintenance procedures can be used. There are potentially serious issues regarding schema migrations in this model as well. Therefore, the Iceberg table spec should be considered subject to change in the near future. Iceberg View \u00b6 Note Iceberg Views are experimental and subject to change! The state of an Iceberg view is represented using the attributes versionId , schemaId , sqlText and dialect . Iceberg views are handled similar to Iceberg Tables . Delta Lake Table \u00b6 The state of a Delta Lake Table is represented using the Delta Lake Table attributes metadataLocationHistory , checkpointLocationHistory and lastCheckpoint . Delta Lake Tables are tracked without a Global State in Nessie, i.e. those three attributes are recorded within the Put Operation of a Nessie commit. Operations in a Nessie commit \u00b6 Each Nessie commit carries one or more operations. Each operation contains the Content Key and is either a Put , Delete or Unmodified operation. A Content Key must only occur once in a Nessie commit. Operations present in a commit are passed into Nessie as a list of operations. Mapping SQL DDL to Nessie commit operations \u00b6 A CREATE TABLE is mapped to one Put operation . An ALTER TABLE RENAME is mapped to a Delete operation using the Content Key for the table being renamed plus at least one Put operation using the Content Key of the table\u2019s new name, using the Content Id of the table being renamed. A DROP TABLE is represented as a Nessie Delete operation (without a Put operation for the same Content Id). A DROP TABLE + CREATE TABLE using the same table name (Content Key) in a single commit are mapped to one Put operation with a different Content Id. Put operation \u00b6 A Put operation modifies the state of the included Content object. It must contain the Content object and, if the Put operation modifies an existing content object, also the the expected contents . The expected contents attribute can be omitted, if the Content object refers to a new Content Id, e.g. a newly created table or view. See also Conflict Resolution . A Nessie Put operation is created for everything that modifies a table or a view, either its definition (think: SQL DDL) or data (think: SQL DML). Delete operation \u00b6 A Delete operation does not carry any Content object and is used to indicate that a Content object is no longer referenced using the Content Key of the Delete operation . Unmodified operation \u00b6 An Unmodified operation does not represent any change of the data, but can be included in a Nessie commit operation to enforce strict serializable transactions. The presence of an Unmodified operation means that the Content object referred to via the operation\u2019s Content Key must not have been modified since the Nessie commit\u2019s expectedHash . The Unmodified operation is not persisted. Version Store \u00b6 See Commit Kernel for details. Conflict Resolution \u00b6 The API passes an expectedHash parameter with a Nessie commit operation. This is the commit that the client thinks is the most up to date (its HEAD). The Nessie backend will check to see if the key has been modified since that expectedHash and if so, it will reject the requested modification with a NessieConflictException . This is basically an optimistic lock that accounts for the fact that the commit hash is global and nessie branch could have moved on from expectedHash without modifying the key in question. A Nessie Put operation that updates an existing content object must pass the so-called expected state , which might be used to compare the current recorded state of a content object with the state in the expected state in the Put operation . If both values differ, Nessie will reject the operation with a NessieConflictException . The reason for these conditions is to behave like a \u2018real\u2019 database. You shouldn\u2019t have to update your reference before transacting on table A because it just happened to update table B whilst you were preparing your transaction.","title":"Nessie Specification"},{"location":"develop/spec/#nessie-specification","text":"This page documents the complete Nessie specification. This includes: API and its constraints Contract for value objects","title":"Nessie Specification"},{"location":"develop/spec/#api-contract","text":"The Nessie API is used by Nessie integrations within for example Apache Iceberg or Delta Lake and user facing applications like Web UIs. Nessie defines a REST API (OpenAPI) and implementations for Java and Python .","title":"API contract"},{"location":"develop/spec/#content-managed-by-nessie","text":"","title":"Content managed by Nessie"},{"location":"develop/spec/#general-contract","text":"Content Objects describe the state of a data lake object like a table or view. Nessie currently provides types for Iceberg tables, Delta Lake tables and Iceberg views. Nessie uses two identifiers for a single Content object: The Content Id is used to identify a content object across all branches even if the content object is being referred to using different table or view names. The Content Key is used to look up a content object by name, like a table name or view name. The Content Key changes when the associated table or view is renamed.","title":"General Contract"},{"location":"develop/spec/#content-key","text":"The Content Key consists of multiple strings and is used to resolve a symbolic name, like a table name or a view name used in SQL statements, to a Content object. When a table or view is renamed using for example an SQL ALTER TABLE RENAME operation, Nessie will record this operation using a remove operation on the old key plus a put operation on the new key ( see below ).","title":"Content Key"},{"location":"develop/spec/#on-reference-state-vs-global-state","text":"Nessie is designed to support multiple table formats like Apache Iceberg or Delta Lake. Since different Nessie commits, think: on different branches in Nessie, can refer to the same physical table but with different state of the data and potentially different schema, some table formats require Nessie to refer to a single Global State . IDs of the Iceberg snapshot , Iceberg schema , Iceberg partition spec , Iceberg sort order within the Iceberg table metadata are also stored per Nessie named reference (branch or tag), as the so-called on-reference-state . Note The term all information in all Nessie commits used above precisely means all information in all Nessie commits that are considered \u201clive\u201d , have not been garbage-collected by Nessie. See also Management Services .","title":"On Reference State vs Global State"},{"location":"develop/spec/#content-id","text":"All contents object must have an id field. This field is unique to the object and immutable once created. By convention, it is a UUID though this is not enforced by this Specification. There are several expectations on this field: Content Ids are immutable. Once created the object will keep the same id for its entire lifetime. If the object is moved (e.g. stored under a different Key ) it will keep the id. The same content object, i.e. the same content-id, can be referred to using different keys on different branches. There is no API to look up an object by id and the intention of an id is not to serve in that capacity. An example usage of the id field might be storing auxiliary data on an object in a local cache and using id to look up that auxiliary data. Note A note about caching: The Content objects or the values of the referred information (e.g. schema, partitions etc.) might be cached locally by services using Nessie. For content types that do not track Global State , the hash of the contents object does uniquely reference an object in the Nessie history and is a suitable key to identify an object at a particular point in its history. Evolution of the Global State is performed in a way that keeps old contents resp. contents on different branches (and tags) available. This is the case for Apache Iceberg. Content types that do track Global State , the Content Id must be included in the cache key. For simplicity, it is recommeded to always include the Content Id. Since the Content object is immutable, the hash is stable and since it is disconnected from Nessie\u2019s version store properties it exists across commits/branches and survives GC and other table maintenance operations. The commit hash on the other hand makes a poor cache key because multiple commits can refer to the same state of a Content object, e.g. a merge or transplant will change the commit hash but not the state of the Content object.","title":"Content Id"},{"location":"develop/spec/#content-types","text":"Nessie is designed to support various table formats, and currently supports the following types. See also Tables & Views .","title":"Content Types"},{"location":"develop/spec/#iceberg-table","text":"Apache Iceberg describes any table using the so called table metadata , see Iceberg Table Spec . Each Iceberg operation that modifies data, for example an append or rewrite operation or more generally each Iceberg transaction, creates a new Iceberg snapshot. Any Nessie commit refers to a particular Iceberg snapshot for an Iceberg table, which translates to the state of an Iceberg table for a particular Nessie commit. The Nessie IcebergTable object passed to Nessie in a Put operation therefore consists of the pointer to the Iceberg table metadata and the IDs of the Iceberg snapshot , Iceberg schema , Iceberg partition spec , Iceberg sort order within the Iceberg table metadata . (so-called On Reference State ) Note This model puts a strong restriction on the Iceberg table. All metadata JSON documents must be stored and none of the built-in iceberg maintenance procedures can be used. There are potentially serious issues regarding schema migrations in this model as well. Therefore, the Iceberg table spec should be considered subject to change in the near future.","title":"Iceberg Table"},{"location":"develop/spec/#iceberg-view","text":"Note Iceberg Views are experimental and subject to change! The state of an Iceberg view is represented using the attributes versionId , schemaId , sqlText and dialect . Iceberg views are handled similar to Iceberg Tables .","title":"Iceberg View"},{"location":"develop/spec/#delta-lake-table","text":"The state of a Delta Lake Table is represented using the Delta Lake Table attributes metadataLocationHistory , checkpointLocationHistory and lastCheckpoint . Delta Lake Tables are tracked without a Global State in Nessie, i.e. those three attributes are recorded within the Put Operation of a Nessie commit.","title":"Delta Lake Table"},{"location":"develop/spec/#operations-in-a-nessie-commit","text":"Each Nessie commit carries one or more operations. Each operation contains the Content Key and is either a Put , Delete or Unmodified operation. A Content Key must only occur once in a Nessie commit. Operations present in a commit are passed into Nessie as a list of operations.","title":"Operations in a Nessie commit"},{"location":"develop/spec/#mapping-sql-ddl-to-nessie-commit-operations","text":"A CREATE TABLE is mapped to one Put operation . An ALTER TABLE RENAME is mapped to a Delete operation using the Content Key for the table being renamed plus at least one Put operation using the Content Key of the table\u2019s new name, using the Content Id of the table being renamed. A DROP TABLE is represented as a Nessie Delete operation (without a Put operation for the same Content Id). A DROP TABLE + CREATE TABLE using the same table name (Content Key) in a single commit are mapped to one Put operation with a different Content Id.","title":"Mapping SQL DDL to Nessie commit operations"},{"location":"develop/spec/#put-operation","text":"A Put operation modifies the state of the included Content object. It must contain the Content object and, if the Put operation modifies an existing content object, also the the expected contents . The expected contents attribute can be omitted, if the Content object refers to a new Content Id, e.g. a newly created table or view. See also Conflict Resolution . A Nessie Put operation is created for everything that modifies a table or a view, either its definition (think: SQL DDL) or data (think: SQL DML).","title":"Put operation"},{"location":"develop/spec/#delete-operation","text":"A Delete operation does not carry any Content object and is used to indicate that a Content object is no longer referenced using the Content Key of the Delete operation .","title":"Delete operation"},{"location":"develop/spec/#unmodified-operation","text":"An Unmodified operation does not represent any change of the data, but can be included in a Nessie commit operation to enforce strict serializable transactions. The presence of an Unmodified operation means that the Content object referred to via the operation\u2019s Content Key must not have been modified since the Nessie commit\u2019s expectedHash . The Unmodified operation is not persisted.","title":"Unmodified operation"},{"location":"develop/spec/#version-store","text":"See Commit Kernel for details.","title":"Version Store"},{"location":"develop/spec/#conflict-resolution","text":"The API passes an expectedHash parameter with a Nessie commit operation. This is the commit that the client thinks is the most up to date (its HEAD). The Nessie backend will check to see if the key has been modified since that expectedHash and if so, it will reject the requested modification with a NessieConflictException . This is basically an optimistic lock that accounts for the fact that the commit hash is global and nessie branch could have moved on from expectedHash without modifying the key in question. A Nessie Put operation that updates an existing content object must pass the so-called expected state , which might be used to compare the current recorded state of a content object with the state in the expected state in the Put operation . If both values differ, Nessie will reject the operation with a NessieConflictException . The reason for these conditions is to behave like a \u2018real\u2019 database. You shouldn\u2019t have to update your reference before transacting on table A because it just happened to update table B whilst you were preparing your transaction.","title":"Conflict Resolution"},{"location":"features/","text":"About Nessie \u00b6 Nessie is to Data Lakes what Git is to source code repositories. Therefore, Nessie uses many terms from both Git and data lakes. This page explains how Nessie makes working with data in data lakes much easier without requiring much prior knowledge of either Git or data lakes. Nessie is designed to give users an always-consistent view of their data across all involved data sets (tables). Changes to your data, for example from batch jobs, happen independently and are completely isolated. Users will not see any incomplete changes. Once all the changes are done, all the changes can be atomically and consistently applied and become visible to your users. Nessie completely eliminates the hard and often manual work required to keep track of the individual data files. Nessie knows which data files are being used and which data files can safely be deleted. Production, staging and development environments can use the same data lake without risking the consistent state of production data. Nessie does not copy your data, instead it references the existing data, which works fine, because data files 1 are immutable. Nessie 101 \u00b6 Changes to the contents of the data lake are recorded in Nessie as commits without copying the actual data. Add meaning to the changes to your data lake. Always-consistent view to all the data. Sets of changes, like the whole work of a distributed Spark job . or experiments of data engineers are isolated in Nessie via branches . Failed jobs do not add additional harm to the data. Known, fixed versions of all data can be tagged . Automatic removal of unused data files ( garbage collection ). Data Lake 101 \u00b6 \u201cA data lake is a system or repository of data stored in its natural/raw format, usually object blobs or files.\u201d (cite from Wikipedia ) Data is stored in immutable data files 1 . Each data file defines the schema of the data (i.e. names and types of the columns) and contains the data. A single, logical table (for example a customers or a bank_account_transactions table) consists of many data files. A common (mis)understanding of Data Lakes is \u201cthrow everything in and see what happens\u201d. This might work for some time, leaving data, especially large amounts of data, unorganized is a rather bad idea. A common best-practice is still to properly organize the (immutable) data files in directories that reflect both organizational (think: units/groups in your company) and structural (think: table schema) aspects. New data files can be added to the set of files for a particular table. Data files can also contain updates to and deletions of existing data. For example: if you need to make changes to the data in data-file A , you basically have to read that data-file, apply the changes and write a new data-file A' with the changes, which makes data-file A irrelevant. The amount of data held in data lakes is rather huge (GBs, TBs, PBs), and so is the number of tables and data files (100s of thousands, millions). Managing that amount of data and data files while keeping track of schema changes, for example adding or removing a column, changing a column\u2019s type, renaming a column in a table and views, is one of the things that Nessie tackles. Data in a data lake is usually consumed and written using tools like Apache Hive 2 or Apache Spark 2 . Your existing jobs can easily integrate Nessie without any production code changes, it\u2019s a simple configuration change. Git 101 \u00b6 \u201cGit is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency\u201d (cite from git-scm.com ) Git maintains the history or all changes of a software project from the very first commit until the current state. Git is used by humans, i.e. developers. Many of the concepts of Git for source code are implemented by Nessie for all the data in your data lake. It would be rather confusing to explain all Git concepts here and then outline the differences in the next chapter. If you want to learn more about Git, we recommend looking this Git book (available in many languages) or the About Git pages as a quick start. Terms summary \u00b6 Term Meaning in Nessie Commit An atomic change to a set of data files. Hash Nessie-commits are identified by a commit id. 3 (Multi-table) transaction Since a Nessie commit can group data data files from many tables, you can think of a Nessie commit as a (multi-table) transaction. Branch Named reference to a commit. A new commit to a branch updates the branch to the new commit. Tag Named reference to a commit. Not automatically changed. Merge Combination of two commits. Usually applies the changes of one source-branch onto another target-branch. Working with data in Nessie \u00b6 Each individual state in Nessie is defined by a Nessie commit . Each commit in Nessie, except the very first one, has references to its predecessor, the previous versions of the data. For those who know Git and merge-commits: One important difference of Nessie-merges is that Nessie-commits have only one parent (predecessor). Nessie-merge operations technically work a bit different: the changes in branch to be merged are replayed on top of the target branch. Each Nessie commit also indirectly \u201cknows\u201d about the data files (via some metadata) in your data lake, which represent the state of all data in all tables. The following example illustrates that our current commit adds a 3 rd data file. The other two data files 1+2 have been added by previous commit . +-------------------+ +-------------------------+ | previous commit | --<-- | current commit | +-------------------+ +-------------------------+ | | | | | (add) (add) | | (add) | | | | | +------+ +------+ +------+ +------+ +------+ | data | | data | | data | | data | | data | | file | | file | | file | | file | | file | | #1 | | #2 | | #1 | | #2 | | #3 | | _| | _| | _| | _| | _| | __/ | __/ | __/ | __/ | __/ |_/ |_/ |_/ |_/ |_/ In \u201crelational SQL\u201d you can think of the following sequence of SQL statements: BEGIN TRANSACTION ; -- The data for data file #1 INSERT INTO table_one (...) VALUES (...); -- The data for data file #2 INSERT INTO other_table (...) VALUES (...); -- creates our \"previous commit\" COMMIT TRANSACTION ; BEGIN TRANSACTION ; -- Data added to 'table_one' will \"land\" in a new data file #3, because -- data files are immutable. INSERT INTO table_one (...) VALUES (...); -- Creates our \"current commit\" COMMIT TRANSACTION ; Each commit is identified by a sequence of hexadecimal characters like 2898591840e992ec5a7d5c811c58c8b42a8e0d0914f86a37badbeedeadaffe 3 , which is not easy to read and remember for us humans. Transaction in Nessie \u00b6 The term \u201ctransaction\u201d has different meanings to different people coming from different backgrounds. It is probably fair to say that, in general, a transaction is a group of changes applied to some data. The term \u201ctransaction\u201d alone does not define any guarantees. Different systems provide different guarantees, for example whether (or: when) changes performed in a transaction become visible to others, whether (parts of) the data gets locked, and so on. Relational database systems (RDBMS) for example usually provide certain levels of isolation (think: others cannot see uncommitted changes) and also ensure that either a change within a transaction succeeds, the request times out or fails straight away. Relational databases have a single and central transaction-coordinator 4 and are designed to always provide a consistent data set. The smallest atomic change in Nessie is a single commit. It is fair to say, that a commit is the smallest possible transaction in Nessie. A single Nessie commit in Nessie: \u2026 can be \u201cjust\u201d the set of changes of a single worker out of many distributed workers. \u2026 can cover a quite small change or cover a huge amount of changes and/or huge amount of changed data or even group many Nessie commits into an atomic merge operation (think: a transaction over many transactions). The major difference between \u201cNessie\u2019s (distributed) transactions\u201d and transactions in a relational database is that Nessie\u2019s concept of having multiple commits plus the concept of merging one branch into another branch provides a lot of flexibility. Branches \u00b6 Nessie uses the concept of \u201cbranches\u201d to always reference the latest version in a chain of commits. Our example branch is named \u201cmain\u201d and has just a single commit: +-------------+ | commit #1 | +-------------+ ^ | | \"main\" branch When we add changes to our \u201cmain\u201d branch, a new commit #2 will be created: the new commit #2 will reference commit #1 as its predecessor and the named reference \u201cmain\u201d will be updated to point to our new commit #2 +-------------+ +-------------+ | commit #1 | --<-- | commit #2 | +-------------+ +-------------+ ^ | | \"main\" branch This behavior ensures that the named reference \u201cmain\u201d always points to the very latest version of our data. Working-branches for analytics jobs \u00b6 The above example with a single branch works well, if all changes to all tables can be grouped into a single commit. In a distributed world, computational work is distributed across many machines running many processes. All these individual tasks generate commits, but only the \u201csum\u201d of all commits from all the tasks represents a consistent state. If all the tasks of a job would directly commit onto our \u201cmain\u201d branch, the \u201cmain\u201d branch would be inconsistent at least until not all tasks have finished. Further, if the whole job fails, it would be hard to roll back the changes, especially if other jobs are running. Last but not least, the \u201cmain\u201d branch would contain a lot of commits (for example job#213, task#47346, add 1234 rows to table x ), which do not make a lot of sense on their own, but a single commit (for example aggregate-financial-stuff 2020/12/24 ) would. To get around that issue, jobs can create a new \u201cwork\u201d-branch when they start. The results from all tasks of a job are recorded as individual commits into that \u201cwork\u201d-branch. Once the job has finished, all changes are then merged into the \u201cmain\u201d branch at once. \"work\" branch | | v +-----------+ | commit #1 | +-----------+ ^ | | \"main\" branch Our example Spark job has two tasks, each generates a separate commit, which are only visible on our \u201cwork\u201d-branch: task#1 task#2 \"work\" result result branch | | | v v v +-----------+ +-----------+ | commit #2 | --<-- | commit #3 | +-----------+ +-----------+ | v | +-----------+ | commit #1 | +-----------+ ^ | | \"main\" branch When the job has finished, you can merge the now consistent result back into the \u201cmain\u201d-branch. task#1 task#2 \"work\" result result branch | | | v v v +-----------+ +-----------+ | commit #2 | --<-- | commit #3 | +-----------+ +-----------+ | | v ^ | | +-----------+ +-----------+ | commit #1 | --------<---------- | commit #4 | +-----------+ +-----------+ ^ | | \"main\" branch Technically, Nessie replays commit #2 and commit #3 on top of the most-recent commit of the \u201cmain\u201d branch. For those who know Git and merge-commits: One important difference of Nessie-merges is that Nessie-commits have only one parent (predecessor). Nessie-merge operations technically work a bit different: the changes in branch to be merged are replayed on top of the target branch. It is recommended to give a commit a meaningful commit message and to let someone review the changes . As described above in Transactions in Nessie , the merge operation in the above example can be considered a Nessie distributed transaction . Working branches for \u201chumans\u201d \u00b6 You can also use \u201cdeveloper\u201d branches to run experiments against your data, test changes of your jobs etc. Production, staging and development environments can use the same data lake without risking the consistent state of production data. Squashing \u00b6 Nessie can not yet squash commits. Tags \u00b6 Another type of named references are tags . Nessie tags are named references to specific commits. Tags do always point to the same commit and won\u2019t be changed automatically. This means, that tags are useful to reference specific commits, for example a tag named financial-data-of-FY2021 could reference all sources of financial data relevant used for some financial year report. See Git tags for comparison and to learn how tagging works in Git. Commit messages and more \u00b6 As briefly mentioned above, every commit in Nessie has a set of attributes. Some of the more important ones are \u201csummary\u201d and \u201cdescription\u201d, which are exactly that - meaningful summaries and detailed descriptions that explain what has been changed and why it has been changed. In addition to \u201csummary\u201d and \u201cdescription\u201d, there are a bunch of additional attributes as shown in the following table. We plan to add more structure to these attributes in the future. Attribute Meaning in Nessie commit timestamp The timestamp when the commit was recorded in Nessie. committer The one (human user, system id) that actually recorded the change in Nessie. author timestamp the timestamp when a change has been implemented (can be different from the commit timestamp). author The one (human user, system id) that authored the change, can be different if someone else actually commits the change to Nessie. summary A short, one-line meaningful summary of the changes. description potentially long description of the changes. \u2026 There are potentially way more attributes, just too many to mention here. Garbage collection \u00b6 Data lakes contain a lot of data. The amount of data has a direct relation to the cost of ownership of a data lake. Keeping all data forever is probably going to be just too expensive, practically not useful and can also collide with data privacy regulations (for example GDPR or CCPA). Nessie keeps track of unused data files and collects the garbage for you. See Table Management Footnotes \u00b6 Common data file formats are Apache Iceberg Tables , Delta Lake Tables \u21a9 \u21a9 Apache, Hive, Spark, Iceberg, Parquet are trademarks of The Apache Software Foundation. \u21a9 \u21a9 Nessie-commits are identified by a commit-id. All commits in Nessie (and in Git) are identified using such a hash. The value of each hash is generated from the relevant contents and attributes of each commit that are stored in Nessie. \u21a9 \u21a9 There are distributed relational databases that are not implemented as a single monolith. Those \u201cproper\u201d distributed relational databases use distributed consensus algorithms like RAFT to provide the same (or even better) guarantees that classic relational databases give. However, the concepts of a classic relational database still apply. \u21a9","title":"About Nessie"},{"location":"features/#about-nessie","text":"Nessie is to Data Lakes what Git is to source code repositories. Therefore, Nessie uses many terms from both Git and data lakes. This page explains how Nessie makes working with data in data lakes much easier without requiring much prior knowledge of either Git or data lakes. Nessie is designed to give users an always-consistent view of their data across all involved data sets (tables). Changes to your data, for example from batch jobs, happen independently and are completely isolated. Users will not see any incomplete changes. Once all the changes are done, all the changes can be atomically and consistently applied and become visible to your users. Nessie completely eliminates the hard and often manual work required to keep track of the individual data files. Nessie knows which data files are being used and which data files can safely be deleted. Production, staging and development environments can use the same data lake without risking the consistent state of production data. Nessie does not copy your data, instead it references the existing data, which works fine, because data files 1 are immutable.","title":"About Nessie"},{"location":"features/#nessie-101","text":"Changes to the contents of the data lake are recorded in Nessie as commits without copying the actual data. Add meaning to the changes to your data lake. Always-consistent view to all the data. Sets of changes, like the whole work of a distributed Spark job . or experiments of data engineers are isolated in Nessie via branches . Failed jobs do not add additional harm to the data. Known, fixed versions of all data can be tagged . Automatic removal of unused data files ( garbage collection ).","title":"Nessie 101"},{"location":"features/#data-lake-101","text":"\u201cA data lake is a system or repository of data stored in its natural/raw format, usually object blobs or files.\u201d (cite from Wikipedia ) Data is stored in immutable data files 1 . Each data file defines the schema of the data (i.e. names and types of the columns) and contains the data. A single, logical table (for example a customers or a bank_account_transactions table) consists of many data files. A common (mis)understanding of Data Lakes is \u201cthrow everything in and see what happens\u201d. This might work for some time, leaving data, especially large amounts of data, unorganized is a rather bad idea. A common best-practice is still to properly organize the (immutable) data files in directories that reflect both organizational (think: units/groups in your company) and structural (think: table schema) aspects. New data files can be added to the set of files for a particular table. Data files can also contain updates to and deletions of existing data. For example: if you need to make changes to the data in data-file A , you basically have to read that data-file, apply the changes and write a new data-file A' with the changes, which makes data-file A irrelevant. The amount of data held in data lakes is rather huge (GBs, TBs, PBs), and so is the number of tables and data files (100s of thousands, millions). Managing that amount of data and data files while keeping track of schema changes, for example adding or removing a column, changing a column\u2019s type, renaming a column in a table and views, is one of the things that Nessie tackles. Data in a data lake is usually consumed and written using tools like Apache Hive 2 or Apache Spark 2 . Your existing jobs can easily integrate Nessie without any production code changes, it\u2019s a simple configuration change.","title":"Data Lake 101"},{"location":"features/#git-101","text":"\u201cGit is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency\u201d (cite from git-scm.com ) Git maintains the history or all changes of a software project from the very first commit until the current state. Git is used by humans, i.e. developers. Many of the concepts of Git for source code are implemented by Nessie for all the data in your data lake. It would be rather confusing to explain all Git concepts here and then outline the differences in the next chapter. If you want to learn more about Git, we recommend looking this Git book (available in many languages) or the About Git pages as a quick start.","title":"Git 101"},{"location":"features/#terms-summary","text":"Term Meaning in Nessie Commit An atomic change to a set of data files. Hash Nessie-commits are identified by a commit id. 3 (Multi-table) transaction Since a Nessie commit can group data data files from many tables, you can think of a Nessie commit as a (multi-table) transaction. Branch Named reference to a commit. A new commit to a branch updates the branch to the new commit. Tag Named reference to a commit. Not automatically changed. Merge Combination of two commits. Usually applies the changes of one source-branch onto another target-branch.","title":"Terms summary"},{"location":"features/#working-with-data-in-nessie","text":"Each individual state in Nessie is defined by a Nessie commit . Each commit in Nessie, except the very first one, has references to its predecessor, the previous versions of the data. For those who know Git and merge-commits: One important difference of Nessie-merges is that Nessie-commits have only one parent (predecessor). Nessie-merge operations technically work a bit different: the changes in branch to be merged are replayed on top of the target branch. Each Nessie commit also indirectly \u201cknows\u201d about the data files (via some metadata) in your data lake, which represent the state of all data in all tables. The following example illustrates that our current commit adds a 3 rd data file. The other two data files 1+2 have been added by previous commit . +-------------------+ +-------------------------+ | previous commit | --<-- | current commit | +-------------------+ +-------------------------+ | | | | | (add) (add) | | (add) | | | | | +------+ +------+ +------+ +------+ +------+ | data | | data | | data | | data | | data | | file | | file | | file | | file | | file | | #1 | | #2 | | #1 | | #2 | | #3 | | _| | _| | _| | _| | _| | __/ | __/ | __/ | __/ | __/ |_/ |_/ |_/ |_/ |_/ In \u201crelational SQL\u201d you can think of the following sequence of SQL statements: BEGIN TRANSACTION ; -- The data for data file #1 INSERT INTO table_one (...) VALUES (...); -- The data for data file #2 INSERT INTO other_table (...) VALUES (...); -- creates our \"previous commit\" COMMIT TRANSACTION ; BEGIN TRANSACTION ; -- Data added to 'table_one' will \"land\" in a new data file #3, because -- data files are immutable. INSERT INTO table_one (...) VALUES (...); -- Creates our \"current commit\" COMMIT TRANSACTION ; Each commit is identified by a sequence of hexadecimal characters like 2898591840e992ec5a7d5c811c58c8b42a8e0d0914f86a37badbeedeadaffe 3 , which is not easy to read and remember for us humans.","title":"Working with data in Nessie"},{"location":"features/#transaction-in-nessie","text":"The term \u201ctransaction\u201d has different meanings to different people coming from different backgrounds. It is probably fair to say that, in general, a transaction is a group of changes applied to some data. The term \u201ctransaction\u201d alone does not define any guarantees. Different systems provide different guarantees, for example whether (or: when) changes performed in a transaction become visible to others, whether (parts of) the data gets locked, and so on. Relational database systems (RDBMS) for example usually provide certain levels of isolation (think: others cannot see uncommitted changes) and also ensure that either a change within a transaction succeeds, the request times out or fails straight away. Relational databases have a single and central transaction-coordinator 4 and are designed to always provide a consistent data set. The smallest atomic change in Nessie is a single commit. It is fair to say, that a commit is the smallest possible transaction in Nessie. A single Nessie commit in Nessie: \u2026 can be \u201cjust\u201d the set of changes of a single worker out of many distributed workers. \u2026 can cover a quite small change or cover a huge amount of changes and/or huge amount of changed data or even group many Nessie commits into an atomic merge operation (think: a transaction over many transactions). The major difference between \u201cNessie\u2019s (distributed) transactions\u201d and transactions in a relational database is that Nessie\u2019s concept of having multiple commits plus the concept of merging one branch into another branch provides a lot of flexibility.","title":"Transaction in Nessie"},{"location":"features/#branches","text":"Nessie uses the concept of \u201cbranches\u201d to always reference the latest version in a chain of commits. Our example branch is named \u201cmain\u201d and has just a single commit: +-------------+ | commit #1 | +-------------+ ^ | | \"main\" branch When we add changes to our \u201cmain\u201d branch, a new commit #2 will be created: the new commit #2 will reference commit #1 as its predecessor and the named reference \u201cmain\u201d will be updated to point to our new commit #2 +-------------+ +-------------+ | commit #1 | --<-- | commit #2 | +-------------+ +-------------+ ^ | | \"main\" branch This behavior ensures that the named reference \u201cmain\u201d always points to the very latest version of our data.","title":"Branches"},{"location":"features/#working-branches-for-analytics-jobs","text":"The above example with a single branch works well, if all changes to all tables can be grouped into a single commit. In a distributed world, computational work is distributed across many machines running many processes. All these individual tasks generate commits, but only the \u201csum\u201d of all commits from all the tasks represents a consistent state. If all the tasks of a job would directly commit onto our \u201cmain\u201d branch, the \u201cmain\u201d branch would be inconsistent at least until not all tasks have finished. Further, if the whole job fails, it would be hard to roll back the changes, especially if other jobs are running. Last but not least, the \u201cmain\u201d branch would contain a lot of commits (for example job#213, task#47346, add 1234 rows to table x ), which do not make a lot of sense on their own, but a single commit (for example aggregate-financial-stuff 2020/12/24 ) would. To get around that issue, jobs can create a new \u201cwork\u201d-branch when they start. The results from all tasks of a job are recorded as individual commits into that \u201cwork\u201d-branch. Once the job has finished, all changes are then merged into the \u201cmain\u201d branch at once. \"work\" branch | | v +-----------+ | commit #1 | +-----------+ ^ | | \"main\" branch Our example Spark job has two tasks, each generates a separate commit, which are only visible on our \u201cwork\u201d-branch: task#1 task#2 \"work\" result result branch | | | v v v +-----------+ +-----------+ | commit #2 | --<-- | commit #3 | +-----------+ +-----------+ | v | +-----------+ | commit #1 | +-----------+ ^ | | \"main\" branch When the job has finished, you can merge the now consistent result back into the \u201cmain\u201d-branch. task#1 task#2 \"work\" result result branch | | | v v v +-----------+ +-----------+ | commit #2 | --<-- | commit #3 | +-----------+ +-----------+ | | v ^ | | +-----------+ +-----------+ | commit #1 | --------<---------- | commit #4 | +-----------+ +-----------+ ^ | | \"main\" branch Technically, Nessie replays commit #2 and commit #3 on top of the most-recent commit of the \u201cmain\u201d branch. For those who know Git and merge-commits: One important difference of Nessie-merges is that Nessie-commits have only one parent (predecessor). Nessie-merge operations technically work a bit different: the changes in branch to be merged are replayed on top of the target branch. It is recommended to give a commit a meaningful commit message and to let someone review the changes . As described above in Transactions in Nessie , the merge operation in the above example can be considered a Nessie distributed transaction .","title":"Working-branches for analytics jobs"},{"location":"features/#working-branches-for-humans","text":"You can also use \u201cdeveloper\u201d branches to run experiments against your data, test changes of your jobs etc. Production, staging and development environments can use the same data lake without risking the consistent state of production data.","title":"Working branches for \"humans\""},{"location":"features/#squashing","text":"Nessie can not yet squash commits.","title":"Squashing"},{"location":"features/#tags","text":"Another type of named references are tags . Nessie tags are named references to specific commits. Tags do always point to the same commit and won\u2019t be changed automatically. This means, that tags are useful to reference specific commits, for example a tag named financial-data-of-FY2021 could reference all sources of financial data relevant used for some financial year report. See Git tags for comparison and to learn how tagging works in Git.","title":"Tags"},{"location":"features/#commit-messages-and-more","text":"As briefly mentioned above, every commit in Nessie has a set of attributes. Some of the more important ones are \u201csummary\u201d and \u201cdescription\u201d, which are exactly that - meaningful summaries and detailed descriptions that explain what has been changed and why it has been changed. In addition to \u201csummary\u201d and \u201cdescription\u201d, there are a bunch of additional attributes as shown in the following table. We plan to add more structure to these attributes in the future. Attribute Meaning in Nessie commit timestamp The timestamp when the commit was recorded in Nessie. committer The one (human user, system id) that actually recorded the change in Nessie. author timestamp the timestamp when a change has been implemented (can be different from the commit timestamp). author The one (human user, system id) that authored the change, can be different if someone else actually commits the change to Nessie. summary A short, one-line meaningful summary of the changes. description potentially long description of the changes. \u2026 There are potentially way more attributes, just too many to mention here.","title":"Commit messages and more"},{"location":"features/#garbage-collection","text":"Data lakes contain a lot of data. The amount of data has a direct relation to the cost of ownership of a data lake. Keeping all data forever is probably going to be just too expensive, practically not useful and can also collide with data privacy regulations (for example GDPR or CCPA). Nessie keeps track of unused data files and collects the garbage for you. See Table Management","title":"Garbage collection"},{"location":"features/#footnotes","text":"Common data file formats are Apache Iceberg Tables , Delta Lake Tables \u21a9 \u21a9 Apache, Hive, Spark, Iceberg, Parquet are trademarks of The Apache Software Foundation. \u21a9 \u21a9 Nessie-commits are identified by a commit-id. All commits in Nessie (and in Git) are identified using such a hash. The value of each hash is generated from the relevant contents and attributes of each commit that are stored in Nessie. \u21a9 \u21a9 There are distributed relational databases that are not implemented as a single monolith. Those \u201cproper\u201d distributed relational databases use distributed consensus algorithms like RAFT to provide the same (or even better) guarantees that classic relational databases give. However, the concepts of a classic relational database still apply. \u21a9","title":"Footnotes"},{"location":"features/best-practices/","text":"Best Practices \u00b6 Commit Messages \u00b6 Give Nessie commits a meaningful commit summary and message, like aggregate-financial-stuff 2020/12/24 , so people that look through the history of the data can grasp what that commit changes and why it\u2019s there. Reviews \u00b6 Before merging manually performed changes back, it is really helpful to let someone else who is familiar with the topic, the changes applied in a work-branch (aka \u201cdevelopment branch\u201d), review the changes.","title":"Best Practices"},{"location":"features/best-practices/#best-practices","text":"","title":"Best Practices"},{"location":"features/best-practices/#commit-messages","text":"Give Nessie commits a meaningful commit summary and message, like aggregate-financial-stuff 2020/12/24 , so people that look through the history of the data can grasp what that commit changes and why it\u2019s there.","title":"Commit Messages"},{"location":"features/best-practices/#reviews","text":"Before merging manually performed changes back, it is really helpful to let someone else who is familiar with the topic, the changes applied in a work-branch (aka \u201cdevelopment branch\u201d), review the changes.","title":"Reviews"},{"location":"features/intro/","text":"Introduction \u00b6 Nessie is an OSS service and libraries that enable you to maintain multiple versions of your data and leverage Git-like Branches & Tags for your Data Lake. Nessie enhances the following table formats with version control techniques: Apache Iceberg Tables ( more ) Delta Lake Tables ( more ) Apache Iceberg Views ( more ) Basic Concepts \u00b6 Nessie is heavily inspired by Git. The main concepts Nessie exposes map directly to Git concepts . In most cases, you simply need to replace references of files and directories in Git with Tables in Nessie. The primary concepts in Nessie are: Commit: Consistent snapshot of all tables at a particular point in time. Branch: Human-friendly reference that a user can add commits to. Tag: Human-friendly reference that points to a particular commit. Hash: Hexadecimal string representation of a particular commit. Out of the box, Nessie starts with a single branch called main that points to the beginning of time. A user can immediately start adding tables to that branch. For example (in pseudocode): $ create t1 ... $ insert 2 records into t1 ... $ create t2 ... $ insert 2 records into t2 ... A user can then use the Nessie CLI to view the history of the main branch. You\u2019ll see that each operation was automatically recorded as a commit within Nessie: $ nessie log hash4 t2 data added hash3 t2 created hash2 t1 data added hash1 t1 created A user can then create a new tag referencing this point in time. After doing so, a user can continue changing the tables but that point in time snapshot will maintain that version of data. $ nessie tag mytag hash4 $ insert records into t1 $ select count(*) from t1 join t2 .. record 1 .. .. record 2 .. .. record 3 .. .. 3 records .. $ select count(*) from t1@mytag join t2@mytag .. record 1 .. .. record 2 .. .. only 2 records .. Data and Metadata \u00b6 Nessie does not make copies of your underlying data. Instead, it works to version separate lists of files associated with your dataset. Whether using Spark or some other tool, each mutation operation you do will add or delete one or more files from the definition of your table. Nessie keeps tracks of which files are related to each of your tables at every point in time and then allows you to recall those as needed. Scale & Performance \u00b6 Nessie is built for very large data warehouses. Nessie supports millions of tables and thousands of commits/second. Because Nessie builds on top of Iceberg and Delta Lake, each table can have millions of files. As such, Nessie can support data warehouses several magnitudes larger than the largest in the world today. This is possible in large part due to the separation of transaction management (Nessie) from table metadata management (Iceberg and Delta Lake). Technology \u00b6 Nessie can be deployed in multiple ways and is composed primarily of the Nessie service, which exposes a set of REST APIs and a simple browser UI. This service works with multiple libraries to expose Nessie\u2019s version control capabilities to common data management technologies. Nessie was built as a Cloud native technology and is designed to be highly scalable, performant and resilient. Built on Java and leveraging Quarkus , it is compiled to a GraalVM native image that starts in less than 20ms. This makes Nessie work very well in Docker and FaaS environments. Nessie has a pluggable storage backend and comes pre-packaged with support for DynamoDB and local storage. License and Governance \u00b6 Nessie is Apache-Licensed and built in an open source, consensus-driven GitHub community. Nessie was originally conceived and built by engineers at Dremio . Getting Started \u00b6 Read more about Nessie transactions Get started with the Nessie quickstart .","title":"Introduction"},{"location":"features/intro/#introduction","text":"Nessie is an OSS service and libraries that enable you to maintain multiple versions of your data and leverage Git-like Branches & Tags for your Data Lake. Nessie enhances the following table formats with version control techniques: Apache Iceberg Tables ( more ) Delta Lake Tables ( more ) Apache Iceberg Views ( more )","title":"Introduction"},{"location":"features/intro/#basic-concepts","text":"Nessie is heavily inspired by Git. The main concepts Nessie exposes map directly to Git concepts . In most cases, you simply need to replace references of files and directories in Git with Tables in Nessie. The primary concepts in Nessie are: Commit: Consistent snapshot of all tables at a particular point in time. Branch: Human-friendly reference that a user can add commits to. Tag: Human-friendly reference that points to a particular commit. Hash: Hexadecimal string representation of a particular commit. Out of the box, Nessie starts with a single branch called main that points to the beginning of time. A user can immediately start adding tables to that branch. For example (in pseudocode): $ create t1 ... $ insert 2 records into t1 ... $ create t2 ... $ insert 2 records into t2 ... A user can then use the Nessie CLI to view the history of the main branch. You\u2019ll see that each operation was automatically recorded as a commit within Nessie: $ nessie log hash4 t2 data added hash3 t2 created hash2 t1 data added hash1 t1 created A user can then create a new tag referencing this point in time. After doing so, a user can continue changing the tables but that point in time snapshot will maintain that version of data. $ nessie tag mytag hash4 $ insert records into t1 $ select count(*) from t1 join t2 .. record 1 .. .. record 2 .. .. record 3 .. .. 3 records .. $ select count(*) from t1@mytag join t2@mytag .. record 1 .. .. record 2 .. .. only 2 records ..","title":"Basic Concepts"},{"location":"features/intro/#data-and-metadata","text":"Nessie does not make copies of your underlying data. Instead, it works to version separate lists of files associated with your dataset. Whether using Spark or some other tool, each mutation operation you do will add or delete one or more files from the definition of your table. Nessie keeps tracks of which files are related to each of your tables at every point in time and then allows you to recall those as needed.","title":"Data and Metadata"},{"location":"features/intro/#scale-performance","text":"Nessie is built for very large data warehouses. Nessie supports millions of tables and thousands of commits/second. Because Nessie builds on top of Iceberg and Delta Lake, each table can have millions of files. As such, Nessie can support data warehouses several magnitudes larger than the largest in the world today. This is possible in large part due to the separation of transaction management (Nessie) from table metadata management (Iceberg and Delta Lake).","title":"Scale &amp; Performance"},{"location":"features/intro/#technology","text":"Nessie can be deployed in multiple ways and is composed primarily of the Nessie service, which exposes a set of REST APIs and a simple browser UI. This service works with multiple libraries to expose Nessie\u2019s version control capabilities to common data management technologies. Nessie was built as a Cloud native technology and is designed to be highly scalable, performant and resilient. Built on Java and leveraging Quarkus , it is compiled to a GraalVM native image that starts in less than 20ms. This makes Nessie work very well in Docker and FaaS environments. Nessie has a pluggable storage backend and comes pre-packaged with support for DynamoDB and local storage.","title":"Technology"},{"location":"features/intro/#license-and-governance","text":"Nessie is Apache-Licensed and built in an open source, consensus-driven GitHub community. Nessie was originally conceived and built by engineers at Dremio .","title":"License and Governance"},{"location":"features/intro/#getting-started","text":"Read more about Nessie transactions Get started with the Nessie quickstart .","title":"Getting Started"},{"location":"features/management/","text":"Management Services \u00b6 Nessie can and needs to manage several operations within your data lake. Each management service can be scheduled and Nessie reports the outcome of each scheduled operation. Scheduled operations require that Nessie have access to a Spark cluster to complete those operations and many of them are distributed compute operations. Garbage Collection \u00b6 Since Nessie is maintaining many versions of metadata and data-pointers simultaneously, you must rely on Nessie to clean up old data. Nessie calls this garbage collection. There are at least two steps to a garbage collection action. The first steps are instructive, and the last step is destructive. Info currently the GC algorithm only works for Iceberg tables and Dynamo as a backend Identify Unreferenced Assets \u00b6 This is a spark job which should be run periodically to identify no longer referenced assets. Assets are defined as the set of files, records, entries etc. that make up a table, view or other Nessie object. For example, iceberg assets are: * manifest files * manifest lists * data files * metadata files * the entire table directory on disk (if it is empty) To be marked as unreferenced an asset must either be: 1. No longer referenced by any branch or tag. For example, an entire branch was deleted, and a table on that branch is no longer accessible. 2. Assets created in a commit which has passed the (configurable) commit age. If they are not referenced by newer commits Identifying unreferenced assets is a non-destructive action. The result of the spark job is a Spark DataFrame of all the unreferenced assets. This dataframe is stored in an iceberg table managed by nessie at a configurable key. This table is referencable in Nessie so can be examined via Spark or any other Nessie/Iceberg compatible engine. An example of the table output is shown below. This action is designed to run concurrently to normal operational workloads and can/should be run regularly. This table is used as input into the destructive GC operation described below. Configuration and running \u00b6 GcActionsConfig actionsConfig, GcOptions gcConfig, TableIdentifier table The relevant configuration items are: parameter default value description table null The Iceberg TableIdentifier to which the unreferenced assets should be written GcOptions.getBloomFilterCapacity 10000000 Size (number of items) of bloom filter for identification of referenced values GcOptions.getMaxAgeMicros 7 days age at which a commit starts to expire GcOptions.getTimeSlopMicros 1 day minimum age a values can be before it will be considered expired GcActionsConfig.getDynamoRegion provider default AWS Region of the Nessie DynamoDB GcActionsConfig.getDynamoEndpoint provider default Custom AWS endpoint of the Nessie DynamoDB GcActionsConfig.getStoreType DYNAMO only backend which supports GC Running the action can be done simply by: GcActionsConfig actionsConfig = GcActionsConfig . builder (). build (); //use all defaults GcOptions gcOptions = GcOptions . builder (). build (); //use all defaults GcActions actions = new GcActions . Builder ( spark ) . setActionsConfig ( actionsConfig ) . setGcOptions ( gcOptions ) . setTable ( TABLE_IDENTIFIER ). build (); // (1) Dataset < Row > unreferencedAssets = actions . identifyUnreferencedAssets (); // (2) actions . updateUnreferencedAssetTable ( unreferencedAssets ); // (3) The first step above builds the action with known configs. Step 2 generates a DataFrame of unreferenced assets and Step 3 writes it as an iceberg table. Delete Unreferenced Assets \u00b6 The destructive garbage collection step is also a Spark job and takes as input the table that has been built above. This job is modelled as an Iceberg Action and has a similar API to the other Iceberg Actions. In the future it will be registered with Iceberg\u2019s Action APIs and callable via Iceberg\u2019s custom SQL statements . This Iceberg Action looks at the generated table from the Identify step and counts the number of times a distinct asset has been seen. Effectively it performs a group-by and count on this table. If the count of an asset is over a specified threshold AND it was seen in the last run of the Identify stage it is collectable. This asset is then deleted permanently. A report table of deleted object is returned to the user and either the records are removed from the \u2018identify\u2019 table or the whole table is purged. Configuration and running \u00b6 The relevant configuration items are: parameter default value description seenCount 10 How many times an asset has been seen as unreferenced in order to be considered for deletion deleteOnPurge true Delete records from the underlying iceberg table of unreferenced assets dropGcTable true Drop the underlying iceberg table or attempt to clean only the missing rows table null The iceberg Table which stores the list of unreferenced assets Running the action can be done simply by: Table table = catalog . loadTable ( TABLE_IDENTIFIER ); GcTableCleanAction . GcTableCleanResult result = new GcTableCleanAction ( table , spark ). dropGcTable ( true ). deleteCountThreshold ( 2 ). deleteOnPurge ( true ). execute (); The above snippet assumes a TABLE_IDENTIFIER which points to the unreferenced assets table. It also requires an active spark session and a nessie owned Catalog . The result object above returns the number of files the action tried to delete and the number that failed. Note You can follow along an interactive demo in a Jupyter Notebook via Binder . Internal Garbage collection \u00b6 Currently, the only garbage collection algorithm available is on the values and assets in a Nessie database only. The internal records of the Nessie Database are currently not cleaned up. Unreferenced objects stored in Nessie\u2019s internal database will be persisted forever currently. A future release will also clean up internal Nessie records if they are unreferenced. Time-based AutoTagging \u00b6 Info This service is currently in progress and is not yet included in a released version of Nessie. Nessie works against data based on a commit timeline. In many situations, it is useful to capture historical versions of data for analysis or comparison purposes. As such, you can configure Nessie to AutoTag (and auto-delete) using a timestamp based naming scheme. When enabled, Nessie will automatically generate and maintain tags based on time so that users can refer to historical data using timestamps as opposed to commits. This also works hand-in-hand with the Nessie garbage collection process by ensuring that older data is \u201creferenced\u201d and thus available for historical analysis. Currently, there is one AutoTagging policy. By default, it creates the following tags: Hourly tags for the last 25 hours Daily tags for the last 8 days Weekly tags for the last 6 weeks Monthly tags for the last 13 months Yearly tags for the last 3 years Tags are automatically named using a date/ prefix and a zero-extended underscore based naming scheme. For example: date/2019_09_07_15_50 would be a tag for August 7, 2019 at 3:50pm. Warning AutoTags are automatically deleted once the policy rolls-over. As such, if retention is desired post roll-over, manual tags should be created. AutoTagging is currently done based on the UTC roll-over of each item. Manifest Reorganization \u00b6 Info This service is currently in progress and is not yet included in a released version of Nessie. Rewrites the manifests associated with a table so that manifest files are organized around partitions. This extends on the ideas in the Iceberg RewriteManifestsAction . Note Manifest reorganization will show up as a commit, like any other table operation. Key configuration parameters: Name Default Meaning effort medium How much rewriting is allowed to achieve the goals target manifest size 8mb What is the target partition priority medium How important achieving partition-oriented manifests. Compaction \u00b6 Info This service is currently in progress and is not yet included in a released version of Nessie. Because operations against table formats are done at the file level, a table can start to generate many small files. These small files will slow consumption. As such, Nessie can automatically run jobs to compact tables to ensure a consistent level of performance. Name Default Meaning Maximum Small Files 10.0 Maximum number of small files as a ratio to large files Maximum Delete Files 10.0 Maximum number of delete tombstones as a ratio to other files before merging the tombstones into a consolidated file Small File Size 100mb Size of file before it is considered small Target Rewrite Size 256mb The target size for splittable units when rewriting data. Note Compaction will show up as a commit, like any other table operation.","title":"Management Services"},{"location":"features/management/#management-services","text":"Nessie can and needs to manage several operations within your data lake. Each management service can be scheduled and Nessie reports the outcome of each scheduled operation. Scheduled operations require that Nessie have access to a Spark cluster to complete those operations and many of them are distributed compute operations.","title":"Management Services"},{"location":"features/management/#garbage-collection","text":"Since Nessie is maintaining many versions of metadata and data-pointers simultaneously, you must rely on Nessie to clean up old data. Nessie calls this garbage collection. There are at least two steps to a garbage collection action. The first steps are instructive, and the last step is destructive. Info currently the GC algorithm only works for Iceberg tables and Dynamo as a backend","title":"Garbage Collection"},{"location":"features/management/#identify-unreferenced-assets","text":"This is a spark job which should be run periodically to identify no longer referenced assets. Assets are defined as the set of files, records, entries etc. that make up a table, view or other Nessie object. For example, iceberg assets are: * manifest files * manifest lists * data files * metadata files * the entire table directory on disk (if it is empty) To be marked as unreferenced an asset must either be: 1. No longer referenced by any branch or tag. For example, an entire branch was deleted, and a table on that branch is no longer accessible. 2. Assets created in a commit which has passed the (configurable) commit age. If they are not referenced by newer commits Identifying unreferenced assets is a non-destructive action. The result of the spark job is a Spark DataFrame of all the unreferenced assets. This dataframe is stored in an iceberg table managed by nessie at a configurable key. This table is referencable in Nessie so can be examined via Spark or any other Nessie/Iceberg compatible engine. An example of the table output is shown below. This action is designed to run concurrently to normal operational workloads and can/should be run regularly. This table is used as input into the destructive GC operation described below.","title":"Identify Unreferenced Assets"},{"location":"features/management/#configuration-and-running","text":"GcActionsConfig actionsConfig, GcOptions gcConfig, TableIdentifier table The relevant configuration items are: parameter default value description table null The Iceberg TableIdentifier to which the unreferenced assets should be written GcOptions.getBloomFilterCapacity 10000000 Size (number of items) of bloom filter for identification of referenced values GcOptions.getMaxAgeMicros 7 days age at which a commit starts to expire GcOptions.getTimeSlopMicros 1 day minimum age a values can be before it will be considered expired GcActionsConfig.getDynamoRegion provider default AWS Region of the Nessie DynamoDB GcActionsConfig.getDynamoEndpoint provider default Custom AWS endpoint of the Nessie DynamoDB GcActionsConfig.getStoreType DYNAMO only backend which supports GC Running the action can be done simply by: GcActionsConfig actionsConfig = GcActionsConfig . builder (). build (); //use all defaults GcOptions gcOptions = GcOptions . builder (). build (); //use all defaults GcActions actions = new GcActions . Builder ( spark ) . setActionsConfig ( actionsConfig ) . setGcOptions ( gcOptions ) . setTable ( TABLE_IDENTIFIER ). build (); // (1) Dataset < Row > unreferencedAssets = actions . identifyUnreferencedAssets (); // (2) actions . updateUnreferencedAssetTable ( unreferencedAssets ); // (3) The first step above builds the action with known configs. Step 2 generates a DataFrame of unreferenced assets and Step 3 writes it as an iceberg table.","title":"Configuration and running"},{"location":"features/management/#delete-unreferenced-assets","text":"The destructive garbage collection step is also a Spark job and takes as input the table that has been built above. This job is modelled as an Iceberg Action and has a similar API to the other Iceberg Actions. In the future it will be registered with Iceberg\u2019s Action APIs and callable via Iceberg\u2019s custom SQL statements . This Iceberg Action looks at the generated table from the Identify step and counts the number of times a distinct asset has been seen. Effectively it performs a group-by and count on this table. If the count of an asset is over a specified threshold AND it was seen in the last run of the Identify stage it is collectable. This asset is then deleted permanently. A report table of deleted object is returned to the user and either the records are removed from the \u2018identify\u2019 table or the whole table is purged.","title":"Delete Unreferenced Assets"},{"location":"features/management/#configuration-and-running_1","text":"The relevant configuration items are: parameter default value description seenCount 10 How many times an asset has been seen as unreferenced in order to be considered for deletion deleteOnPurge true Delete records from the underlying iceberg table of unreferenced assets dropGcTable true Drop the underlying iceberg table or attempt to clean only the missing rows table null The iceberg Table which stores the list of unreferenced assets Running the action can be done simply by: Table table = catalog . loadTable ( TABLE_IDENTIFIER ); GcTableCleanAction . GcTableCleanResult result = new GcTableCleanAction ( table , spark ). dropGcTable ( true ). deleteCountThreshold ( 2 ). deleteOnPurge ( true ). execute (); The above snippet assumes a TABLE_IDENTIFIER which points to the unreferenced assets table. It also requires an active spark session and a nessie owned Catalog . The result object above returns the number of files the action tried to delete and the number that failed. Note You can follow along an interactive demo in a Jupyter Notebook via Binder .","title":"Configuration and running"},{"location":"features/management/#internal-garbage-collection","text":"Currently, the only garbage collection algorithm available is on the values and assets in a Nessie database only. The internal records of the Nessie Database are currently not cleaned up. Unreferenced objects stored in Nessie\u2019s internal database will be persisted forever currently. A future release will also clean up internal Nessie records if they are unreferenced.","title":"Internal Garbage collection"},{"location":"features/management/#time-based-autotagging","text":"Info This service is currently in progress and is not yet included in a released version of Nessie. Nessie works against data based on a commit timeline. In many situations, it is useful to capture historical versions of data for analysis or comparison purposes. As such, you can configure Nessie to AutoTag (and auto-delete) using a timestamp based naming scheme. When enabled, Nessie will automatically generate and maintain tags based on time so that users can refer to historical data using timestamps as opposed to commits. This also works hand-in-hand with the Nessie garbage collection process by ensuring that older data is \u201creferenced\u201d and thus available for historical analysis. Currently, there is one AutoTagging policy. By default, it creates the following tags: Hourly tags for the last 25 hours Daily tags for the last 8 days Weekly tags for the last 6 weeks Monthly tags for the last 13 months Yearly tags for the last 3 years Tags are automatically named using a date/ prefix and a zero-extended underscore based naming scheme. For example: date/2019_09_07_15_50 would be a tag for August 7, 2019 at 3:50pm. Warning AutoTags are automatically deleted once the policy rolls-over. As such, if retention is desired post roll-over, manual tags should be created. AutoTagging is currently done based on the UTC roll-over of each item.","title":"Time-based AutoTagging"},{"location":"features/management/#manifest-reorganization","text":"Info This service is currently in progress and is not yet included in a released version of Nessie. Rewrites the manifests associated with a table so that manifest files are organized around partitions. This extends on the ideas in the Iceberg RewriteManifestsAction . Note Manifest reorganization will show up as a commit, like any other table operation. Key configuration parameters: Name Default Meaning effort medium How much rewriting is allowed to achieve the goals target manifest size 8mb What is the target partition priority medium How important achieving partition-oriented manifests.","title":"Manifest Reorganization"},{"location":"features/management/#compaction","text":"Info This service is currently in progress and is not yet included in a released version of Nessie. Because operations against table formats are done at the file level, a table can start to generate many small files. These small files will slow consumption. As such, Nessie can automatically run jobs to compact tables to ensure a consistent level of performance. Name Default Meaning Maximum Small Files 10.0 Maximum number of small files as a ratio to large files Maximum Delete Files 10.0 Maximum number of delete tombstones as a ratio to other files before merging the tombstones into a consolidated file Small File Size 100mb Size of file before it is considered small Target Rewrite Size 256mb The target size for splittable units when rewriting data. Note Compaction will show up as a commit, like any other table operation.","title":"Compaction"},{"location":"features/metadata_authorization/","text":"Metadata authorization \u00b6 Authorization scope \u00b6 It is important to note that Nessie does not store data directly but only data location and other metadata. As a consequence, the Nessie authorization layer can only really control access to metadata , but might not prevent data itself to be accessed directly without interacting with Nessie. It is then expected that another system can control access to data itself to make sure unauthorized access isn\u2019t possible. The same is true for access to historical data, which is one of Nessie\u2019s main features. For example, while it might seem safe committing a change that removes undesired sensitive data and restricting access to only the latest version of the dataset, the truth is that the sensitive data may still exist on the data lake and be accessed by other means (similar to how redacting a PDF by adding black boxes on top of sensitive information does not prevent people to read what is written beneath in most cases). The only safe way to remove this data is to remove it from the table (e.g. via DELETE statements) and then run the Garbage Collection algorithm to ensure the data has been removed from Nessie history and deleted on the data lake. Stories \u00b6 Here\u2019s a list of common authorization scenarios: Alice attempts to execute a query against the table Foo on branch prod . As she has read access to the table on this branch, Nessie allows the execution engine to get the table details. Bob attempts to execute a query against the table Foo on branch prod . However, Bob does not have read access to the table. Nessie returns an authorization error, and the execution engine refuses to execute the query. Carol has access to the content on branch prod , but not to the table Foo on this branch. Carol creates a new reference named carol-branch with the same hash as prod , and attempts to change permissions on table Foo . However, request is denied and Carol cannot access the content of Foo . Dave has access to the content on branch prod , and wants to update the content of the table Foo . He creates a new reference named dave-experiment , and executes several queries against this branch to modify table Foo . Each modification is a commit done against dave-experiment branch which is approved by the Nessie server. When all the desired modifications are done, Dave attempts to merge the changes back to the prod branch. However, Dave doesn\u2019t have the rights to modify the prod branch, causing Nessie to deny the request. Access control model \u00b6 Any object in Nessie can be designated by a pair of coordinates ( reference , path ), therefore access control is also designed around those two concepts. Access control against references \u00b6 References can be designated by their name (branches and tags) and there are several operations that can be exercised: view/list available references create a new named reference assign a hash to a reference delete a reference list objects present in the tree read objects content in the tree commit a change against the reference Note that a user needs to be able to view a reference in order to list objects on that reference. Access control against paths \u00b6 For a specific reference, an entity is designated by its path which is why a simple way of performing access control can be done by applying restrictions on path. Several operations can be exercised against an entity : create a new entity delete an entity update entity\u2019s content Note that those operations combine themselves with the reference operations. For example to actually be able to update the content of an entity, user needs both permission to do the update AND to commit the change against the reference where the change will be stored Service Provider Interface \u00b6 The SPI is named AccessChecker and uses AccessContext , which carries information about the overall context of the operation. Implementers of AccessChecker are completely free to define their own way of creating/updating/checking authorization rules. ContentId Usage \u00b6 Note that there is a contentId parameter in some methods of the AccessChecker , which allows checking specific rules for a given entity at a given point in time. The contentId parameter refers to the ID of a Content object and its contract is defined here . One can think of this similar to how permissions are defined in Google Docs. There are some permissions that are specific to the parent folder and to the doc itself. When a Doc is moved from one folder to another, it inherits the permissions of the parent folder. However, the doc-specific permissions are carried over with the doc and still apply. The same is true in the context of entities. There are some rules that apply to an entity in a global fashion, and then there\u2019s the possibility to define rules specific to the contentId of an entity. Reference implementation for Metadata Authorization \u00b6 The reference implementation allows defining authorization rules via application.properties and is therefore dependent on Quarkus . Nessie\u2019s metadata authorization can be enabled via nessie.server.authorization.enabled=true . Authorization Rules \u00b6 Authorization rule definitions are using a Common Expression Language (CEL) expression (an intro to CEL can be found at https://github.com/google/cel-spec/blob/master/doc/intro.md ). Rule definitions are of the form nessie.server.authorization.rules.<ruleId>=<rule_expression> , where <ruleId> is a unique identifier for the rule. <rule_expression> is basically a CEL expression string, which allows lots of flexibility on a given set of variables. Available variables within the <rule_expression> are: \u2018op\u2019 / \u2018role\u2019 / \u2018ref\u2019 / \u2018path\u2019 . The \u2018op\u2019 variable in the <rule_expression> refers to the type of operation can be any of the following. See BatchAccessChecker and Check types. VIEW_REFERENCE CREATE_REFERENCE DELETE_REFERENCE DELETE_DEFAULT_BRANCH READ_ENTRIES READ_CONTENT_KEY LIST_COMMIT_LOG COMMIT_CHANGE_AGAINST_REFERENCE ASSIGN_REFERENCE_TO_HASH UPDATE_ENTITY READ_ENTITY_VALUE DELETE_ENTITY VIEW_REFLOG . The \u2018role\u2019 refers to the user\u2019s role and can be any string. The \u2018ref\u2019 refers to a string representing a branch/tag name or DETATCHED for direct access to a commit id. The \u2018path\u2019 refers to the content key for the contents of an object and can be any string Since all available authorization rule variables are strings, the relevant CEL-specific things that are worth mentioning are shown below: equality and inequality regular expressions operators & functions Example authorization rules \u00b6 Below are some basic examples that show how to give a permission for a particular operation. In reality, one would want to keep the number of authorization rules for a single user/role low and grant permissions for all required operations through as few rules as possible. allows viewing the branch/tag starting with the name allowedBranch for the role that starts with the name test_ : nessie.server.authorization.rules.allow_branch_listing=\\ op=='VIEW_REFERENCE' && role.startsWith('test_') && ref.startsWith('allowedBranch') allows creating branches/tags that match the regex .*allowedBranch.* for the role test_user : nessie.server.authorization.rules.allow_branch_creation=\\ op=='CREATE_REFERENCE' && role=='test_user' && ref.matches('.*allowedBranch.*') allows deleting branches/tags that end with allowedBranch for the role named test_user123 : nessie.server.authorization.rules.allow_branch_deletion=\\ op in ['VIEW_REFERENCE', 'DELETE_REFERENCE'] && role=='test_user123' && ref.endsWith('allowedBranch') allows listing the commit log for all branches/tags starting with dev : nessie.server.authorization.rules.allow_listing_commitlog=\\ op in ['VIEW_REFERENCE', 'LIST_COMMIT_LOG'] && ref.startsWith('dev') allows reading the entity value where teh path starts with allowed. for the role test_user : nessie.server.authorization.rules.allow_reading_entity_value=\\ op in ['VIEW_REFERENCE', 'READ_ENTITY_VALUE'] && role=='test_user' && path.startsWith('allowed.') allows deleting the entity where the path starts with dev. for all roles: nessie.server.authorization.rules.allow_deleting_entity=\\ op in ['VIEW_REFERENCE', 'DELETE_ENTITY'] && path.startsWith('dev.') allows listing reflog for the role admin_user : nessie.server.authorization.rules.allow_listing_reflog=\\ op=='VIEW_REFLOG' && role=='admin_user' allows deletion of the default branch for the role admin_user : nessie.server.authorization.rules.allow_deleting_default_branch=\\ op=='DELETE_DEFAULT_BRANCH' && role=='admin_user' Example authorization rules from Stories section \u00b6 As mentioned in the Stories section, a few common scenarios that are possible are: * Alice attempts to execute a query against the table Foo on branch prod . As she has read access to the table on this branch, Nessie allows the execution engine to get the table details. * Bob attempts to execute a query against the table Foo on branch prod . However, Bob does not have read access to the table. Nessie returns an authorization error, and the execution engine refuses to execute the query. * Carol has access to the content on branch prod , but not to the table Foo on this branch. Carol creates a new reference named carol-branch with the same hash as prod , and attempts to change permissions on table Foo . However, request is denied and Carol cannot access the content of Foo . * Dave has access to the content on branch prod , and wants to update the content of the table Foo . He creates a new reference named dave-experiment , and executes several queries against this branch to modify table Foo . Each modification is a commit done against dave-experiment branch which is approved by the Nessie server. When all the desired modifications are done, Dave attempts to merge the changes back to the prod branch. However, Dave doesn\u2019t have the rights to modify the prod branch, causing Nessie to deny the request. Below are the respective authorization rules for these scenarios: # read access for all on the prod branch nessie.server.authorization.rules.prod=\\ op in ['VIEW_REFERENCE'] && ref=='prod' && role in ['Alice', 'Bob', 'Carol', 'Dave'] # alice & dave can read Foo nessie.server.authorization.rules.reading_foo_on_prod=\\ op in ['READ_ENTITY_VALUE'] && ref=='prod' && path=='Foo' && role in ['Alice', 'Dave'] # specific rules for carol on her branch nessie.server.authorization.rules.carol-branch=\\ op in ['VIEW_REFERENCE', 'CREATE_REFERENCE', 'DELETE_REFERENCE', 'COMMIT_CHANGE_AGAINST_REFERENCE'] && ref=='carol-branch' && role=='Carol' # specific rules for dave on his branch nessie.server.authorization.rules.dave-experiment=\\ op in ['VIEW_REFERENCE', 'CREATE_REFERENCE', 'DELETE_REFERENCE', 'COMMIT_CHANGE_AGAINST_REFERENCE'] && ref=='dave-experiment' && role=='Dave' # bob can read/update/delete BobsBar only nessie.server.authorization.rules.bob=\\ op in ['READ_ENTITY_VALUE', 'UPDATE_ENTITY', 'DELETE_ENTITY'] && path=='BobsBar` && role=='Bob') # carol can read/update/delete CarolsSecret nessie.server.authorization.rules.carol=\\ op in ['READ_ENTITY_VALUE', 'UPDATE_ENTITY', 'DELETE_ENTITY'] && path=='CarolsSecret` && role=='Alice') # dave can read/update/delete DavesHiddenX nessie.server.authorization.rules.dave=\\ op in ['READ_ENTITY_VALUE', 'UPDATE_ENTITY', 'DELETE_ENTITY'] && path=='DavesHiddenX` && role=='Dave')","title":"Metadata authorization"},{"location":"features/metadata_authorization/#metadata-authorization","text":"","title":"Metadata authorization"},{"location":"features/metadata_authorization/#authorization-scope","text":"It is important to note that Nessie does not store data directly but only data location and other metadata. As a consequence, the Nessie authorization layer can only really control access to metadata , but might not prevent data itself to be accessed directly without interacting with Nessie. It is then expected that another system can control access to data itself to make sure unauthorized access isn\u2019t possible. The same is true for access to historical data, which is one of Nessie\u2019s main features. For example, while it might seem safe committing a change that removes undesired sensitive data and restricting access to only the latest version of the dataset, the truth is that the sensitive data may still exist on the data lake and be accessed by other means (similar to how redacting a PDF by adding black boxes on top of sensitive information does not prevent people to read what is written beneath in most cases). The only safe way to remove this data is to remove it from the table (e.g. via DELETE statements) and then run the Garbage Collection algorithm to ensure the data has been removed from Nessie history and deleted on the data lake.","title":"Authorization scope"},{"location":"features/metadata_authorization/#stories","text":"Here\u2019s a list of common authorization scenarios: Alice attempts to execute a query against the table Foo on branch prod . As she has read access to the table on this branch, Nessie allows the execution engine to get the table details. Bob attempts to execute a query against the table Foo on branch prod . However, Bob does not have read access to the table. Nessie returns an authorization error, and the execution engine refuses to execute the query. Carol has access to the content on branch prod , but not to the table Foo on this branch. Carol creates a new reference named carol-branch with the same hash as prod , and attempts to change permissions on table Foo . However, request is denied and Carol cannot access the content of Foo . Dave has access to the content on branch prod , and wants to update the content of the table Foo . He creates a new reference named dave-experiment , and executes several queries against this branch to modify table Foo . Each modification is a commit done against dave-experiment branch which is approved by the Nessie server. When all the desired modifications are done, Dave attempts to merge the changes back to the prod branch. However, Dave doesn\u2019t have the rights to modify the prod branch, causing Nessie to deny the request.","title":"Stories"},{"location":"features/metadata_authorization/#access-control-model","text":"Any object in Nessie can be designated by a pair of coordinates ( reference , path ), therefore access control is also designed around those two concepts.","title":"Access control model"},{"location":"features/metadata_authorization/#access-control-against-references","text":"References can be designated by their name (branches and tags) and there are several operations that can be exercised: view/list available references create a new named reference assign a hash to a reference delete a reference list objects present in the tree read objects content in the tree commit a change against the reference Note that a user needs to be able to view a reference in order to list objects on that reference.","title":"Access control against references"},{"location":"features/metadata_authorization/#access-control-against-paths","text":"For a specific reference, an entity is designated by its path which is why a simple way of performing access control can be done by applying restrictions on path. Several operations can be exercised against an entity : create a new entity delete an entity update entity\u2019s content Note that those operations combine themselves with the reference operations. For example to actually be able to update the content of an entity, user needs both permission to do the update AND to commit the change against the reference where the change will be stored","title":"Access control against paths"},{"location":"features/metadata_authorization/#service-provider-interface","text":"The SPI is named AccessChecker and uses AccessContext , which carries information about the overall context of the operation. Implementers of AccessChecker are completely free to define their own way of creating/updating/checking authorization rules.","title":"Service Provider Interface"},{"location":"features/metadata_authorization/#contentid-usage","text":"Note that there is a contentId parameter in some methods of the AccessChecker , which allows checking specific rules for a given entity at a given point in time. The contentId parameter refers to the ID of a Content object and its contract is defined here . One can think of this similar to how permissions are defined in Google Docs. There are some permissions that are specific to the parent folder and to the doc itself. When a Doc is moved from one folder to another, it inherits the permissions of the parent folder. However, the doc-specific permissions are carried over with the doc and still apply. The same is true in the context of entities. There are some rules that apply to an entity in a global fashion, and then there\u2019s the possibility to define rules specific to the contentId of an entity.","title":"ContentId Usage"},{"location":"features/metadata_authorization/#reference-implementation-for-metadata-authorization","text":"The reference implementation allows defining authorization rules via application.properties and is therefore dependent on Quarkus . Nessie\u2019s metadata authorization can be enabled via nessie.server.authorization.enabled=true .","title":"Reference implementation for Metadata Authorization"},{"location":"features/metadata_authorization/#authorization-rules","text":"Authorization rule definitions are using a Common Expression Language (CEL) expression (an intro to CEL can be found at https://github.com/google/cel-spec/blob/master/doc/intro.md ). Rule definitions are of the form nessie.server.authorization.rules.<ruleId>=<rule_expression> , where <ruleId> is a unique identifier for the rule. <rule_expression> is basically a CEL expression string, which allows lots of flexibility on a given set of variables. Available variables within the <rule_expression> are: \u2018op\u2019 / \u2018role\u2019 / \u2018ref\u2019 / \u2018path\u2019 . The \u2018op\u2019 variable in the <rule_expression> refers to the type of operation can be any of the following. See BatchAccessChecker and Check types. VIEW_REFERENCE CREATE_REFERENCE DELETE_REFERENCE DELETE_DEFAULT_BRANCH READ_ENTRIES READ_CONTENT_KEY LIST_COMMIT_LOG COMMIT_CHANGE_AGAINST_REFERENCE ASSIGN_REFERENCE_TO_HASH UPDATE_ENTITY READ_ENTITY_VALUE DELETE_ENTITY VIEW_REFLOG . The \u2018role\u2019 refers to the user\u2019s role and can be any string. The \u2018ref\u2019 refers to a string representing a branch/tag name or DETATCHED for direct access to a commit id. The \u2018path\u2019 refers to the content key for the contents of an object and can be any string Since all available authorization rule variables are strings, the relevant CEL-specific things that are worth mentioning are shown below: equality and inequality regular expressions operators & functions","title":"Authorization Rules"},{"location":"features/metadata_authorization/#example-authorization-rules","text":"Below are some basic examples that show how to give a permission for a particular operation. In reality, one would want to keep the number of authorization rules for a single user/role low and grant permissions for all required operations through as few rules as possible. allows viewing the branch/tag starting with the name allowedBranch for the role that starts with the name test_ : nessie.server.authorization.rules.allow_branch_listing=\\ op=='VIEW_REFERENCE' && role.startsWith('test_') && ref.startsWith('allowedBranch') allows creating branches/tags that match the regex .*allowedBranch.* for the role test_user : nessie.server.authorization.rules.allow_branch_creation=\\ op=='CREATE_REFERENCE' && role=='test_user' && ref.matches('.*allowedBranch.*') allows deleting branches/tags that end with allowedBranch for the role named test_user123 : nessie.server.authorization.rules.allow_branch_deletion=\\ op in ['VIEW_REFERENCE', 'DELETE_REFERENCE'] && role=='test_user123' && ref.endsWith('allowedBranch') allows listing the commit log for all branches/tags starting with dev : nessie.server.authorization.rules.allow_listing_commitlog=\\ op in ['VIEW_REFERENCE', 'LIST_COMMIT_LOG'] && ref.startsWith('dev') allows reading the entity value where teh path starts with allowed. for the role test_user : nessie.server.authorization.rules.allow_reading_entity_value=\\ op in ['VIEW_REFERENCE', 'READ_ENTITY_VALUE'] && role=='test_user' && path.startsWith('allowed.') allows deleting the entity where the path starts with dev. for all roles: nessie.server.authorization.rules.allow_deleting_entity=\\ op in ['VIEW_REFERENCE', 'DELETE_ENTITY'] && path.startsWith('dev.') allows listing reflog for the role admin_user : nessie.server.authorization.rules.allow_listing_reflog=\\ op=='VIEW_REFLOG' && role=='admin_user' allows deletion of the default branch for the role admin_user : nessie.server.authorization.rules.allow_deleting_default_branch=\\ op=='DELETE_DEFAULT_BRANCH' && role=='admin_user'","title":"Example authorization rules"},{"location":"features/metadata_authorization/#example-authorization-rules-from-stories-section","text":"As mentioned in the Stories section, a few common scenarios that are possible are: * Alice attempts to execute a query against the table Foo on branch prod . As she has read access to the table on this branch, Nessie allows the execution engine to get the table details. * Bob attempts to execute a query against the table Foo on branch prod . However, Bob does not have read access to the table. Nessie returns an authorization error, and the execution engine refuses to execute the query. * Carol has access to the content on branch prod , but not to the table Foo on this branch. Carol creates a new reference named carol-branch with the same hash as prod , and attempts to change permissions on table Foo . However, request is denied and Carol cannot access the content of Foo . * Dave has access to the content on branch prod , and wants to update the content of the table Foo . He creates a new reference named dave-experiment , and executes several queries against this branch to modify table Foo . Each modification is a commit done against dave-experiment branch which is approved by the Nessie server. When all the desired modifications are done, Dave attempts to merge the changes back to the prod branch. However, Dave doesn\u2019t have the rights to modify the prod branch, causing Nessie to deny the request. Below are the respective authorization rules for these scenarios: # read access for all on the prod branch nessie.server.authorization.rules.prod=\\ op in ['VIEW_REFERENCE'] && ref=='prod' && role in ['Alice', 'Bob', 'Carol', 'Dave'] # alice & dave can read Foo nessie.server.authorization.rules.reading_foo_on_prod=\\ op in ['READ_ENTITY_VALUE'] && ref=='prod' && path=='Foo' && role in ['Alice', 'Dave'] # specific rules for carol on her branch nessie.server.authorization.rules.carol-branch=\\ op in ['VIEW_REFERENCE', 'CREATE_REFERENCE', 'DELETE_REFERENCE', 'COMMIT_CHANGE_AGAINST_REFERENCE'] && ref=='carol-branch' && role=='Carol' # specific rules for dave on his branch nessie.server.authorization.rules.dave-experiment=\\ op in ['VIEW_REFERENCE', 'CREATE_REFERENCE', 'DELETE_REFERENCE', 'COMMIT_CHANGE_AGAINST_REFERENCE'] && ref=='dave-experiment' && role=='Dave' # bob can read/update/delete BobsBar only nessie.server.authorization.rules.bob=\\ op in ['READ_ENTITY_VALUE', 'UPDATE_ENTITY', 'DELETE_ENTITY'] && path=='BobsBar` && role=='Bob') # carol can read/update/delete CarolsSecret nessie.server.authorization.rules.carol=\\ op in ['READ_ENTITY_VALUE', 'UPDATE_ENTITY', 'DELETE_ENTITY'] && path=='CarolsSecret` && role=='Alice') # dave can read/update/delete DavesHiddenX nessie.server.authorization.rules.dave=\\ op in ['READ_ENTITY_VALUE', 'UPDATE_ENTITY', 'DELETE_ENTITY'] && path=='DavesHiddenX` && role=='Dave')","title":"Example authorization rules from Stories section"},{"location":"features/security/","text":"Security \u00b6 Authentication \u00b6 Nessie currently supports 3 security modes: No Security Open Id Connect AWS IAM Roles (limited to API calls, UI not supported) Authorization \u00b6 Nessie authorization can only be done externally at the moment. However, because of the way that the REST APIs are defined, many operations can be controlled via a layer 7 firewall so that users and systems can be controlled depending on what read/write and types of operations should be allowed. This works especially well with Nessie run as an AWS Lambda using API gateway policies . Metadata authorization \u00b6 Nessie supports authorization on metadata. Details are described in the Metadata Authorization section.","title":"Security"},{"location":"features/security/#security","text":"","title":"Security"},{"location":"features/security/#authentication","text":"Nessie currently supports 3 security modes: No Security Open Id Connect AWS IAM Roles (limited to API calls, UI not supported)","title":"Authentication"},{"location":"features/security/#authorization","text":"Nessie authorization can only be done externally at the moment. However, because of the way that the REST APIs are defined, many operations can be controlled via a layer 7 firewall so that users and systems can be controlled depending on what read/write and types of operations should be allowed. This works especially well with Nessie run as an AWS Lambda using API gateway policies .","title":"Authorization"},{"location":"features/security/#metadata-authorization","text":"Nessie supports authorization on metadata. Details are described in the Metadata Authorization section.","title":"Metadata authorization"},{"location":"features/transactions/","text":"Transactions \u00b6 Nessie extends existing table formats to provide a single serial view of transaction history. This is enabled across an unlimited number of tables. A user can view a commit log either through the UI or by using the Nessie CLI. Operations against each table are listed along with timestamp, user and helpful information about the operation. Cross-Table Transactions \u00b6 Nessie is the first technology to provide an open facility for cross-table transactions within your data lake. There are two ways that this can be accomplished: Via Branches: Because Nessie allows branches to be created and then reassigned, a sequence of commits on one branch can be exposed as a single consistent view to other users through the use of a merge operation. This allows use of systems that don\u2019t have internal cross-table transaction support to still control the visibility of connected changes. Single Commits: Nessie allows a single commit operation to include many object changes simultaneously. While Nessie operations internally use this capability, tools will need to be enhanced to take advantage of this powerful new capability. START TRANSACTION.. COMMIT \u00b6 The Nessie community is working with tool developers to introduce traditional data warehouse cross-table transactions. Nessie\u2019s catalog implementations already support the underlying capability of multi-table transactions. Isolation Levels \u00b6 Nessie exposes APIs to support three-levels of isolation: Read Committed, Repeated Read and Serialized. By supporting the recording of reads as part of a commit (via the Unchanged operation), tools can introduce full per operation serialized isolation. This is a transaction mode that has been traditionally limited to OLTP systems and unavailable to OLAP systems and data warehouses 1 . Info While Nessie exposes the necessary primitives to support configurable isolation, work still needs to be done with tool developers to ensure those tools expose these capabilities. As those integrations progress, we\u2019ll include more information about them here. At the moment, most tools operate in either Read Committed (Iceberg when calling refresh, Delta Lake) or Repeated Read (HMS Bridge operations, Iceberg when avoiding calls to refresh). Read Committed (Optimistic) \u00b6 Read Each time metadata for a table is retrieved, the latest version of that ref for the that current branch is exposed. Ownership A transaction only needs to be created on the client. There is not concept of a long-lived transaction. Write Safe writes are allowed. How Client goes to server to retrieve latest version of data for each operation Repeated Read (Optimistic) \u00b6 Read When a transaction is started, a ref is turned into a specific commit id. All metadata retrieved is locked to this hash or later, as long as future hashes have not changed any table already read. Ownership A transaction only needs to be created on the client. There is no concept of a long-lived transaction on the server. Write Safe writes are allowed. Unsafe writes fail. How Client resolves commit hash on first read and uses that for all subsequent operations. Note: this is stricter than the formal definition of repeatable read since that will allow new records to also be viewed on a second operation within the same transaction. However, both implementations are of similar complexity and a stricter form of repeated read seems easier to understand. Serializable (Optimistic) \u00b6 Read When a transaction is started, a ref is turned into a specific commit id. During the transaction, a recording of all read tables is recorded. Ownership A transaction only needs to be created on the client. There is no concept of a long-lived transaction on the server. Write All tables touched as part of the read operations must be in the same state when the commit operation is attempted. If they are not, the write operation is rejected. This is done internally via the Unchanged operation. How Client resolves commit hash on first read and uses that for all subsequent operations. Serializable transactions allow one to do guaranteed exactly once operations. For example- move all this data from table1 to table2. At the end of this operation there is a guarantee that any operations done against table1 will either show up in table2 or fail to apply to table1 (true before & after). Pessimistic Locking \u00b6 Currently, all three isolation models are supported only via optimistic locking. In the future, it is likely that we will also add support for pessimistic locking. To support pessimistic locking, transaction state must be held by the Nessie service as opposed to Nessie clients requiring a more formal protocol around start transaction, commit transaction with relevant timeouts, deadlock detection and cancellation capabilities. Lock Coarseness and Resolution \u00b6 Nessie maintains state and locks at table granularity. If a conflict is found at the table level, Nessie will either reject the operation or delegate the operation to the underlying table format to see if further conflict resolution can occur. Delta Lake does support serializable isolation against a single table . It does not support serializable across multiple tables. \u21a9","title":"Transactions"},{"location":"features/transactions/#transactions","text":"Nessie extends existing table formats to provide a single serial view of transaction history. This is enabled across an unlimited number of tables. A user can view a commit log either through the UI or by using the Nessie CLI. Operations against each table are listed along with timestamp, user and helpful information about the operation.","title":"Transactions"},{"location":"features/transactions/#cross-table-transactions","text":"Nessie is the first technology to provide an open facility for cross-table transactions within your data lake. There are two ways that this can be accomplished: Via Branches: Because Nessie allows branches to be created and then reassigned, a sequence of commits on one branch can be exposed as a single consistent view to other users through the use of a merge operation. This allows use of systems that don\u2019t have internal cross-table transaction support to still control the visibility of connected changes. Single Commits: Nessie allows a single commit operation to include many object changes simultaneously. While Nessie operations internally use this capability, tools will need to be enhanced to take advantage of this powerful new capability.","title":"Cross-Table Transactions"},{"location":"features/transactions/#start-transaction-commit","text":"The Nessie community is working with tool developers to introduce traditional data warehouse cross-table transactions. Nessie\u2019s catalog implementations already support the underlying capability of multi-table transactions.","title":"START TRANSACTION.. COMMIT"},{"location":"features/transactions/#isolation-levels","text":"Nessie exposes APIs to support three-levels of isolation: Read Committed, Repeated Read and Serialized. By supporting the recording of reads as part of a commit (via the Unchanged operation), tools can introduce full per operation serialized isolation. This is a transaction mode that has been traditionally limited to OLTP systems and unavailable to OLAP systems and data warehouses 1 . Info While Nessie exposes the necessary primitives to support configurable isolation, work still needs to be done with tool developers to ensure those tools expose these capabilities. As those integrations progress, we\u2019ll include more information about them here. At the moment, most tools operate in either Read Committed (Iceberg when calling refresh, Delta Lake) or Repeated Read (HMS Bridge operations, Iceberg when avoiding calls to refresh).","title":"Isolation Levels"},{"location":"features/transactions/#read-committed-optimistic","text":"Read Each time metadata for a table is retrieved, the latest version of that ref for the that current branch is exposed. Ownership A transaction only needs to be created on the client. There is not concept of a long-lived transaction. Write Safe writes are allowed. How Client goes to server to retrieve latest version of data for each operation","title":"Read Committed (Optimistic)"},{"location":"features/transactions/#repeated-read-optimistic","text":"Read When a transaction is started, a ref is turned into a specific commit id. All metadata retrieved is locked to this hash or later, as long as future hashes have not changed any table already read. Ownership A transaction only needs to be created on the client. There is no concept of a long-lived transaction on the server. Write Safe writes are allowed. Unsafe writes fail. How Client resolves commit hash on first read and uses that for all subsequent operations. Note: this is stricter than the formal definition of repeatable read since that will allow new records to also be viewed on a second operation within the same transaction. However, both implementations are of similar complexity and a stricter form of repeated read seems easier to understand.","title":"Repeated Read (Optimistic)"},{"location":"features/transactions/#serializable-optimistic","text":"Read When a transaction is started, a ref is turned into a specific commit id. During the transaction, a recording of all read tables is recorded. Ownership A transaction only needs to be created on the client. There is no concept of a long-lived transaction on the server. Write All tables touched as part of the read operations must be in the same state when the commit operation is attempted. If they are not, the write operation is rejected. This is done internally via the Unchanged operation. How Client resolves commit hash on first read and uses that for all subsequent operations. Serializable transactions allow one to do guaranteed exactly once operations. For example- move all this data from table1 to table2. At the end of this operation there is a guarantee that any operations done against table1 will either show up in table2 or fail to apply to table1 (true before & after).","title":"Serializable (Optimistic)"},{"location":"features/transactions/#pessimistic-locking","text":"Currently, all three isolation models are supported only via optimistic locking. In the future, it is likely that we will also add support for pessimistic locking. To support pessimistic locking, transaction state must be held by the Nessie service as opposed to Nessie clients requiring a more formal protocol around start transaction, commit transaction with relevant timeouts, deadlock detection and cancellation capabilities.","title":"Pessimistic Locking"},{"location":"features/transactions/#lock-coarseness-and-resolution","text":"Nessie maintains state and locks at table granularity. If a conflict is found at the table level, Nessie will either reject the operation or delegate the operation to the underlying table format to see if further conflict resolution can occur. Delta Lake does support serializable isolation against a single table . It does not support serializable across multiple tables. \u21a9","title":"Lock Coarseness and Resolution"},{"location":"guides/keycloak/","text":"Authentication with Keycloak \u00b6 In this guide we walk through the process of configuring a Nessie Server to authenticate clients against a local Keycloak server. Docker is use at the runtime environments for both servers. Setting up Keycloak \u00b6 For the purposes of this guide we will only do use a simple Keycloak configuration, that is still sufficient to demonstrate how OpenID authentication works in Nessie servers. First, start a Keycloak container using its latest Docker image. docker run -p 8080 :8080 -e KEYCLOAK_USER = admin -e KEYCLOAK_PASSWORD = admin \\ --name keycloak quay.io/keycloak/keycloak:latest start-dev Note the admin username and password. Those values will be required to log into the Keycloak Administration Console that should now be available at http://localhost:8080/auth/admin/ The default realm is called Master . On the left-hand pane find the Manage > Users page and click Add User on the right side of the (initially empty) users table. Enter the username \u201cnessie\u201d and click Save . Now, under the Credentials tab of the nessie user page set password to nessie and turn off the Temporary flag. Click Set Password . Be sure also to remove all the Required User Actions if any. For the sake of convenience let\u2019s increase the default token expiration time. Goto Clients > admin-cli > Advanced Settings . Set Access Token Lifespan to 1 day and click Save . Now we are ready to generate an access_token for the nessie user. Use the following command to obtain a token. Then, store it in the NESSIE_AUTH_TOKEN environment variable. It will be required to access Nessie APIs later. Plain Command curl -X POST \\ http://localhost:8080/auth/realms/master/protocol/openid-connect/token \\ --user admin-cli:none \\ -d 'username=nessie' \\ -d 'password=nessie' \\ -d 'grant_type=password' Bash export NESSIE_AUTH_TOKEN = $( curl -X POST \\ http://localhost:8080/auth/realms/master/protocol/openid-connect/token \\ --user admin-cli:none \\ -d 'username=nessie' \\ -d 'password=nessie' \\ -d 'grant_type=password' | jq -r .access_token ) Note: when using keycloak 17+ change the URL to http://localhost:8080/realms/master/protocol/openid-connect/token Setting up Nessie Server \u00b6 Start the Nessie server container from the projectnessie/nessie Docker image in authenticated mode, using the Keycloak server for validating user credentials. docker run -p 19120 :19120 \\ -e QUARKUS_OIDC_AUTH_SERVER_URL = http://localhost:8080/auth/realms/master \\ -e QUARKUS_OIDC_CLIENT_ID = projectnessie \\ -e NESSIE_SERVER_AUTHENTICATION_ENABLED = true \\ --network host projectnessie/nessie:latest Note: when using keycloak 17+ change the URL to http://localhost:8080/realms/master/protocol/openid-connect/token Note: this example uses a snapshot build. When Nessie 1.0 is released, the latest stable image will be usable with the instructions from this guide. Using Nessie CLI \u00b6 Now that the Nessie server runs in authenticated mode with a Keycloak, clients have to provide credentials in the form of bearer authentication tokens. For example: nessie --auth-token $NESSIE_AUTH_TOKEN remote show Note: since the name of the NESSIE_AUTH_TOKEN variable matches Nessie CLI configuration naming conventions, the client can automatically find it in the environment, and it does not have to be specified as a command line option. All nessie CLI command will automatically use that token for authenticating their requests. For example: nessie log","title":"Authentication with Keycloak"},{"location":"guides/keycloak/#authentication-with-keycloak","text":"In this guide we walk through the process of configuring a Nessie Server to authenticate clients against a local Keycloak server. Docker is use at the runtime environments for both servers.","title":"Authentication with Keycloak"},{"location":"guides/keycloak/#setting-up-keycloak","text":"For the purposes of this guide we will only do use a simple Keycloak configuration, that is still sufficient to demonstrate how OpenID authentication works in Nessie servers. First, start a Keycloak container using its latest Docker image. docker run -p 8080 :8080 -e KEYCLOAK_USER = admin -e KEYCLOAK_PASSWORD = admin \\ --name keycloak quay.io/keycloak/keycloak:latest start-dev Note the admin username and password. Those values will be required to log into the Keycloak Administration Console that should now be available at http://localhost:8080/auth/admin/ The default realm is called Master . On the left-hand pane find the Manage > Users page and click Add User on the right side of the (initially empty) users table. Enter the username \u201cnessie\u201d and click Save . Now, under the Credentials tab of the nessie user page set password to nessie and turn off the Temporary flag. Click Set Password . Be sure also to remove all the Required User Actions if any. For the sake of convenience let\u2019s increase the default token expiration time. Goto Clients > admin-cli > Advanced Settings . Set Access Token Lifespan to 1 day and click Save . Now we are ready to generate an access_token for the nessie user. Use the following command to obtain a token. Then, store it in the NESSIE_AUTH_TOKEN environment variable. It will be required to access Nessie APIs later. Plain Command curl -X POST \\ http://localhost:8080/auth/realms/master/protocol/openid-connect/token \\ --user admin-cli:none \\ -d 'username=nessie' \\ -d 'password=nessie' \\ -d 'grant_type=password' Bash export NESSIE_AUTH_TOKEN = $( curl -X POST \\ http://localhost:8080/auth/realms/master/protocol/openid-connect/token \\ --user admin-cli:none \\ -d 'username=nessie' \\ -d 'password=nessie' \\ -d 'grant_type=password' | jq -r .access_token ) Note: when using keycloak 17+ change the URL to http://localhost:8080/realms/master/protocol/openid-connect/token","title":"Setting up Keycloak"},{"location":"guides/keycloak/#setting-up-nessie-server","text":"Start the Nessie server container from the projectnessie/nessie Docker image in authenticated mode, using the Keycloak server for validating user credentials. docker run -p 19120 :19120 \\ -e QUARKUS_OIDC_AUTH_SERVER_URL = http://localhost:8080/auth/realms/master \\ -e QUARKUS_OIDC_CLIENT_ID = projectnessie \\ -e NESSIE_SERVER_AUTHENTICATION_ENABLED = true \\ --network host projectnessie/nessie:latest Note: when using keycloak 17+ change the URL to http://localhost:8080/realms/master/protocol/openid-connect/token Note: this example uses a snapshot build. When Nessie 1.0 is released, the latest stable image will be usable with the instructions from this guide.","title":"Setting up Nessie Server"},{"location":"guides/keycloak/#using-nessie-cli","text":"Now that the Nessie server runs in authenticated mode with a Keycloak, clients have to provide credentials in the form of bearer authentication tokens. For example: nessie --auth-token $NESSIE_AUTH_TOKEN remote show Note: since the name of the NESSIE_AUTH_TOKEN variable matches Nessie CLI configuration naming conventions, the client can automatically find it in the environment, and it does not have to be specified as a command line option. All nessie CLI command will automatically use that token for authenticating their requests. For example: nessie log","title":"Using Nessie CLI"},{"location":"guides/spark-s3/","text":"Accessing data in S3 with Spark \u00b6 In this guide we walk through the process of configuring an Apache Spark session to work with data files stored in Amazon S3 and version history in a local Nessie Server. Docker is used at the runtime environments for Nessie. Spark is assumed to be installed locally. Setting up Nessie Server \u00b6 Start the Nessie server container from the projectnessie/nessie Docker image in default mode. docker run -p 19120 :19120 projectnessie/nessie:latest Note: this example will run the Nessie Server using in-memory storage for table metadata. If/when the container is deleted, Nessie data about table changes will be lost, yet the data files in S3 will remain. Setting up Spark Session \u00b6 Configure an AWS profile (e.g. called demo ) in ~/.aws/credentials (or other location appropriate for your OS) and export the profile name in the AWS_PROFILE environment variable. For example: export AWS_PROFILE = demo Create an S3 bucket of your own. This guide uses the bucket name spark-demo1 . Start a Spark session: spark-sql \\ --packages \\ org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.1, \\ software.amazon.awssdk:bundle:2.17.178, \\ software.amazon.awssdk:url-connection-client:2.17.178 \\ --conf spark.sql.extensions = org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \\ --conf spark.sql.catalog.nessie = org.apache.iceberg.spark.SparkCatalog \\ --conf spark.sql.catalog.nessie.warehouse = s3://spark-demo1 \\ --conf spark.sql.catalog.nessie.catalog-impl = org.apache.iceberg.nessie.NessieCatalog \\ --conf spark.sql.catalog.nessie.io-impl = org.apache.iceberg.aws.s3.S3FileIO \\ --conf spark.sql.catalog.nessie.uri = http://localhost:19120/api/v1 \\ --conf spark.sql.catalog.nessie.ref = main \\ --conf spark.sql.catalog.nessie.cache-enabled = false Note: spark-demo1 is the name of the S3 bucket that will hold table data files. Note: the --packages option lists modules required for Iceberg to write data files into S3. Please refer to Iceberg documentation for the most up-to-date information on how to connect Iceberg to S3. Note: the word nessie in configuration property names is the name of the Nessie catalog in the Spark session. A different name can be chosen according the user\u2019s liking. Then, in spark-sql issue a use statement to make nessie the current catalog: spark-sql> use nessie This command will establish a connection to the Nessie Server. When it is done, it will be possible to create tables and run DML. For example: spark-sql> CREATE TABLE demo (id bigint, data string); Time taken: 1.615 seconds spark-sql> show tables; demo Time taken: 0.425 seconds, Fetched 1 row(s) spark-sql> INSERT INTO demo (id, data) VALUES (1, 'a'); Time taken: 4.017 seconds spark-sql> SELECT * FROM demo; 1 a Time taken: 3.225 seconds, Fetched 1 row(s) Branches, merges and other git-like commands can be run as well, as explained in the Getting Started guide. Note: The above example uses the spark-sql shell, but the same configuration options apply to spark-shell . Authentication \u00b6 This example uses implicit AWS authentication via credentials configured in a credentials file plus the AWS_PROFILE environment variable. The Nessie Server in this example does not require authentication. If the Nessie Server runs with authentication enabled, additional configuration parameters will be required in the Spark session. Please refer to the Authentication in Tools section for details.","title":"Accessing data in S3 with Spark"},{"location":"guides/spark-s3/#accessing-data-in-s3-with-spark","text":"In this guide we walk through the process of configuring an Apache Spark session to work with data files stored in Amazon S3 and version history in a local Nessie Server. Docker is used at the runtime environments for Nessie. Spark is assumed to be installed locally.","title":"Accessing data in S3 with Spark"},{"location":"guides/spark-s3/#setting-up-nessie-server","text":"Start the Nessie server container from the projectnessie/nessie Docker image in default mode. docker run -p 19120 :19120 projectnessie/nessie:latest Note: this example will run the Nessie Server using in-memory storage for table metadata. If/when the container is deleted, Nessie data about table changes will be lost, yet the data files in S3 will remain.","title":"Setting up Nessie Server"},{"location":"guides/spark-s3/#setting-up-spark-session","text":"Configure an AWS profile (e.g. called demo ) in ~/.aws/credentials (or other location appropriate for your OS) and export the profile name in the AWS_PROFILE environment variable. For example: export AWS_PROFILE = demo Create an S3 bucket of your own. This guide uses the bucket name spark-demo1 . Start a Spark session: spark-sql \\ --packages \\ org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.1, \\ software.amazon.awssdk:bundle:2.17.178, \\ software.amazon.awssdk:url-connection-client:2.17.178 \\ --conf spark.sql.extensions = org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \\ --conf spark.sql.catalog.nessie = org.apache.iceberg.spark.SparkCatalog \\ --conf spark.sql.catalog.nessie.warehouse = s3://spark-demo1 \\ --conf spark.sql.catalog.nessie.catalog-impl = org.apache.iceberg.nessie.NessieCatalog \\ --conf spark.sql.catalog.nessie.io-impl = org.apache.iceberg.aws.s3.S3FileIO \\ --conf spark.sql.catalog.nessie.uri = http://localhost:19120/api/v1 \\ --conf spark.sql.catalog.nessie.ref = main \\ --conf spark.sql.catalog.nessie.cache-enabled = false Note: spark-demo1 is the name of the S3 bucket that will hold table data files. Note: the --packages option lists modules required for Iceberg to write data files into S3. Please refer to Iceberg documentation for the most up-to-date information on how to connect Iceberg to S3. Note: the word nessie in configuration property names is the name of the Nessie catalog in the Spark session. A different name can be chosen according the user\u2019s liking. Then, in spark-sql issue a use statement to make nessie the current catalog: spark-sql> use nessie This command will establish a connection to the Nessie Server. When it is done, it will be possible to create tables and run DML. For example: spark-sql> CREATE TABLE demo (id bigint, data string); Time taken: 1.615 seconds spark-sql> show tables; demo Time taken: 0.425 seconds, Fetched 1 row(s) spark-sql> INSERT INTO demo (id, data) VALUES (1, 'a'); Time taken: 4.017 seconds spark-sql> SELECT * FROM demo; 1 a Time taken: 3.225 seconds, Fetched 1 row(s) Branches, merges and other git-like commands can be run as well, as explained in the Getting Started guide. Note: The above example uses the spark-sql shell, but the same configuration options apply to spark-shell .","title":"Setting up Spark Session"},{"location":"guides/spark-s3/#authentication","text":"This example uses implicit AWS authentication via credentials configured in a credentials file plus the AWS_PROFILE environment variable. The Nessie Server in this example does not require authentication. If the Nessie Server runs with authentication enabled, additional configuration parameters will be required in the Spark session. Please refer to the Authentication in Tools section for details.","title":"Authentication"},{"location":"tables/","text":"Overview \u00b6 Nessie is designed to work with table formats that support a write-once, immutable asset and metadata model . These types of formats rely on a transaction arbitrator to decide the order of operations within a table. Nessie developers have named this operation a \u201croot pointer store\u201d (or RPS). This is because these formats all have the same need of determining what is the \u201clatest\u201d version of data. This decision needs to be maintained via a check-and-set operation about what the current state of a table is. Root Pointer Store \u00b6 Each table format provides at least one RPS facility. Existing RPS models include: RPS by convention: E.g. \u201conly one writer is allowed\u201d RPS by consistent fileSystem: E.g. one file can be created with a certain name RPS by external locking: E.g. calling Hive Metastore lock apis Nessie formalizes and extends the concept of an RPS. It adds two main types of operations: coordination of multiple per-table root pointers and historical versioning across changes. This allows users to combine the rich capabilities of existing table formats with the Nessie capabilities around versioning and transactions. Table Formats \u00b6 Nessie currently works with the following formats. Iceberg Tables Delta Lake Tables We expect that Nessie will continue to add table formats as more are created. Iceberg Views \u00b6 In addition to table formats, Nessie also supports storing Iceberg views within the Nessie repository. This allows tools working in tandem with Nessie to provide very powerful versioned, semantic-layering system. See more in our documentation on Iceberg Views . Other Object Types \u00b6 There has been discussion about adding additional types of objects to Nessie for the purpose of creating a consistent repository between input assets (jobs, models, etc.) and output assets. This is something that will be evaluated based on demand. There are currently three options being considered: - more structured object types (such as spark job) - blob types - support for git sub-modules (where Nessie offers a new object type that refers to a particular commit within a git repository) If you have more thoughts on this, please provide feedback on the mailing list .","title":"Overview"},{"location":"tables/#overview","text":"Nessie is designed to work with table formats that support a write-once, immutable asset and metadata model . These types of formats rely on a transaction arbitrator to decide the order of operations within a table. Nessie developers have named this operation a \u201croot pointer store\u201d (or RPS). This is because these formats all have the same need of determining what is the \u201clatest\u201d version of data. This decision needs to be maintained via a check-and-set operation about what the current state of a table is.","title":"Overview"},{"location":"tables/#root-pointer-store","text":"Each table format provides at least one RPS facility. Existing RPS models include: RPS by convention: E.g. \u201conly one writer is allowed\u201d RPS by consistent fileSystem: E.g. one file can be created with a certain name RPS by external locking: E.g. calling Hive Metastore lock apis Nessie formalizes and extends the concept of an RPS. It adds two main types of operations: coordination of multiple per-table root pointers and historical versioning across changes. This allows users to combine the rich capabilities of existing table formats with the Nessie capabilities around versioning and transactions.","title":"Root Pointer Store"},{"location":"tables/#table-formats","text":"Nessie currently works with the following formats. Iceberg Tables Delta Lake Tables We expect that Nessie will continue to add table formats as more are created.","title":"Table Formats"},{"location":"tables/#iceberg-views","text":"In addition to table formats, Nessie also supports storing Iceberg views within the Nessie repository. This allows tools working in tandem with Nessie to provide very powerful versioned, semantic-layering system. See more in our documentation on Iceberg Views .","title":"Iceberg Views"},{"location":"tables/#other-object-types","text":"There has been discussion about adding additional types of objects to Nessie for the purpose of creating a consistent repository between input assets (jobs, models, etc.) and output assets. This is something that will be evaluated based on demand. There are currently three options being considered: - more structured object types (such as spark job) - blob types - support for git sub-modules (where Nessie offers a new object type that refers to a particular commit within a git repository) If you have more thoughts on this, please provide feedback on the mailing list .","title":"Other Object Types"},{"location":"tables/deltalake/","text":"Delta Lake \u00b6 Delta Lake is a table format open-sourced under the Apache License. It provides several benefits including: Single table ACID transactions Scalable metadata Appends, deletes, updates and merges via file re-statements Delta Lake is relatively Spark-centric. It does expose tables via manifests for tools that are not Delta Lake enabled and there are libraries for other tools 1 but the core library relies heavily on Spark. When using Nessie as the backing store for Delta Lake there are no longer restrictions on which types of filesystems/blob stores can be written to. When using Nessie you can write to Delta Lake regardless of the filesystem or number of writers. Client Integration Points \u00b6 Nessie provides a custom LogStore implementation for Delta Lake. Additionally, Nessie currently requires a small change to core Delta Lake code to enable use of Nessie. Without Nessie, Delta Lake normally maintains a single consistent version history through the use of a custom naming scheme within a known directory. While this works for one version history, with multiple additional work is required. As such, Nessie introduces a new abstraction that allows multiple file naming schemes thus enabling multiple version of the same dataset (with separate histories) to exist simultaneously. This is done by adding an extension point to the LogFileHandler interface. Server Integration Points \u00b6 There is a plan for Nessie to run table management tasks related to Delta Lake for manifest generation. This would expose manifests for selected branches and or tags that are maintained as references in HMS. This would target situations where the consumption tool doesn\u2019t have Delta Lake and Nessie libraries. For example, this would enable AWS Athena to consume Nessie-versioned Delta Lake tables via AWS Glue. These libraries look to be unmaintained and leverage old versions of Delta Lake. \u21a9","title":"Delta Lake"},{"location":"tables/deltalake/#delta-lake","text":"Delta Lake is a table format open-sourced under the Apache License. It provides several benefits including: Single table ACID transactions Scalable metadata Appends, deletes, updates and merges via file re-statements Delta Lake is relatively Spark-centric. It does expose tables via manifests for tools that are not Delta Lake enabled and there are libraries for other tools 1 but the core library relies heavily on Spark. When using Nessie as the backing store for Delta Lake there are no longer restrictions on which types of filesystems/blob stores can be written to. When using Nessie you can write to Delta Lake regardless of the filesystem or number of writers.","title":"Delta Lake"},{"location":"tables/deltalake/#client-integration-points","text":"Nessie provides a custom LogStore implementation for Delta Lake. Additionally, Nessie currently requires a small change to core Delta Lake code to enable use of Nessie. Without Nessie, Delta Lake normally maintains a single consistent version history through the use of a custom naming scheme within a known directory. While this works for one version history, with multiple additional work is required. As such, Nessie introduces a new abstraction that allows multiple file naming schemes thus enabling multiple version of the same dataset (with separate histories) to exist simultaneously. This is done by adding an extension point to the LogFileHandler interface.","title":"Client Integration Points"},{"location":"tables/deltalake/#server-integration-points","text":"There is a plan for Nessie to run table management tasks related to Delta Lake for manifest generation. This would expose manifests for selected branches and or tags that are maintained as references in HMS. This would target situations where the consumption tool doesn\u2019t have Delta Lake and Nessie libraries. For example, this would enable AWS Athena to consume Nessie-versioned Delta Lake tables via AWS Glue. These libraries look to be unmaintained and leverage old versions of Delta Lake. \u21a9","title":"Server Integration Points"},{"location":"tables/iceberg/","text":"Apache Iceberg \u00b6 Apache Iceberg is an Apache Software Foundation project that provides a rich, relatively new table format. It provides: Single table ACID transactions Scalable metadata Appends via file addition Updates, deletes and merges via single record operations Iceberg Extension Points \u00b6 Iceberg exposes two primary classes for working with datasets. These are Catalog and TableOperations. Nessie implements each. These classes are available in the Iceberg source code and are available directly in Iceberg releases (eg spark-runtime , spark3-runtime , flink-runtime ). Iceberg Snapshots \u00b6 Iceberg supports the concept of snapshots. Snapshots are point in time versions of a table and are managed as part of each commit operation. Snapshots are limited to single table versioning. Nessie versions and commits provide a broader set of snapshot capabilities as they support multiple tables. Nessie is happy to coexist with Iceberg Snapshots. When working with Nessie, Iceberg snapshots will also be versioned along the rest of Iceberg metadata within the Nessie commit model. Automatic Snapshot Import \u00b6 We are exploring the creation of a tool where a user can import table snapshots across multiple Iceberg tables into a single Nessie repository to capture historical data snapshots (interleaved across time).","title":"Apache Iceberg"},{"location":"tables/iceberg/#apache-iceberg","text":"Apache Iceberg is an Apache Software Foundation project that provides a rich, relatively new table format. It provides: Single table ACID transactions Scalable metadata Appends via file addition Updates, deletes and merges via single record operations","title":"Apache Iceberg"},{"location":"tables/iceberg/#iceberg-extension-points","text":"Iceberg exposes two primary classes for working with datasets. These are Catalog and TableOperations. Nessie implements each. These classes are available in the Iceberg source code and are available directly in Iceberg releases (eg spark-runtime , spark3-runtime , flink-runtime ).","title":"Iceberg Extension Points"},{"location":"tables/iceberg/#iceberg-snapshots","text":"Iceberg supports the concept of snapshots. Snapshots are point in time versions of a table and are managed as part of each commit operation. Snapshots are limited to single table versioning. Nessie versions and commits provide a broader set of snapshot capabilities as they support multiple tables. Nessie is happy to coexist with Iceberg Snapshots. When working with Nessie, Iceberg snapshots will also be versioned along the rest of Iceberg metadata within the Nessie commit model.","title":"Iceberg Snapshots"},{"location":"tables/iceberg/#automatic-snapshot-import","text":"We are exploring the creation of a tool where a user can import table snapshots across multiple Iceberg tables into a single Nessie repository to capture historical data snapshots (interleaved across time).","title":"Automatic Snapshot Import"},{"location":"tables/views/","text":"Apache Iceberg Views \u00b6 Nessie supports versioning Iceberg views. A view is composed of the following properties: Metadata Location Version ID Schema ID SQL Text Dialect (such as Hive, Spark, Dremio, Presto) This enables Iceberg views to be versioned along with underlying datasets to provide a complete place for logical and physical experimentation. Because SQL dialects differ by system, Nessie does not parse or understand SQL. It relies on the creator of SQL statements to validate the provided SQL before being stored in Nessie. Additional information about Iceberg Views can be found in the View Spec Info While Nessie can already store Iceberg Views, further work needs to be done in existing systems to fully expose this functionality.","title":"Apache Iceberg Views"},{"location":"tables/views/#apache-iceberg-views","text":"Nessie supports versioning Iceberg views. A view is composed of the following properties: Metadata Location Version ID Schema ID SQL Text Dialect (such as Hive, Spark, Dremio, Presto) This enables Iceberg views to be versioned along with underlying datasets to provide a complete place for logical and physical experimentation. Because SQL dialects differ by system, Nessie does not parse or understand SQL. It relies on the creator of SQL statements to validate the provided SQL before being stored in Nessie. Additional information about Iceberg Views can be found in the View Spec Info While Nessie can already store Iceberg Views, further work needs to be done in existing systems to fully expose this functionality.","title":"Apache Iceberg Views"},{"location":"tools/","text":"Overview \u00b6 Nessie is focused on working with the widest range of tools possible. If a tool creates or reads data, Nessie seeks to work with it. Current Nessie integrations/tools include the following: Iceberg Integration Spark via Iceberg Flink via Iceberg Hive via Iceberg Delta Lake Integration Spark via Delta Lake Nessie CLI Nessie Web UI Authentication in Tools Nessie Spark SQL Extensions Feature Matrix \u00b6 Spark 2 1 Spark 3 2 Nessie CLI Flink Read Default Branch Read Any Branch/Tag/Hash Write Default Branch Write Any Branch/Tag/Hash Create Branch Create Tag Iceberg Tables Delta Lake Tables Demos \u00b6 The Nessie Demos GitHub repository contains a set of demos that help users understand how Nessie works. Spark 2 currently only supports access via the Dataframe API due to weak generic catalog support. \u21a9 Spark 3 supports both SQL and dataframe access. Consumption can be done via existing Iceberg and Delta Lake catalogs with Nessie extensions or through the Nessie Catalog, which currently exposes both of these formats. \u21a9","title":"Overview"},{"location":"tools/#overview","text":"Nessie is focused on working with the widest range of tools possible. If a tool creates or reads data, Nessie seeks to work with it. Current Nessie integrations/tools include the following: Iceberg Integration Spark via Iceberg Flink via Iceberg Hive via Iceberg Delta Lake Integration Spark via Delta Lake Nessie CLI Nessie Web UI Authentication in Tools Nessie Spark SQL Extensions","title":"Overview"},{"location":"tools/#feature-matrix","text":"Spark 2 1 Spark 3 2 Nessie CLI Flink Read Default Branch Read Any Branch/Tag/Hash Write Default Branch Write Any Branch/Tag/Hash Create Branch Create Tag Iceberg Tables Delta Lake Tables","title":"Feature Matrix"},{"location":"tools/#demos","text":"The Nessie Demos GitHub repository contains a set of demos that help users understand how Nessie works. Spark 2 currently only supports access via the Dataframe API due to weak generic catalog support. \u21a9 Spark 3 supports both SQL and dataframe access. Consumption can be done via existing Iceberg and Delta Lake catalogs with Nessie extensions or through the Nessie Catalog, which currently exposes both of these formats. \u21a9","title":"Demos"},{"location":"tools/auth_config/","text":"Authentication in Tools \u00b6 When Nessie is integrated into a broader data processing environment, authentication settings need to be provided in a way specific to the tool used. Spark \u00b6 When Nessie is used in Spark-based environments (either with Iceberg or Delta Lake ) the Nessie authentication settings are configured via Spark session properties (Replace <catalog_name> with the name of your catalog). Java // local spark instance, assuming NONE authentication conf . set ( \"spark.sql.catalog.<catalog_name>\" , \"org.apache.iceberg.spark.SparkCatalog\" ) . set ( \"spark.sql.catalog.<catalog_name>.authentication.type\" , \"NONE\" ) . set (...); spark = SparkSession . builder () . master ( \"local[2]\" ) . config ( conf ) . getOrCreate (); Python # local spark instance, assuming NONE authentication spark = SparkSession . builder \\ . config ( \"spark.sql.catalog.<catalog_name>\" , \"org.apache.iceberg.spark.SparkCatalog\" ) \\ . config ( \"spark.sql.catalog.<catalog_name>.authentication.type\" , \"NONE\" ) \\ . config ( ... ) . getOrCreate () Flink \u00b6 When Nessie is used in Flink with Iceberg , the Nessie authentication settings are configured when creating the Nessie catalog in Flink (Replace <catalog_name> with the name of your catalog): table_env . execute_sql ( \"\"\"CREATE CATALOG <catalog_name> WITH ( 'type'='iceberg', 'catalog-impl'='org.apache.iceberg.nessie.NessieCatalog', 'authentication.type'='NONE')\"\"\" ) Hive \u00b6 When Nessie is used in Hive with Iceberg , the Nessie authentication settings are configured through Hive Shell (Replace <catalog_name> with the name of your catalog): SET iceberg.catalog.<catalog_name>.catalog-impl=org.apache.iceberg.nessie.NessieCatalog SET iceberg.catalog.<catalog_name>.authentication.type=NONE Property Prefixes \u00b6 The spark.sql.catalog.<catalog_name> prefix identifies properties for the Nessie catalog. The <catalog_name> part is just the name of the catalog in this case (not to be confused with the Nessie project name). Multiple Nessie catalogs can be configured in the same Spark environment, each with its own set of configuration properties and its own property name prefix. Authentication Settings \u00b6 The sections below discuss specific authentication settings. The property names are shown without environment-specific prefixes for brevity. Nonetheless, in practice the property names should be given appropriate prefixes (as in the example above) for them to be recognized by the tools and Nessie code. The value of the authentication.type property can be one of the following: NONE (default) BEARER AWS BASIC (deprecated) Authentication Type NONE \u00b6 For the Authentication Type NONE only the authentication.type property needs to be set. This is also the default authentication type if nothing else is configured. Authentication Type BEARER \u00b6 For the BEARER Authentication Type the authentication.token property should be set to a valid OpenID token . Authentication Type AWS \u00b6 For the AWS Authentication Type the authentication.aws.region property should be set to the AWS region where the Nessie Server endpoint is located. Additional AWS authentication configuration should be provided via standard AWS configuration files. Authentication Type BASIC \u00b6 For the BASIC Authentication Type the authentication.username and authentication.password properties should be set. Note: the BASIC authentication type is considered insecure and Nessie Servers do not support it in production mode. This authentication type is can only be used when the Nessie Server runs in test or \u201cdevelopment\u201d mode.","title":"Authentication in Tools"},{"location":"tools/auth_config/#authentication-in-tools","text":"When Nessie is integrated into a broader data processing environment, authentication settings need to be provided in a way specific to the tool used.","title":"Authentication in Tools"},{"location":"tools/auth_config/#spark","text":"When Nessie is used in Spark-based environments (either with Iceberg or Delta Lake ) the Nessie authentication settings are configured via Spark session properties (Replace <catalog_name> with the name of your catalog). Java // local spark instance, assuming NONE authentication conf . set ( \"spark.sql.catalog.<catalog_name>\" , \"org.apache.iceberg.spark.SparkCatalog\" ) . set ( \"spark.sql.catalog.<catalog_name>.authentication.type\" , \"NONE\" ) . set (...); spark = SparkSession . builder () . master ( \"local[2]\" ) . config ( conf ) . getOrCreate (); Python # local spark instance, assuming NONE authentication spark = SparkSession . builder \\ . config ( \"spark.sql.catalog.<catalog_name>\" , \"org.apache.iceberg.spark.SparkCatalog\" ) \\ . config ( \"spark.sql.catalog.<catalog_name>.authentication.type\" , \"NONE\" ) \\ . config ( ... ) . getOrCreate ()","title":"Spark"},{"location":"tools/auth_config/#flink","text":"When Nessie is used in Flink with Iceberg , the Nessie authentication settings are configured when creating the Nessie catalog in Flink (Replace <catalog_name> with the name of your catalog): table_env . execute_sql ( \"\"\"CREATE CATALOG <catalog_name> WITH ( 'type'='iceberg', 'catalog-impl'='org.apache.iceberg.nessie.NessieCatalog', 'authentication.type'='NONE')\"\"\" )","title":"Flink"},{"location":"tools/auth_config/#hive","text":"When Nessie is used in Hive with Iceberg , the Nessie authentication settings are configured through Hive Shell (Replace <catalog_name> with the name of your catalog): SET iceberg.catalog.<catalog_name>.catalog-impl=org.apache.iceberg.nessie.NessieCatalog SET iceberg.catalog.<catalog_name>.authentication.type=NONE","title":"Hive"},{"location":"tools/auth_config/#property-prefixes","text":"The spark.sql.catalog.<catalog_name> prefix identifies properties for the Nessie catalog. The <catalog_name> part is just the name of the catalog in this case (not to be confused with the Nessie project name). Multiple Nessie catalogs can be configured in the same Spark environment, each with its own set of configuration properties and its own property name prefix.","title":"Property Prefixes"},{"location":"tools/auth_config/#authentication-settings","text":"The sections below discuss specific authentication settings. The property names are shown without environment-specific prefixes for brevity. Nonetheless, in practice the property names should be given appropriate prefixes (as in the example above) for them to be recognized by the tools and Nessie code. The value of the authentication.type property can be one of the following: NONE (default) BEARER AWS BASIC (deprecated)","title":"Authentication Settings"},{"location":"tools/auth_config/#authentication-type-none","text":"For the Authentication Type NONE only the authentication.type property needs to be set. This is also the default authentication type if nothing else is configured.","title":"Authentication Type NONE"},{"location":"tools/auth_config/#authentication-type-bearer","text":"For the BEARER Authentication Type the authentication.token property should be set to a valid OpenID token .","title":"Authentication Type BEARER"},{"location":"tools/auth_config/#authentication-type-aws","text":"For the AWS Authentication Type the authentication.aws.region property should be set to the AWS region where the Nessie Server endpoint is located. Additional AWS authentication configuration should be provided via standard AWS configuration files.","title":"Authentication Type AWS"},{"location":"tools/auth_config/#authentication-type-basic","text":"For the BASIC Authentication Type the authentication.username and authentication.password properties should be set. Note: the BASIC authentication type is considered insecure and Nessie Servers do not support it in production mode. This authentication type is can only be used when the Nessie Server runs in test or \u201cdevelopment\u201d mode.","title":"Authentication Type BASIC"},{"location":"tools/cli/","text":"Nessie CLI \u00b6 The Nessie CLI is an easy way to get started with Nessie. It supports multiple branch and tag management capabilities. This is installed as pynessie via pip install pynessie . Additional information about pynessie and release notes can be found at the PyPI site. Installation \u00b6 # python 3 required pip install pynessie Usage \u00b6 All the REST API calls are exposed via the command line interface. To see a list of what is available run: $ nessie --help All docs of the CLI can be found here . Configuration \u00b6 You can configure the Nessie CLI by creating a configuration file as described below: macOS: ~/.config/nessie and ~/Library/Application Support/nessie Other Unix: ~/.config/nessie and /etc/nessie Windows: %APPDATA%\\nessie where the APPDATA environment variable falls back to %HOME%\\AppData\\Roaming if undefined Via the environment variable DREMIO_CLIENTDIR The default config file is as follows: auth : # Authentication type can be: none, bearer or aws type : none # OpenID token for the \"bearer\" authentication type # token: <OpenID token> timeout : 10 # Nessie endpoint endpoint : http://localhost/api/v1 # whether to skip SSL cert verification verify : true Possible values for the auth.type property are: none (default) bearer aws basic (deprecated) When configuring authentication type bearer , the auth.token parameter should be set to a valid OpenID token . The token can be set in the Nessie configuration file, as an environment variable (details below), or by the --auth-token <TOKEN> command line option (for each command). When configuring authentication type aws , the client delegates to the Boto library. You can configure credentials using any of the standard Boto AWS methods . Additionally, the Nessie auth.region parameter should be set to the relevant AWS region. When configuring authentication type basic , both auth.username and auth.password parameters should be set. Note: the basic authentication type is considered insecure and Nessie Servers do not support it in production mode. This authentication type is can only be used when the Nessie Server runs in test or \u201cdevelopment\u201d mode. The command line interface can be configured with most of the above parameters via flags or by setting a config directory. The relevant configs can also be set via environment variables. These take precedence. The environment variable format is to append NESSIE_ to a config parameter and nested configs are separated by a _ . For example: NESSIE_AUTH_TIMEOUT maps to auth.timeout in the default configuration file above. Working with JSON \u00b6 The Nessie CLI can return data in json format and can be used effectively with jq . For example: $ nessie --json branch -l | jq . The Nessie CLI is built on the great Python Click library. It requires Python 3.x.","title":"Nessie CLI"},{"location":"tools/cli/#nessie-cli","text":"The Nessie CLI is an easy way to get started with Nessie. It supports multiple branch and tag management capabilities. This is installed as pynessie via pip install pynessie . Additional information about pynessie and release notes can be found at the PyPI site.","title":"Nessie CLI"},{"location":"tools/cli/#installation","text":"# python 3 required pip install pynessie","title":"Installation"},{"location":"tools/cli/#usage","text":"All the REST API calls are exposed via the command line interface. To see a list of what is available run: $ nessie --help All docs of the CLI can be found here .","title":"Usage"},{"location":"tools/cli/#configuration","text":"You can configure the Nessie CLI by creating a configuration file as described below: macOS: ~/.config/nessie and ~/Library/Application Support/nessie Other Unix: ~/.config/nessie and /etc/nessie Windows: %APPDATA%\\nessie where the APPDATA environment variable falls back to %HOME%\\AppData\\Roaming if undefined Via the environment variable DREMIO_CLIENTDIR The default config file is as follows: auth : # Authentication type can be: none, bearer or aws type : none # OpenID token for the \"bearer\" authentication type # token: <OpenID token> timeout : 10 # Nessie endpoint endpoint : http://localhost/api/v1 # whether to skip SSL cert verification verify : true Possible values for the auth.type property are: none (default) bearer aws basic (deprecated) When configuring authentication type bearer , the auth.token parameter should be set to a valid OpenID token . The token can be set in the Nessie configuration file, as an environment variable (details below), or by the --auth-token <TOKEN> command line option (for each command). When configuring authentication type aws , the client delegates to the Boto library. You can configure credentials using any of the standard Boto AWS methods . Additionally, the Nessie auth.region parameter should be set to the relevant AWS region. When configuring authentication type basic , both auth.username and auth.password parameters should be set. Note: the basic authentication type is considered insecure and Nessie Servers do not support it in production mode. This authentication type is can only be used when the Nessie Server runs in test or \u201cdevelopment\u201d mode. The command line interface can be configured with most of the above parameters via flags or by setting a config directory. The relevant configs can also be set via environment variables. These take precedence. The environment variable format is to append NESSIE_ to a config parameter and nested configs are separated by a _ . For example: NESSIE_AUTH_TIMEOUT maps to auth.timeout in the default configuration file above.","title":"Configuration"},{"location":"tools/cli/#working-with-json","text":"The Nessie CLI can return data in json format and can be used effectively with jq . For example: $ nessie --json branch -l | jq . The Nessie CLI is built on the great Python Click library. It requires Python 3.x.","title":"Working with JSON"},{"location":"tools/sql/","text":"Nessie Spark SQL Extensions \u00b6 Spark SQL extensions provide an easy way to execute common Nessie commands via SQL. How to use them \u00b6 Spark 3.1 \u00b6 In order to be able to use Nessie\u2019s custom Spark SQL extensions, one needs to configure org.projectnessie:nessie-spark-extensions:0.30.0 along with org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0 . Here\u2019s an example of how this is done when starting the spark-sql shell: bin/spark-sql --packages \"org.apache.iceberg:iceberg-spark3-runtime-0.13.0:0.13.0,org.projectnessie:nessie-spark-extensions:0.30.0\" --conf spark.sql.extensions=\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions\" --conf <other settings> Spark 3.2 \u00b6 In order to be able to use Nessie\u2019s custom Spark SQL extensions with Spark 3.2.x, one needs to configure org.projectnessie:nessie-spark-3.2-extensions:0.30.0 along with org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0 . Here\u2019s an example of how this is done when starting the spark-sql shell: bin/spark-sql --packages \"org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0,org.projectnessie:nessie-spark-3.2-extensions:0.30.0\" --conf spark.sql.extensions=\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSpark32SessionExtensions\" --conf <other settings> Additional configuration details can be found in the Spark via Iceberg docs. Grammar \u00b6 The current grammar is shown below: : CREATE (BRANCH|TAG) (IF NOT EXISTS)? reference=identifier (IN catalog=identifier)? (FROM fromRef=identifier)? | DROP (BRANCH|TAG) identifier (IN catalog=identifier)? | USE REFERENCE reference=identifier (AT tsOrHash=identifier)? (IN catalog=identifier)? | LIST REFERENCES (IN catalog=identifier)? | SHOW REFERENCE (IN catalog=identifier)? | MERGE BRANCH (reference=identifier)? (INTO toRef=identifier)? (IN catalog=identifier)? | SHOW LOG (reference=identifier)? (IN catalog=identifier)? | ASSIGN (BRANCH|TAG) (reference=identifier)? (TO toRef=identifier)? (IN catalog=identifier)? Creating Branches/Tags \u00b6 Creating a branch dev in the nessie catalog (in case it doesn\u2019t already exist): CREATE BRANCH IF NOT EXISTS dev IN nessie Creating a tag devTag in the nessie catalog (in case it doesn\u2019t already exist): CREATE TAG IF NOT EXISTS devTag IN nessie Creating a branch dev in the nessie catalog off of an existing branch/tag base : CREATE BRANCH IF NOT EXISTS dev IN nessie FROM base Note that in case base doesn\u2019t exist, Nessie will fall back to the default branch ( main ). Dropping Branches/Tags \u00b6 Dropping a branch dev in the nessie catalog (in case it exists): DROP BRANCH IF EXISTS dev IN nessie Dropping a tag devTag in the nessie catalog (in case it exists): DROP TAG IF EXISTS devTag IN nessie Switching to a Branch/Tag \u00b6 In order to switch to the HEAD of the branch/tag ref in the nessie catalog: USE REFERENCE ref IN nessie It is also possible to switch to a specific timestamp on a given branch/tag: USE REFERENCE ref AT `2021-10-06T08:50:37.157602` IN nessie Additionally, one can switch to a specific hash on a given branch/tag: USE REFERENCE ref AT dd8d46a3dd5478ce69749a5455dba29d74f6d1171188f4c21d0e15ff4a0a9a9b IN nessie Listing available Branches/Tags \u00b6 One can list available branches/tags in the nessie catalog via: LIST REFERENCES IN nessie Showing details of the current Branch/Tag \u00b6 One can see details about the current branch/tag in the nessie catalog via: SHOW REFERENCE IN nessie Showing the Commit Log of the current Branch/Tag \u00b6 It is possible to look at the commit log of a particular branch/tag in the nessie catalog via: SHOW LOG dev IN nessie Assigning Branches/Tags \u00b6 Assigning a branch dev to base in catalog nessie can be done via: ASSIGN BRANCH dev TO base IN nessie Assigning a tag devTag to base in catalog nessie can be done via: ASSIGN TAG devTag TO base IN nessie Note that in case base doesn\u2019t exist, Nessie will fall back to the default branch ( main ). It is also possible to assign a branch/tag to a base at a particular hash : ASSIGN TAG devTag TO base AT dd8d46a3dd5478ce69749a5455dba29d74f6d1171188f4c21d0e15ff4a0a9a9b IN nessie Merging a Branch into another Branch \u00b6 Merging branch dev into base for the nessie catalog can be done via: MERGE BRANCH dev INTO base IN nessie Note that in case base doesn\u2019t exist, Nessie will fall back to the default branch ( main ).","title":"Nessie Spark SQL Extensions"},{"location":"tools/sql/#nessie-spark-sql-extensions","text":"Spark SQL extensions provide an easy way to execute common Nessie commands via SQL.","title":"Nessie Spark SQL Extensions"},{"location":"tools/sql/#how-to-use-them","text":"","title":"How to use them"},{"location":"tools/sql/#spark-31","text":"In order to be able to use Nessie\u2019s custom Spark SQL extensions, one needs to configure org.projectnessie:nessie-spark-extensions:0.30.0 along with org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0 . Here\u2019s an example of how this is done when starting the spark-sql shell: bin/spark-sql --packages \"org.apache.iceberg:iceberg-spark3-runtime-0.13.0:0.13.0,org.projectnessie:nessie-spark-extensions:0.30.0\" --conf spark.sql.extensions=\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions\" --conf <other settings>","title":"Spark 3.1"},{"location":"tools/sql/#spark-32","text":"In order to be able to use Nessie\u2019s custom Spark SQL extensions with Spark 3.2.x, one needs to configure org.projectnessie:nessie-spark-3.2-extensions:0.30.0 along with org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0 . Here\u2019s an example of how this is done when starting the spark-sql shell: bin/spark-sql --packages \"org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0,org.projectnessie:nessie-spark-3.2-extensions:0.30.0\" --conf spark.sql.extensions=\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSpark32SessionExtensions\" --conf <other settings> Additional configuration details can be found in the Spark via Iceberg docs.","title":"Spark 3.2"},{"location":"tools/sql/#grammar","text":"The current grammar is shown below: : CREATE (BRANCH|TAG) (IF NOT EXISTS)? reference=identifier (IN catalog=identifier)? (FROM fromRef=identifier)? | DROP (BRANCH|TAG) identifier (IN catalog=identifier)? | USE REFERENCE reference=identifier (AT tsOrHash=identifier)? (IN catalog=identifier)? | LIST REFERENCES (IN catalog=identifier)? | SHOW REFERENCE (IN catalog=identifier)? | MERGE BRANCH (reference=identifier)? (INTO toRef=identifier)? (IN catalog=identifier)? | SHOW LOG (reference=identifier)? (IN catalog=identifier)? | ASSIGN (BRANCH|TAG) (reference=identifier)? (TO toRef=identifier)? (IN catalog=identifier)?","title":"Grammar"},{"location":"tools/sql/#creating-branchestags","text":"Creating a branch dev in the nessie catalog (in case it doesn\u2019t already exist): CREATE BRANCH IF NOT EXISTS dev IN nessie Creating a tag devTag in the nessie catalog (in case it doesn\u2019t already exist): CREATE TAG IF NOT EXISTS devTag IN nessie Creating a branch dev in the nessie catalog off of an existing branch/tag base : CREATE BRANCH IF NOT EXISTS dev IN nessie FROM base Note that in case base doesn\u2019t exist, Nessie will fall back to the default branch ( main ).","title":"Creating Branches/Tags"},{"location":"tools/sql/#dropping-branchestags","text":"Dropping a branch dev in the nessie catalog (in case it exists): DROP BRANCH IF EXISTS dev IN nessie Dropping a tag devTag in the nessie catalog (in case it exists): DROP TAG IF EXISTS devTag IN nessie","title":"Dropping Branches/Tags"},{"location":"tools/sql/#switching-to-a-branchtag","text":"In order to switch to the HEAD of the branch/tag ref in the nessie catalog: USE REFERENCE ref IN nessie It is also possible to switch to a specific timestamp on a given branch/tag: USE REFERENCE ref AT `2021-10-06T08:50:37.157602` IN nessie Additionally, one can switch to a specific hash on a given branch/tag: USE REFERENCE ref AT dd8d46a3dd5478ce69749a5455dba29d74f6d1171188f4c21d0e15ff4a0a9a9b IN nessie","title":"Switching to a Branch/Tag"},{"location":"tools/sql/#listing-available-branchestags","text":"One can list available branches/tags in the nessie catalog via: LIST REFERENCES IN nessie","title":"Listing available Branches/Tags"},{"location":"tools/sql/#showing-details-of-the-current-branchtag","text":"One can see details about the current branch/tag in the nessie catalog via: SHOW REFERENCE IN nessie","title":"Showing details of the current Branch/Tag"},{"location":"tools/sql/#showing-the-commit-log-of-the-current-branchtag","text":"It is possible to look at the commit log of a particular branch/tag in the nessie catalog via: SHOW LOG dev IN nessie","title":"Showing the Commit Log of the current Branch/Tag"},{"location":"tools/sql/#assigning-branchestags","text":"Assigning a branch dev to base in catalog nessie can be done via: ASSIGN BRANCH dev TO base IN nessie Assigning a tag devTag to base in catalog nessie can be done via: ASSIGN TAG devTag TO base IN nessie Note that in case base doesn\u2019t exist, Nessie will fall back to the default branch ( main ). It is also possible to assign a branch/tag to a base at a particular hash : ASSIGN TAG devTag TO base AT dd8d46a3dd5478ce69749a5455dba29d74f6d1171188f4c21d0e15ff4a0a9a9b IN nessie","title":"Assigning Branches/Tags"},{"location":"tools/sql/#merging-a-branch-into-another-branch","text":"Merging branch dev into base for the nessie catalog can be done via: MERGE BRANCH dev INTO base IN nessie Note that in case base doesn\u2019t exist, Nessie will fall back to the default branch ( main ).","title":"Merging a Branch into another Branch"},{"location":"tools/ui/","text":"Web UI \u00b6 Nessie comes with a simple web UI that allows you to understand what is in your Nessie repository. You can view existing tags and branches as well as the content within them. The UI automatically runs as part of starting the Nessie service. If running locally, you can find the UI at localhost:19120 . Swagger UI \u00b6 The Swagger UI allows for testing the REST API and reading the API docs. It is available at localhost:19120/q/swagger-ui .","title":"Web UI"},{"location":"tools/ui/#web-ui","text":"Nessie comes with a simple web UI that allows you to understand what is in your Nessie repository. You can view existing tags and branches as well as the content within them. The UI automatically runs as part of starting the Nessie service. If running locally, you can find the UI at localhost:19120 .","title":"Web UI"},{"location":"tools/ui/#swagger-ui","text":"The Swagger UI allows for testing the REST API and reading the API docs. It is available at localhost:19120/q/swagger-ui .","title":"Swagger UI"},{"location":"tools/deltalake/","text":"Overview \u00b6 Delta Lake support in Nessie requires some minor modifications to the core Delta libraries. This patch is still ongoing, in the meantime Nessie will not work on Databricks and must be used with the open source Delta. Nessie is able to interact with Delta Lake by implementing a custom version of Delta\u2019s LogStore interface . This ensures that all filesystem changes are recorded by Nessie as commits. The benefit of this approach is the core ACID primitives are handled by Nessie. The limitations around concurrency that Delta would normally have are removed, any number of readers and writers can simultaneously interact with a Nessie managed Delta Lake table. Current Nessie Delta Lake integration include the following: Spark via Delta Lake","title":"Overview"},{"location":"tools/deltalake/#overview","text":"Delta Lake support in Nessie requires some minor modifications to the core Delta libraries. This patch is still ongoing, in the meantime Nessie will not work on Databricks and must be used with the open source Delta. Nessie is able to interact with Delta Lake by implementing a custom version of Delta\u2019s LogStore interface . This ensures that all filesystem changes are recorded by Nessie as commits. The benefit of this approach is the core ACID primitives are handled by Nessie. The limitations around concurrency that Delta would normally have are removed, any number of readers and writers can simultaneously interact with a Nessie managed Delta Lake table. Current Nessie Delta Lake integration include the following: Spark via Delta Lake","title":"Overview"},{"location":"tools/deltalake/spark/","text":"Spark via Delta Lake \u00b6 Note Detailed steps on how to set up Pyspark + Delta Lake + Nessie with Python is available on Binder . To access Nessie from a spark cluster make sure the spark.jars.packages option is set to include the Nessie Deltalake Client for Spark 3 jar. These jars contain all Nessie and Delta Lake libraries required for operation. In pyspark this would look like SparkSession . builder . config ( 'spark.jars.packages' , 'org.projectnessie:nessie-deltalake:0.30.0' ) ... rest of spark config . getOrCreate () In order to utilize the additional SQL grammar from the Nessie Spark SQL Extensions make sure to also include org.projectnessie:nessie-spark-3.2-extensions:0.30.0 and to set the spark.sql.extensions config option accordingly (see examples below). The Nessie LogStore needs the following parameters set in the Spark/Hadoop config. nessie.url = full url to nessie nessie.authentication.type = authentication type spark.delta.logFileHandler.class=org.projectnessie.deltalake.NessieLogFileMetaParser spark.delta.logStore.class=org.projectnessie.deltalake.NessieLogStore These are set as follows in code (or through other methods as described here ) Java //for a local spark instance conf . set ( \"spark.jars.packages\" , \"org.projectnessie:nessie-deltalake:0.30.0,org.projectnessie:nessie-spark-3.2-extensions:0.30.0\" ) . set ( \"spark.hadoop.nessie.url\" , url ) . set ( \"spark.hadoop.nessie.ref\" , branch ) . set ( \"spark.hadoop.nessie.authentication.type\" , authType ) . set ( \"spark.sql.catalog.spark_catalog\" , \"org.apache.spark.sql.delta.catalog.DeltaCatalog\" ) . set ( \"spark.sql.extensions\" , \"io.delta.sql.DeltaSparkSessionExtension,org.projectnessie.spark.extensions.NessieSpark32SessionExtensions\" ) . set ( \"spark.delta.logStore.class\" , \"org.projectnessie.deltalake.NessieLogStore\" ) . set ( \"spark.delta.logFileHandler.class\" , \"org.projectnessie.deltalake.NessieLogFileMetaParser\" ); spark = SparkSession . builder () . master ( \"local[2]\" ) . config ( conf ) . getOrCreate (); Python # here we are assuming NONE authorisation spark = SparkSession . builder \\ . config ( \"spark.jars.packages\" , \"org.projectnessie:nessie-deltalake:0.30.0,org.projectnessie:nessie-spark-3.2-extensions:0.30.0\" ) \\ . config ( \"spark.hadoop.nessie.url\" , \"http://localhost:19120/api/v1\" ) \\ . config ( \"spark.hadoop.nessie.ref\" , \"main\" ) \\ . config ( \"spark.sql.catalog.spark_catalog\" , \"org.apache.spark.sql.delta.catalog.DeltaCatalog\" ) \\ . config ( \"spark.sql.extensions\" , \"io.delta.sql.DeltaSparkSessionExtension,org.projectnessie.spark.extensions.NessieSpark32SessionExtensions\" ) \\ . config ( \"spark.delta.logFileHandler.class\" , \"org.projectnessie.deltalake.NessieLogFileMetaParser\" ) \\ . config ( \"spark.delta.logStore.class\" , \"org.projectnessie.deltalake.NessieLogStore\" ) \\ . getOrCreate () Additional authentication settings are documented in the Authentication in Tools section. Note above we specified the option spark.hadoop.nessie.ref . This value sets the default branch that the delta catalog will use. This can be changed by changing the hadoopConfiguration however best practice would be to use a single write context (branch) for the duration of the spark session. The key to enabling Nessie is to instruct Delta to use the Nessie specific LogStore and LogFileHandler . With these enabled the Delta core library will delegate transaction handling to Nessie. Finally, note we have explicitly enabled Delta\u2019s SQL extensions which enable Delta specific SQL in Spark3. Warning Currently Delta metadata operations like VACUUM are destructive to Nessie managed Delta tables. Do not run these operations. Future versions of Nessie will disable these commands when Nessie is activated. Writing \u00b6 Spark support is constantly evolving and the differences in Spark3 vs Spark2.4 is considerable. See the delta docs for an up-to-date support table. Spark 3 supports reads, appends, overwrites in Delta via data frames as well as SQL syntax. Nessie tables in delta can be written via the Nessi enabled Delta client. The Delta writer allows for either overwrite or append mode in a standard spark.write . Java regionDf = spark . read (). load ( \"data/region.parquet\" ); regionDf . write (). format ( \"delta\" ). mode ( \"overwrite\" ) . save ( \"/location/to/delta/testing/region\" ); Python region_df = spark . read . load ( \"data/region.parquet\" ) region_df . write . format ( \"delta\" ) . mode ( \"overwrite\" ) \\ . save ( \"/location/to/delta/testing/region\" ) SQL CREATE TABLE nessie . testing . city ( C_CITYKEY BIGINT , C_NAME STRING , N_NATIONKEY BIGINT , C_COMMENT STRING ) USING delta PARTITIONED BY ( N_NATIONKEY ) LOCATION 'path/to/delta/testing/city' -- SELECT .. can be added to the sql statement to perform a CTAS INSERT [ OVERWRITE ] INTO nessie . testing . city VALUES ( 1 , 'a' , 1 , 'comment' ) Here we simply read a file from the default filesystem and write it to a new nessie Delta table. This will trigger a commit on current context\u2019s branch. For the examples above we have performed commits on the branch specified when we set our spark configuration. Had we not specified the context in our spark configuration all operations would have defaulted to the default branch defined by the server. This is a strong pattern for a spark job which is for example writing data as part of a wider ETL job. It will only ever need one context or branch to write to. If however you are running an interactive session and would like to write to a specific branch without changing context the following should be used to change the context. Java spark . sparkContext (). hadoopConfiguration (). set ( \"nessie.ref\" , \"dev\" ); regionDf = spark . read (). load ( \"data/region.parquet\" ); regionDf . write (). format ( \"delta\" ). mode ( \"overwrite\" ) . save ( \"/location/to/delta/testing/region\" ); Python spark . sparkContext . _jsc . hadoopConfiguration () . set ( \"nessie.ref\" , \"dev\" ) region_df = spark . read . load ( \"data/region.parquet\" ) region_df . write . format ( \"delta\" ) . mode ( \"overwrite\" ) \\ . save ( \"/location/to/delta/testing/region\" ) SQL -- change hadoop configuration externally using the Java or Python syntax CREATE TABLE nessie . testing . city ( C_CITYKEY BIGINT , C_NAME STRING , N_NATIONKEY BIGINT , C_COMMENT STRING ) USING iceberg PARTITIONED BY ( N_NATIONKEY ) -- AS SELECT .. can be added to the sql statement to perform a CTAS INSERT INTO nessie . testing . city VALUES ( 1 , 'a' , 1 , 'comment' ) We have to manually change the hadoopConfiguration for the SparkContext for a Delta table to be initialised with the correct reference. This will change in the near future when it will be possible to use the same branch@ref syntax as Iceberg inside of delta. Currently, it isn\u2019t possible to change the ref from SQL directly. This should be fixed in an upcoming release. Note Delta by default caches tables internally. If an action has to happen on the same table but a different branch the cache first should be cleared. DeltaLog.clearCache() . Reading \u00b6 To read a Nessie table in Delta Lake simply: Java regionDf = spark . read (). format ( \"delta\" ) . load ( \"/path/to/delta/testing/region\" ); Python region_df = spark . read . format ( \"delta\" ) \\ . load ( \"/path/to/delta/testing/region\" ) SQL SELECT * FROM '/path/to/delta/testing/region' The examples above all use the default branch defined on initialisation. Future versions will add the ability to specify a branch and timestamp similar to Iceberg. Currently, to switch branches a similar technique as writing is required (manually changing the hadoopConfiguration). History can be viewed on the command line or via the python client and a specific hash based on commit time can be extracted for use in the spark config. It is recommended to use the time-travel features of Nessie over the Delta features as Nessie history is consistent across the entire database.","title":"Spark via Delta Lake"},{"location":"tools/deltalake/spark/#spark-via-delta-lake","text":"Note Detailed steps on how to set up Pyspark + Delta Lake + Nessie with Python is available on Binder . To access Nessie from a spark cluster make sure the spark.jars.packages option is set to include the Nessie Deltalake Client for Spark 3 jar. These jars contain all Nessie and Delta Lake libraries required for operation. In pyspark this would look like SparkSession . builder . config ( 'spark.jars.packages' , 'org.projectnessie:nessie-deltalake:0.30.0' ) ... rest of spark config . getOrCreate () In order to utilize the additional SQL grammar from the Nessie Spark SQL Extensions make sure to also include org.projectnessie:nessie-spark-3.2-extensions:0.30.0 and to set the spark.sql.extensions config option accordingly (see examples below). The Nessie LogStore needs the following parameters set in the Spark/Hadoop config. nessie.url = full url to nessie nessie.authentication.type = authentication type spark.delta.logFileHandler.class=org.projectnessie.deltalake.NessieLogFileMetaParser spark.delta.logStore.class=org.projectnessie.deltalake.NessieLogStore These are set as follows in code (or through other methods as described here ) Java //for a local spark instance conf . set ( \"spark.jars.packages\" , \"org.projectnessie:nessie-deltalake:0.30.0,org.projectnessie:nessie-spark-3.2-extensions:0.30.0\" ) . set ( \"spark.hadoop.nessie.url\" , url ) . set ( \"spark.hadoop.nessie.ref\" , branch ) . set ( \"spark.hadoop.nessie.authentication.type\" , authType ) . set ( \"spark.sql.catalog.spark_catalog\" , \"org.apache.spark.sql.delta.catalog.DeltaCatalog\" ) . set ( \"spark.sql.extensions\" , \"io.delta.sql.DeltaSparkSessionExtension,org.projectnessie.spark.extensions.NessieSpark32SessionExtensions\" ) . set ( \"spark.delta.logStore.class\" , \"org.projectnessie.deltalake.NessieLogStore\" ) . set ( \"spark.delta.logFileHandler.class\" , \"org.projectnessie.deltalake.NessieLogFileMetaParser\" ); spark = SparkSession . builder () . master ( \"local[2]\" ) . config ( conf ) . getOrCreate (); Python # here we are assuming NONE authorisation spark = SparkSession . builder \\ . config ( \"spark.jars.packages\" , \"org.projectnessie:nessie-deltalake:0.30.0,org.projectnessie:nessie-spark-3.2-extensions:0.30.0\" ) \\ . config ( \"spark.hadoop.nessie.url\" , \"http://localhost:19120/api/v1\" ) \\ . config ( \"spark.hadoop.nessie.ref\" , \"main\" ) \\ . config ( \"spark.sql.catalog.spark_catalog\" , \"org.apache.spark.sql.delta.catalog.DeltaCatalog\" ) \\ . config ( \"spark.sql.extensions\" , \"io.delta.sql.DeltaSparkSessionExtension,org.projectnessie.spark.extensions.NessieSpark32SessionExtensions\" ) \\ . config ( \"spark.delta.logFileHandler.class\" , \"org.projectnessie.deltalake.NessieLogFileMetaParser\" ) \\ . config ( \"spark.delta.logStore.class\" , \"org.projectnessie.deltalake.NessieLogStore\" ) \\ . getOrCreate () Additional authentication settings are documented in the Authentication in Tools section. Note above we specified the option spark.hadoop.nessie.ref . This value sets the default branch that the delta catalog will use. This can be changed by changing the hadoopConfiguration however best practice would be to use a single write context (branch) for the duration of the spark session. The key to enabling Nessie is to instruct Delta to use the Nessie specific LogStore and LogFileHandler . With these enabled the Delta core library will delegate transaction handling to Nessie. Finally, note we have explicitly enabled Delta\u2019s SQL extensions which enable Delta specific SQL in Spark3. Warning Currently Delta metadata operations like VACUUM are destructive to Nessie managed Delta tables. Do not run these operations. Future versions of Nessie will disable these commands when Nessie is activated.","title":"Spark via Delta Lake"},{"location":"tools/deltalake/spark/#writing","text":"Spark support is constantly evolving and the differences in Spark3 vs Spark2.4 is considerable. See the delta docs for an up-to-date support table. Spark 3 supports reads, appends, overwrites in Delta via data frames as well as SQL syntax. Nessie tables in delta can be written via the Nessi enabled Delta client. The Delta writer allows for either overwrite or append mode in a standard spark.write . Java regionDf = spark . read (). load ( \"data/region.parquet\" ); regionDf . write (). format ( \"delta\" ). mode ( \"overwrite\" ) . save ( \"/location/to/delta/testing/region\" ); Python region_df = spark . read . load ( \"data/region.parquet\" ) region_df . write . format ( \"delta\" ) . mode ( \"overwrite\" ) \\ . save ( \"/location/to/delta/testing/region\" ) SQL CREATE TABLE nessie . testing . city ( C_CITYKEY BIGINT , C_NAME STRING , N_NATIONKEY BIGINT , C_COMMENT STRING ) USING delta PARTITIONED BY ( N_NATIONKEY ) LOCATION 'path/to/delta/testing/city' -- SELECT .. can be added to the sql statement to perform a CTAS INSERT [ OVERWRITE ] INTO nessie . testing . city VALUES ( 1 , 'a' , 1 , 'comment' ) Here we simply read a file from the default filesystem and write it to a new nessie Delta table. This will trigger a commit on current context\u2019s branch. For the examples above we have performed commits on the branch specified when we set our spark configuration. Had we not specified the context in our spark configuration all operations would have defaulted to the default branch defined by the server. This is a strong pattern for a spark job which is for example writing data as part of a wider ETL job. It will only ever need one context or branch to write to. If however you are running an interactive session and would like to write to a specific branch without changing context the following should be used to change the context. Java spark . sparkContext (). hadoopConfiguration (). set ( \"nessie.ref\" , \"dev\" ); regionDf = spark . read (). load ( \"data/region.parquet\" ); regionDf . write (). format ( \"delta\" ). mode ( \"overwrite\" ) . save ( \"/location/to/delta/testing/region\" ); Python spark . sparkContext . _jsc . hadoopConfiguration () . set ( \"nessie.ref\" , \"dev\" ) region_df = spark . read . load ( \"data/region.parquet\" ) region_df . write . format ( \"delta\" ) . mode ( \"overwrite\" ) \\ . save ( \"/location/to/delta/testing/region\" ) SQL -- change hadoop configuration externally using the Java or Python syntax CREATE TABLE nessie . testing . city ( C_CITYKEY BIGINT , C_NAME STRING , N_NATIONKEY BIGINT , C_COMMENT STRING ) USING iceberg PARTITIONED BY ( N_NATIONKEY ) -- AS SELECT .. can be added to the sql statement to perform a CTAS INSERT INTO nessie . testing . city VALUES ( 1 , 'a' , 1 , 'comment' ) We have to manually change the hadoopConfiguration for the SparkContext for a Delta table to be initialised with the correct reference. This will change in the near future when it will be possible to use the same branch@ref syntax as Iceberg inside of delta. Currently, it isn\u2019t possible to change the ref from SQL directly. This should be fixed in an upcoming release. Note Delta by default caches tables internally. If an action has to happen on the same table but a different branch the cache first should be cleared. DeltaLog.clearCache() .","title":"Writing"},{"location":"tools/deltalake/spark/#reading","text":"To read a Nessie table in Delta Lake simply: Java regionDf = spark . read (). format ( \"delta\" ) . load ( \"/path/to/delta/testing/region\" ); Python region_df = spark . read . format ( \"delta\" ) \\ . load ( \"/path/to/delta/testing/region\" ) SQL SELECT * FROM '/path/to/delta/testing/region' The examples above all use the default branch defined on initialisation. Future versions will add the ability to specify a branch and timestamp similar to Iceberg. Currently, to switch branches a similar technique as writing is required (manually changing the hadoopConfiguration). History can be viewed on the command line or via the python client and a specific hash based on commit time can be extracted for use in the spark config. It is recommended to use the time-travel features of Nessie over the Delta features as Nessie history is consistent across the entire database.","title":"Reading"},{"location":"tools/iceberg/","text":"Overview \u00b6 Nessie works seamlessly with Iceberg in Spark2 and Spark3. Nessie is implemented as a custom Iceberg catalog and therefore supports all features available to any Iceberg client. This includes Spark structured streaming, Presto, Flink and Hive. See the Iceberg docs for more info. Current Nessie Iceberg integration includes the following: Spark via Iceberg Flink via Iceberg Hive via Iceberg","title":"Overview"},{"location":"tools/iceberg/#overview","text":"Nessie works seamlessly with Iceberg in Spark2 and Spark3. Nessie is implemented as a custom Iceberg catalog and therefore supports all features available to any Iceberg client. This includes Spark structured streaming, Presto, Flink and Hive. See the Iceberg docs for more info. Current Nessie Iceberg integration includes the following: Spark via Iceberg Flink via Iceberg Hive via Iceberg","title":"Overview"},{"location":"tools/iceberg/flink/","text":"Flink via Iceberg \u00b6 Note Detailed steps on how to set up Pyspark + Iceberg + Flink + Nessie with Python is available on Binder In order to use Flink with Python API, you will need to make sure pyflink have access to all Hadoop JARs as mentioned in these docs . After that, you will need to make sure iceberg-flink-runtime is added to Flink. This can be done by adding the iceberg JAR to pyflink via env.add_jar , e.g: env.add_jars(\"file://path/to/jar/iceberg-flink-runtime-0.13.0.jar\") . This can be shown below: import os from pyflink.datastream import StreamExecutionEnvironment env = StreamExecutionEnvironment . get_execution_environment () iceberg_flink_runtime_jar = os . path . join ( os . getcwd (), \"iceberg-flink-runtime-0.13.0.jar\" ) env . add_jars ( \"file:// {} \" . format ( iceberg_flink_runtime_jar )) Once we have added iceberg-flink-runtime JAR to pyflink , we can then create StreamTableEnvironment and execute Flink SQL statements. This can be shown in the following example: from pyflink.table import StreamTableEnvironment table_env = StreamTableEnvironment . create ( env ) table_env . execute_sql ( \"\"\"CREATE CATALOG <catalog_name> WITH ( 'type'='iceberg', 'catalog-impl'='org.apache.iceberg.nessie.NessieCatalog', 'uri'='http://localhost:19120/api/v1', 'ref'='main', 'warehouse' = '/path/to/flink/warehouse')\"\"\" ) With the above statement, we have created a Nessie catalog (via Iceberg) that Flink will use to manage the tables. For more general information about Flink and Iceberg, refer to Iceberg and Flink documentation . Configuration \u00b6 To use Nessie Catalog in Flink via Iceberg, we will need to create a catalog in Flink through CREATE CATALOG SQL statement (replace <catalog_name> with the name of your catalog), example: table_env . execute_sql ( \"\"\"CREATE CATALOG <catalog_name> WITH ( 'type'='iceberg', 'catalog-impl'='org.apache.iceberg.nessie.NessieCatalog', 'uri'='http://localhost:19120/api/v1', 'ref'='main', 'warehouse' = '/path/to/flink/warehouse')\"\"\" ) The following properties are required in Flink when creating the Nessie Catalog: type : This must be iceberg for iceberg table format. catalog-impl : This must be org.apache.iceberg.nessie.NessieCatalog in order to tell Flink to use Nessie catalog implementation. uri : The location of the Nessie server. ref : The Nessie ref/branch we want to use. warehouse : The location where to store Iceberg tables managed by Nessie catalog. authentication.type : The authentication type to be used, please refer to the authentication docs for more info. Create tables \u00b6 To create tables in Flink that are managed by Nessie/Iceberg, you will need to specify the catalog name in addition to the database whenever you issue CREATE TABLE statement, e.g: CREATE TABLE `< catalog_name >` . `< database_name >` . `< table_name >` ( id BIGINT COMMENT 'unique id' , data STRING ); Reading tables \u00b6 To read tables in Flink, this can be done with a typical SQL SELECT statement, however as the same with creating tables, you will need to make sure to specify the catalog name in addition to the database. e.g: SELECT * FROM `< catalog_name >` . `< database_name >` . `< table_name >` ; As well, similar to Spark , you can read tables from specific branches or hashes from within a SELECT statement. The general pattern is <table_name>@<branch/ref> (e.g: salaries@main ): SELECT * FROM `< catalog_name >` . `< database_name >` . `< table_name >@< branch / ref >` ; Other DDL statements \u00b6 To read and write into tables that are managed by Iceberg and Nessie, typical Flink SQL queries can be used. Refer to this documentation here for more information.","title":"Flink via Iceberg"},{"location":"tools/iceberg/flink/#flink-via-iceberg","text":"Note Detailed steps on how to set up Pyspark + Iceberg + Flink + Nessie with Python is available on Binder In order to use Flink with Python API, you will need to make sure pyflink have access to all Hadoop JARs as mentioned in these docs . After that, you will need to make sure iceberg-flink-runtime is added to Flink. This can be done by adding the iceberg JAR to pyflink via env.add_jar , e.g: env.add_jars(\"file://path/to/jar/iceberg-flink-runtime-0.13.0.jar\") . This can be shown below: import os from pyflink.datastream import StreamExecutionEnvironment env = StreamExecutionEnvironment . get_execution_environment () iceberg_flink_runtime_jar = os . path . join ( os . getcwd (), \"iceberg-flink-runtime-0.13.0.jar\" ) env . add_jars ( \"file:// {} \" . format ( iceberg_flink_runtime_jar )) Once we have added iceberg-flink-runtime JAR to pyflink , we can then create StreamTableEnvironment and execute Flink SQL statements. This can be shown in the following example: from pyflink.table import StreamTableEnvironment table_env = StreamTableEnvironment . create ( env ) table_env . execute_sql ( \"\"\"CREATE CATALOG <catalog_name> WITH ( 'type'='iceberg', 'catalog-impl'='org.apache.iceberg.nessie.NessieCatalog', 'uri'='http://localhost:19120/api/v1', 'ref'='main', 'warehouse' = '/path/to/flink/warehouse')\"\"\" ) With the above statement, we have created a Nessie catalog (via Iceberg) that Flink will use to manage the tables. For more general information about Flink and Iceberg, refer to Iceberg and Flink documentation .","title":"Flink via Iceberg"},{"location":"tools/iceberg/flink/#configuration","text":"To use Nessie Catalog in Flink via Iceberg, we will need to create a catalog in Flink through CREATE CATALOG SQL statement (replace <catalog_name> with the name of your catalog), example: table_env . execute_sql ( \"\"\"CREATE CATALOG <catalog_name> WITH ( 'type'='iceberg', 'catalog-impl'='org.apache.iceberg.nessie.NessieCatalog', 'uri'='http://localhost:19120/api/v1', 'ref'='main', 'warehouse' = '/path/to/flink/warehouse')\"\"\" ) The following properties are required in Flink when creating the Nessie Catalog: type : This must be iceberg for iceberg table format. catalog-impl : This must be org.apache.iceberg.nessie.NessieCatalog in order to tell Flink to use Nessie catalog implementation. uri : The location of the Nessie server. ref : The Nessie ref/branch we want to use. warehouse : The location where to store Iceberg tables managed by Nessie catalog. authentication.type : The authentication type to be used, please refer to the authentication docs for more info.","title":"Configuration"},{"location":"tools/iceberg/flink/#create-tables","text":"To create tables in Flink that are managed by Nessie/Iceberg, you will need to specify the catalog name in addition to the database whenever you issue CREATE TABLE statement, e.g: CREATE TABLE `< catalog_name >` . `< database_name >` . `< table_name >` ( id BIGINT COMMENT 'unique id' , data STRING );","title":"Create tables"},{"location":"tools/iceberg/flink/#reading-tables","text":"To read tables in Flink, this can be done with a typical SQL SELECT statement, however as the same with creating tables, you will need to make sure to specify the catalog name in addition to the database. e.g: SELECT * FROM `< catalog_name >` . `< database_name >` . `< table_name >` ; As well, similar to Spark , you can read tables from specific branches or hashes from within a SELECT statement. The general pattern is <table_name>@<branch/ref> (e.g: salaries@main ): SELECT * FROM `< catalog_name >` . `< database_name >` . `< table_name >@< branch / ref >` ;","title":"Reading tables"},{"location":"tools/iceberg/flink/#other-ddl-statements","text":"To read and write into tables that are managed by Iceberg and Nessie, typical Flink SQL queries can be used. Refer to this documentation here for more information.","title":"Other DDL statements"},{"location":"tools/iceberg/hive/","text":"Hive via Iceberg \u00b6 Note Detailed steps on how to set up Pyspark + Iceberg + Hive + Nessie with Python is available on Binder To access Hive via Iceberg, you will need to make sure iceberg-hive-runtime is added to Hive. This can be done either by adding the JAR file to auxlib folder in Hive home directory, by adding the JAR file to hive-site.xml file or via Hive shell, e.g: add jar /path/to/iceberg-hive-runtime.jar; . Nessie\u2019s Iceberg module is already included with iceberg-hive-runtime JAR distribution. For more general information about Hive and Iceberg, refer to Iceberg and Hive documentation . Configuration \u00b6 To configure a Nessie Catalog in Hive, first it needs to be registered in Hive , this can be done by configuring the following properties in Hive (Replace <catalog_name> with the name of your catalog): SET iceberg.catalog.<catalog_name>.catalog-impl=org.apache.iceberg.nessie.NessieCatalog SET iceberg.catalog.<catalog_name>.<nessie_config_property>=<config> To use Nessie Catalog in Hive via Iceberg, the following properties are required within Hive: iceberg.catalog.<catalog_name>.warehouse : The location where to store Iceberg tables managed by Nessie catalog. This will be the same location that is used to create an Iceberg table as it shown below. iceberg.catalog.<catalog_name>.ref : The current Nessie branch. Note that Hive doesn\u2019t support the notation of table@branch , therefore everytime you want to execute against a specific branch, you will need to set this property to point to the working branch, e.g: SET iceberg.catalog.<catalog_name>.ref=main . iceberg.catalog.<catalog_name>.uri : The location of the Nessie server. iceberg.catalog.<catalog_name>.authentication.type : The authentication type to be used, please refer to the authentication docs for more info. For example: SET iceberg.catalog.<catalog_name>.warehouse=/home/user/notebooks/nessie_warehouse; SET iceberg.catalog.<catalog_name>.ref=dev; SET iceberg.catalog.<catalog_name>.catalog-impl=org.apache.iceberg.nessie.NessieCatalog; SET iceberg.catalog.<catalog_name>.uri=http://localhost:19120/api/v1; Create tables \u00b6 Whenever Hive creates an Iceberg table, it will create it as external table that is managed by Iceberg catalog (in this case Nessie Catalog), thus, some properties need to be provided in order to create an Iceberg tables in Hive: CREATE TABLE database_a.table_a ( id bigint, name string ) PARTITIONED BY ( dept string ) STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' LOCATION '/path_nessie_warehouse/database_a/salaries TBLPROPERTIES ('iceberg.catalog'='<catalog_name>', 'write.format.default'='parquet'); Whereby the above properties are explained as below: STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' : Since Hive doesn\u2019t use a custom global catalog, we tell Hive here that individual table will be managed by Iceberg\u2019s catalog through org.apache.iceberg.mr.hive.HiveIcebergStorageHandler . LOCATION '/path_nessie_warehouse/database_a/salaries : As mentioned before, Hive will create Iceberg tables as external tables and thus, location of the data files needs to be provided. This location is the same location that is provided in iceberg.catalog.<catalog_name>.warehouse in addition to the database and table names. 'iceberg.catalog'='<catalog_name>' : The custom Iceberg catalog to be used to manage this table. 'write.format.default'='parquet' : The format that is used to store the data, this could be anything that is supported by Iceberg, e.g: ORC. Writing and reading tables \u00b6 To read and write into tables that are managed by Iceberg and Nessie, typical Hive SQL queries can be used. Refer to this documentation here for more information. Note : Hive doesn\u2019t support the notation of table@branch , therefore everytime you want to execute against a specific branch, you will need to set this property to point to the working branch, e.g: SET iceberg.catalog.<catalog_name>.ref=main . E.g: SET iceberg.catalog.<catalog_name>.ref=dev SELECT * FROM database_a.table_a;","title":"Hive via Iceberg"},{"location":"tools/iceberg/hive/#hive-via-iceberg","text":"Note Detailed steps on how to set up Pyspark + Iceberg + Hive + Nessie with Python is available on Binder To access Hive via Iceberg, you will need to make sure iceberg-hive-runtime is added to Hive. This can be done either by adding the JAR file to auxlib folder in Hive home directory, by adding the JAR file to hive-site.xml file or via Hive shell, e.g: add jar /path/to/iceberg-hive-runtime.jar; . Nessie\u2019s Iceberg module is already included with iceberg-hive-runtime JAR distribution. For more general information about Hive and Iceberg, refer to Iceberg and Hive documentation .","title":"Hive via Iceberg"},{"location":"tools/iceberg/hive/#configuration","text":"To configure a Nessie Catalog in Hive, first it needs to be registered in Hive , this can be done by configuring the following properties in Hive (Replace <catalog_name> with the name of your catalog): SET iceberg.catalog.<catalog_name>.catalog-impl=org.apache.iceberg.nessie.NessieCatalog SET iceberg.catalog.<catalog_name>.<nessie_config_property>=<config> To use Nessie Catalog in Hive via Iceberg, the following properties are required within Hive: iceberg.catalog.<catalog_name>.warehouse : The location where to store Iceberg tables managed by Nessie catalog. This will be the same location that is used to create an Iceberg table as it shown below. iceberg.catalog.<catalog_name>.ref : The current Nessie branch. Note that Hive doesn\u2019t support the notation of table@branch , therefore everytime you want to execute against a specific branch, you will need to set this property to point to the working branch, e.g: SET iceberg.catalog.<catalog_name>.ref=main . iceberg.catalog.<catalog_name>.uri : The location of the Nessie server. iceberg.catalog.<catalog_name>.authentication.type : The authentication type to be used, please refer to the authentication docs for more info. For example: SET iceberg.catalog.<catalog_name>.warehouse=/home/user/notebooks/nessie_warehouse; SET iceberg.catalog.<catalog_name>.ref=dev; SET iceberg.catalog.<catalog_name>.catalog-impl=org.apache.iceberg.nessie.NessieCatalog; SET iceberg.catalog.<catalog_name>.uri=http://localhost:19120/api/v1;","title":"Configuration"},{"location":"tools/iceberg/hive/#create-tables","text":"Whenever Hive creates an Iceberg table, it will create it as external table that is managed by Iceberg catalog (in this case Nessie Catalog), thus, some properties need to be provided in order to create an Iceberg tables in Hive: CREATE TABLE database_a.table_a ( id bigint, name string ) PARTITIONED BY ( dept string ) STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' LOCATION '/path_nessie_warehouse/database_a/salaries TBLPROPERTIES ('iceberg.catalog'='<catalog_name>', 'write.format.default'='parquet'); Whereby the above properties are explained as below: STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' : Since Hive doesn\u2019t use a custom global catalog, we tell Hive here that individual table will be managed by Iceberg\u2019s catalog through org.apache.iceberg.mr.hive.HiveIcebergStorageHandler . LOCATION '/path_nessie_warehouse/database_a/salaries : As mentioned before, Hive will create Iceberg tables as external tables and thus, location of the data files needs to be provided. This location is the same location that is provided in iceberg.catalog.<catalog_name>.warehouse in addition to the database and table names. 'iceberg.catalog'='<catalog_name>' : The custom Iceberg catalog to be used to manage this table. 'write.format.default'='parquet' : The format that is used to store the data, this could be anything that is supported by Iceberg, e.g: ORC.","title":"Create tables"},{"location":"tools/iceberg/hive/#writing-and-reading-tables","text":"To read and write into tables that are managed by Iceberg and Nessie, typical Hive SQL queries can be used. Refer to this documentation here for more information. Note : Hive doesn\u2019t support the notation of table@branch , therefore everytime you want to execute against a specific branch, you will need to set this property to point to the working branch, e.g: SET iceberg.catalog.<catalog_name>.ref=main . E.g: SET iceberg.catalog.<catalog_name>.ref=dev SELECT * FROM database_a.table_a;","title":"Writing and reading tables"},{"location":"tools/iceberg/spark/","text":"Spark via Iceberg \u00b6 Note Detailed steps on how to set up Pyspark + Iceberg + Nessie with Python is available on Binder To access Nessie from a spark cluster make sure the spark.jars spark option is set to include the Spark 2 or Spark 3 or Spark 3.2 Nessie plugin jar. This fat jar is distributed by the Apache Iceberg project and contains all Apache Iceberg libraries required for operation, including the built-in Nessie Catalog. In pyspark this would look like SparkSession . builder . config ( 'spark.jars.packages' , 'org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0' ) ... rest of spark config . getOrCreate () Note The Spark config parameter spark.jars.packages uses Maven coordinates to pull the given dependencies and all transitively required dependencies as well. Dependencies are resolved via the local Ivy cache, the local Maven repo and then against Maven Central. The config parameter spark.jars only takes a list of jar files and does not resolve transitive dependencies. The docs for the Java API in Iceberg explain how to use a Catalog . The only change is that a Nessie catalog should be instantiated Java Catalog catalog = new NessieCatalog ( spark . sparkContext (). hadoopConfiguration ()) Python catalog = jvm . NessieCatalog ( sc . _jsc . hadoopConfiguration ()) Note Iceberg\u2019s python libraries are still under active development. Actions against catalogs in pyspark still have to go through the jvm objects. See the demo directory for details. Configuration \u00b6 The Nessie Catalog needs the following parameters set in the Spark/Hadoop config. These are set as follows in code (or through other methods as described here ) Spark 3.1 \u00b6 Java // Full url of the Nessie API endpoint to nessie String url = \"http://localhost:19120/api/v1\" ; // Where to store nessie tables String fullPathToWarehouse = ...; // The ref or context that nessie will operate on // (if different from default branch). // Can be the name of a Nessie branch or tag name. String ref = \"main\" ; // Nessie authentication type (BASIC, NONE or AWS) String authType = \"NONE\" ; //for a local spark instance conf . set ( \"spark.jars.packages\" , \"org.apache.iceberg:iceberg-spark3-runtime-0.13.0:0.13.0,org.projectnessie:nessie-spark-extensions:0.30.0\" ) . set ( \"spark.sql.extensions\" , \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions\" ) . set ( \"spark.sql.catalog.nessie.uri\" , url ) . set ( \"spark.sql.catalog.nessie.ref\" , ref ) . set ( \"spark.sql.catalog.nessie.authentication.type\" , authType ) . set ( \"spark.sql.catalog.nessie.catalog-impl\" , \"org.apache.iceberg.nessie.NessieCatalog\" ) . set ( \"spark.sql.catalog.nessie.warehouse\" , fullPathToWarehouse ) . set ( \"spark.sql.catalog.nessie\" , \"org.apache.iceberg.spark.SparkCatalog\" ); spark = SparkSession . builder () . master ( \"local[2]\" ) . config ( conf ) . getOrCreate (); Python # Full url of the Nessie API endpoint to nessie url = \"http://localhost:19120/api/v1\" # Where to store nessie tables full_path_to_warehouse = ... # The ref or context that nessie will operate on (if different from default branch). # Can be the name of a Nessie branch or tag name. ref = \"main\" # Nessie authentication type (BASIC, NONE or AWS) auth_type = \"NONE\" # here we are assuming NONE authorisation spark = SparkSession . builder \\ . config ( \"spark.jars.packages\" , \"org.apache.iceberg:iceberg-spark3-runtime-3.2_2.12:0.13.0,org.projectnessie:nessie-spark-extensions:0.30.0\" ) \\ . config ( \"spark.sql.extensions\" , \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions\" ) \\ . config ( \"spark.sql.catalog.nessie.uri\" , url ) \\ . config ( \"spark.sql.catalog.nessie.ref\" , ref ) \\ . config ( \"spark.sql.catalog.nessie.authentication.type\" , auth_type ) \\ . config ( \"spark.sql.catalog.nessie.catalog-impl\" , \"org.apache.iceberg.nessie.NessieCatalog\" ) \\ . config ( \"spark.sql.catalog.nessie.warehouse\" , full_path_to_warehouse ) \\ . config ( \"spark.sql.catalog.nessie\" , \"org.apache.iceberg.spark.SparkCatalog\" ) \\ . getOrCreate () Spark 3.2 \u00b6 Java // Full url of the Nessie API endpoint to nessie String url = \"http://localhost:19120/api/v1\" ; // Where to store nessie tables String fullPathToWarehouse = ...; // The ref or context that nessie will operate on // (if different from default branch). // Can be the name of a Nessie branch or tag name. String ref = \"main\" ; // Nessie authentication type (BASIC, NONE or AWS) String authType = \"NONE\" ; //for a local spark instance conf . set ( \"spark.jars.packages\" , \"org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0,org.projectnessie:nessie-spark-3.2-extensions:0.30.0\" ) . set ( \"spark.sql.extensions\" , \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSpark32SessionExtensions\" ) . set ( \"spark.sql.catalog.nessie.uri\" , url ) . set ( \"spark.sql.catalog.nessie.ref\" , ref ) . set ( \"spark.sql.catalog.nessie.authentication.type\" , authType ) . set ( \"spark.sql.catalog.nessie.catalog-impl\" , \"org.apache.iceberg.nessie.NessieCatalog\" ) . set ( \"spark.sql.catalog.nessie.warehouse\" , fullPathToWarehouse ) . set ( \"spark.sql.catalog.nessie\" , \"org.apache.iceberg.spark.SparkCatalog\" ); spark = SparkSession . builder () . master ( \"local[2]\" ) . config ( conf ) . getOrCreate (); Python # Full url of the Nessie API endpoint to nessie url = \"http://localhost:19120/api/v1\" # Where to store nessie tables full_path_to_warehouse = ... # The ref or context that nessie will operate on (if different from default branch). # Can be the name of a Nessie branch or tag name. ref = \"main\" # Nessie authentication type (BASIC, NONE or AWS) auth_type = \"NONE\" # here we are assuming NONE authorisation spark = SparkSession . builder \\ . config ( \"spark.jars.packages\" , \"org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0,org.projectnessie:nessie-spark-3.2-extensions:0.30.0\" ) \\ . config ( \"spark.sql.extensions\" , \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions\" ) \\ . config ( \"spark.sql.catalog.nessie.uri\" , url ) \\ . config ( \"spark.sql.catalog.nessie.ref\" , ref ) \\ . config ( \"spark.sql.catalog.nessie.authentication.type\" , auth_type ) \\ . config ( \"spark.sql.catalog.nessie.catalog-impl\" , \"org.apache.iceberg.nessie.NessieCatalog\" ) \\ . config ( \"spark.sql.catalog.nessie.warehouse\" , full_path_to_warehouse ) \\ . config ( \"spark.sql.catalog.nessie\" , \"org.apache.iceberg.spark.SparkCatalog\" ) \\ . getOrCreate () All configuration for the Nessie catalog exists below this spark.sql.catalog.nessie configuration namespace. The catalog name is not important, it is important that the required options are all given below the catalog name. The following properties are required in Spark when creating the Nessie Catalog (replace <catalog_name> with the name of your catalog): spark.sql.catalog.<catalog_name>.uri : The location of the Nessie server. spark.sql.catalog.<catalog_name>.ref : The default Nessie branch that the iceberg catalog will use. spark.sql.catalog.<catalog_name>.authentication.type : The authentication type to be used, set to NONE by default. Please refer to the authentication docs for more info. spark.sql.catalog.<catalog_name>.catalog-impl : This must be org.apache.iceberg.nessie.NessieCatalog in order to tell Spark to use Nessie catalog implementation. spark.sql.catalog.<catalog_name>.warehouse : The location where to store Iceberg tables managed by Nessie catalog. spark.sql.catalog.<catalog_name> : This must be org.apache.iceberg.spark.SparkCatalog . This is a Spark option to set the catalog <catalog_name> to be managed by Nessie\u2019s Catalog implementation. Note An example of configuring Spark with Iceberg and an S3 bucket for the warehouse location is available in the Guides section. Writing \u00b6 Spark support is constantly evolving and the differences in Spark3 vs Spark2.4 are considerable. See the iceberg docs for an up-to-date support table. Spark2 \u00b6 Spark2.4 supports reads, appends, overwrites in Iceberg. Nessie tables in iceberg can be written via the Nessie Iceberg Catalog instantiated above. Iceberg in Spark2.4 has no ability to create tables so before a table can be appended to or overwritten the table must be first created via an Iceberg Catalog. This is straightforward in Java but requires addressing jvm objects directly in Python (until the python library for iceberg is released). Java 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // first instantiate the catalog NessieCatalog catalog = new NessieCatalog (); catalog . setConf ( sc . hadoopConfiguration ()); catalog . initialize ( \"nessie\" , ImmutableMap . of ( \"ref\" , ref , \"url\" , url , \"warehouse\" , pathToWarehouse )); // Creating table by first creating a table name with namespace TableIdentifier region_name = TableIdentifier . parse ( \"testing.region\" ); // next create the schema Schema region_schema = Schema ( [ Types . NestedField . optional ( 1 , \"R_REGIONKEY\" , Types . LongType . get ()), Types . NestedField . optional ( 2 , \"R_NAME\" , Types . StringType . get ()), Types . NestedField . optional ( 3 , \"R_COMMENT\" , Types . StringType . get ()), ] ); // and the partition PartitionSpec region_spec = PartitionSpec . unpartitioned (); // finally create the table catalog . createTable ( region_name , region_schema , region_spec ); Python 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 sc = spark . sparkContext jvm = sc . _gateway . jvm # import jvm libraries for iceberg catalogs and schemas java_import ( jvm , \"org.projectnessie.iceberg.NessieCatalog\" ) java_import ( jvm , \"org.apache.iceberg.catalog.TableIdentifier\" ) java_import ( jvm , \"org.apache.iceberg.Schema\" ) java_import ( jvm , \"org.apache.iceberg.types.Types\" ) java_import ( jvm , \"org.apache.iceberg.PartitionSpec\" ) # first instantiate the catalog catalog = jvm . NessieCatalog () catalog . setConf ( sc . _jsc . hadoopConfiguration ()) catalog . initialize ( \"nessie\" , { \"ref\" : ref , \"url\" : url , \"warehouse\" : pathToWarehouse }) # Creating table by first creating a table name with namespace region_name = jvm . TableIdentifier . parse ( \"testing.region\" ) # next create the schema region_schema = jvm . Schema ([ jvm . Types . NestedField . optional ( 1 , \"R_REGIONKEY\" , jvm . Types . LongType . get () ), jvm . Types . NestedField . optional ( 2 , \"R_NAME\" , jvm . Types . StringType . get () ), jvm . Types . NestedField . optional ( 3 , \"R_COMMENT\" , jvm . Types . StringType . get () ), ]) # and the partition region_spec = jvm . PartitionSpec . unpartitioned () # finally create the table region_table = catalog . createTable ( region_name , region_schema , region_spec ) When looking at the Python code above, lines 1-11 are importing jvm objects into pyspark. Lines 12-25 create the table name, schema and partition spec. These actions will be familiar to seasoned iceberg users and are wholly iceberg operations. Line 29 is where our initial iceberg metadata is finally written to disk and a commit takes place on Nessie. Now that we have created an Iceberg table in nessie we can write to it. The iceberg DataSourceV2 allows for either overwrite or append mode in a standard spark.write . Java regionDf = spark . read (). load ( \"data/region.parquet\" ); regionDf . write (). format ( \"iceberg\" ). mode ( \"overwrite\" ) . save ( \"nessie.testing.region\" ); Python region_df = spark . read . load ( \"data/region.parquet\" ) region_df . write . format ( \"iceberg\" ) . mode ( \"overwrite\" ) \\ . save ( \"nessie.testing.region\" ) Here we simply read a file from the default filesystem and write it to an existing nessie iceberg table. This will trigger a commit on current context\u2019s branch. For the examples above we have performed commits on the branch specified when we set our spark configuration. Had we not specified the context in our spark configuration all operations would have defaulted to the default branch defined by the server. This is a strong pattern for a spark job which is for example writing data as part of a wider ETL job. It will only ever need one context or branch to write to. If however you are running an interactive session and would like to write to a specific branch you would have to create a new Spark Conf. Java sparkDev = spark . newSession (); sparkDev . conf . set ( \"spark.sql.catalog.nessie.ref\" , \"dev\" ); regionDf = sparkDev . read (). load ( \"data/region.parquet\" ); regionDf . write (). format ( \"iceberg\" ). mode ( \"overwrite\" ) . save ( \"nessie.testing.region\" ); Python spark_dev = spark . newSession () spark_dev . conf . set ( \"spark.sql.catalog.nessie.ref\" , \"dev\" ) region_df = spark_dev . read . load ( \"data/region.parquet\" ) region_df . write . format ( \"iceberg\" ) . mode ( \"overwrite\" ) \\ . save ( \"nessie.testing.region\" ) Note the extra option clause in the write command. This will ensure the commit happens on the dev branch rather than the default branch. Spark3 \u00b6 The write path for Spark3 is slightly different and easier to work with. These changes haven\u2019t made it to pyspark yet so writing dataframes looks much the same there, including having to create the table. Spark3 table creation/insertion is as follows: Java regionDf = spark . read (). load ( ' data / region . parquet ' ); //create regionDf . writeTo ( \"nessie.testing.region\" ). create (); //append regionDf . writeTo ( \"nessie.testing.region\" ). append (); //overwrite partition regionDf . writeTo ( \"nessie.testing.region\" ). overwritePartitions (); Python # same code as the spark2 section above to create the testing.region table region_df = spark . read . load ( \"data/region.parquet\" ) region_df . write . format ( \"iceberg\" ) . mode ( \"overwrite\" ) \\ . save ( \"nessie.testing.region\" ) SQL CREATE TABLE nessie . testing . city ( C_CITYKEY BIGINT , C_NAME STRING , N_NATIONKEY BIGINT , C_COMMENT STRING ) USING iceberg PARTITIONED BY ( N_NATIONKEY ) -- AS SELECT .. can be added to the sql statement to perform a CTAS INSERT INTO nessie . testing . city VALUES ( 1 , 'a' , 1 , 'comment' ) The full list of operations can be found here . Everything that Iceberg supports the Nessie Iceberg Catalog also supports. Reading \u00b6 Reading is more straightforward between spark 2 and spark 3. We will look at both versions together in this section. To read a Nessie table in iceberg simply: Java // Spark2: regionDf = spark . read (). format ( \"iceberg\" ) . load ( \"nessie.testing.region\" ); // Spark3: regionDf = spark . table ( \"nessie.testing.region\" ); Python # same code as above to create the testing.region table region_df = spark . read . format ( \"iceberg\" ) . load ( \"nessie.testing.region\" ) SQL -- Spark3 only SELECT * FROM nessie . testing . city -- Spark3 only, read from the `etl` branch SELECT * FROM nessie . testing . ` city @ etl ` The examples above all use the default branch defined on initialisation. There are several ways to reference specific branches or hashes from within a read statement. We will take a look at a few now from pyspark3, the rules are the same across all environments though. The general pattern is <table>@<branch> . Table must be present and either branch and/or hash are optional. We will throw an error if branch or hash don\u2019t exist. Branch or hash references in the table name will override passed option s and the settings in the Spark/Hadoop configs. 1 2 3 4 5 6 7 # read from branch dev spark . read () . format ( \"iceberg\" ) . load ( \"testing.region@dev\" ) # read specifically from hash spark . read () . format ( \"iceberg\" ) . load ( \"testing.region@<hash>\" ) spark . sql ( \"SELECT * FROM nessie.testing.`region@dev`\" ) spark . sql ( \"SELECT * FROM nessie.testing.`region@<hash>`\" ) Notice in the SQL statements the table@branch must be escaped separately from namespace or catalog arguments. Future versions may add the ability to specify a timestamp to query the data at a specific point in time (time-travel). In the meantime the history can be viewed on the command line or via the python client and a specific hash based on commit time can be extracted for use in the spark catalog. It is recommended to use the time-travel features of Nessie over the Iceberg features as Nessie history is consistent across the entire database.","title":"Spark via Iceberg"},{"location":"tools/iceberg/spark/#spark-via-iceberg","text":"Note Detailed steps on how to set up Pyspark + Iceberg + Nessie with Python is available on Binder To access Nessie from a spark cluster make sure the spark.jars spark option is set to include the Spark 2 or Spark 3 or Spark 3.2 Nessie plugin jar. This fat jar is distributed by the Apache Iceberg project and contains all Apache Iceberg libraries required for operation, including the built-in Nessie Catalog. In pyspark this would look like SparkSession . builder . config ( 'spark.jars.packages' , 'org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0' ) ... rest of spark config . getOrCreate () Note The Spark config parameter spark.jars.packages uses Maven coordinates to pull the given dependencies and all transitively required dependencies as well. Dependencies are resolved via the local Ivy cache, the local Maven repo and then against Maven Central. The config parameter spark.jars only takes a list of jar files and does not resolve transitive dependencies. The docs for the Java API in Iceberg explain how to use a Catalog . The only change is that a Nessie catalog should be instantiated Java Catalog catalog = new NessieCatalog ( spark . sparkContext (). hadoopConfiguration ()) Python catalog = jvm . NessieCatalog ( sc . _jsc . hadoopConfiguration ()) Note Iceberg\u2019s python libraries are still under active development. Actions against catalogs in pyspark still have to go through the jvm objects. See the demo directory for details.","title":"Spark via Iceberg"},{"location":"tools/iceberg/spark/#configuration","text":"The Nessie Catalog needs the following parameters set in the Spark/Hadoop config. These are set as follows in code (or through other methods as described here )","title":"Configuration"},{"location":"tools/iceberg/spark/#spark-31","text":"Java // Full url of the Nessie API endpoint to nessie String url = \"http://localhost:19120/api/v1\" ; // Where to store nessie tables String fullPathToWarehouse = ...; // The ref or context that nessie will operate on // (if different from default branch). // Can be the name of a Nessie branch or tag name. String ref = \"main\" ; // Nessie authentication type (BASIC, NONE or AWS) String authType = \"NONE\" ; //for a local spark instance conf . set ( \"spark.jars.packages\" , \"org.apache.iceberg:iceberg-spark3-runtime-0.13.0:0.13.0,org.projectnessie:nessie-spark-extensions:0.30.0\" ) . set ( \"spark.sql.extensions\" , \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions\" ) . set ( \"spark.sql.catalog.nessie.uri\" , url ) . set ( \"spark.sql.catalog.nessie.ref\" , ref ) . set ( \"spark.sql.catalog.nessie.authentication.type\" , authType ) . set ( \"spark.sql.catalog.nessie.catalog-impl\" , \"org.apache.iceberg.nessie.NessieCatalog\" ) . set ( \"spark.sql.catalog.nessie.warehouse\" , fullPathToWarehouse ) . set ( \"spark.sql.catalog.nessie\" , \"org.apache.iceberg.spark.SparkCatalog\" ); spark = SparkSession . builder () . master ( \"local[2]\" ) . config ( conf ) . getOrCreate (); Python # Full url of the Nessie API endpoint to nessie url = \"http://localhost:19120/api/v1\" # Where to store nessie tables full_path_to_warehouse = ... # The ref or context that nessie will operate on (if different from default branch). # Can be the name of a Nessie branch or tag name. ref = \"main\" # Nessie authentication type (BASIC, NONE or AWS) auth_type = \"NONE\" # here we are assuming NONE authorisation spark = SparkSession . builder \\ . config ( \"spark.jars.packages\" , \"org.apache.iceberg:iceberg-spark3-runtime-3.2_2.12:0.13.0,org.projectnessie:nessie-spark-extensions:0.30.0\" ) \\ . config ( \"spark.sql.extensions\" , \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions\" ) \\ . config ( \"spark.sql.catalog.nessie.uri\" , url ) \\ . config ( \"spark.sql.catalog.nessie.ref\" , ref ) \\ . config ( \"spark.sql.catalog.nessie.authentication.type\" , auth_type ) \\ . config ( \"spark.sql.catalog.nessie.catalog-impl\" , \"org.apache.iceberg.nessie.NessieCatalog\" ) \\ . config ( \"spark.sql.catalog.nessie.warehouse\" , full_path_to_warehouse ) \\ . config ( \"spark.sql.catalog.nessie\" , \"org.apache.iceberg.spark.SparkCatalog\" ) \\ . getOrCreate ()","title":"Spark 3.1"},{"location":"tools/iceberg/spark/#spark-32","text":"Java // Full url of the Nessie API endpoint to nessie String url = \"http://localhost:19120/api/v1\" ; // Where to store nessie tables String fullPathToWarehouse = ...; // The ref or context that nessie will operate on // (if different from default branch). // Can be the name of a Nessie branch or tag name. String ref = \"main\" ; // Nessie authentication type (BASIC, NONE or AWS) String authType = \"NONE\" ; //for a local spark instance conf . set ( \"spark.jars.packages\" , \"org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0,org.projectnessie:nessie-spark-3.2-extensions:0.30.0\" ) . set ( \"spark.sql.extensions\" , \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSpark32SessionExtensions\" ) . set ( \"spark.sql.catalog.nessie.uri\" , url ) . set ( \"spark.sql.catalog.nessie.ref\" , ref ) . set ( \"spark.sql.catalog.nessie.authentication.type\" , authType ) . set ( \"spark.sql.catalog.nessie.catalog-impl\" , \"org.apache.iceberg.nessie.NessieCatalog\" ) . set ( \"spark.sql.catalog.nessie.warehouse\" , fullPathToWarehouse ) . set ( \"spark.sql.catalog.nessie\" , \"org.apache.iceberg.spark.SparkCatalog\" ); spark = SparkSession . builder () . master ( \"local[2]\" ) . config ( conf ) . getOrCreate (); Python # Full url of the Nessie API endpoint to nessie url = \"http://localhost:19120/api/v1\" # Where to store nessie tables full_path_to_warehouse = ... # The ref or context that nessie will operate on (if different from default branch). # Can be the name of a Nessie branch or tag name. ref = \"main\" # Nessie authentication type (BASIC, NONE or AWS) auth_type = \"NONE\" # here we are assuming NONE authorisation spark = SparkSession . builder \\ . config ( \"spark.jars.packages\" , \"org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:0.13.0,org.projectnessie:nessie-spark-3.2-extensions:0.30.0\" ) \\ . config ( \"spark.sql.extensions\" , \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions\" ) \\ . config ( \"spark.sql.catalog.nessie.uri\" , url ) \\ . config ( \"spark.sql.catalog.nessie.ref\" , ref ) \\ . config ( \"spark.sql.catalog.nessie.authentication.type\" , auth_type ) \\ . config ( \"spark.sql.catalog.nessie.catalog-impl\" , \"org.apache.iceberg.nessie.NessieCatalog\" ) \\ . config ( \"spark.sql.catalog.nessie.warehouse\" , full_path_to_warehouse ) \\ . config ( \"spark.sql.catalog.nessie\" , \"org.apache.iceberg.spark.SparkCatalog\" ) \\ . getOrCreate () All configuration for the Nessie catalog exists below this spark.sql.catalog.nessie configuration namespace. The catalog name is not important, it is important that the required options are all given below the catalog name. The following properties are required in Spark when creating the Nessie Catalog (replace <catalog_name> with the name of your catalog): spark.sql.catalog.<catalog_name>.uri : The location of the Nessie server. spark.sql.catalog.<catalog_name>.ref : The default Nessie branch that the iceberg catalog will use. spark.sql.catalog.<catalog_name>.authentication.type : The authentication type to be used, set to NONE by default. Please refer to the authentication docs for more info. spark.sql.catalog.<catalog_name>.catalog-impl : This must be org.apache.iceberg.nessie.NessieCatalog in order to tell Spark to use Nessie catalog implementation. spark.sql.catalog.<catalog_name>.warehouse : The location where to store Iceberg tables managed by Nessie catalog. spark.sql.catalog.<catalog_name> : This must be org.apache.iceberg.spark.SparkCatalog . This is a Spark option to set the catalog <catalog_name> to be managed by Nessie\u2019s Catalog implementation. Note An example of configuring Spark with Iceberg and an S3 bucket for the warehouse location is available in the Guides section.","title":"Spark 3.2"},{"location":"tools/iceberg/spark/#writing","text":"Spark support is constantly evolving and the differences in Spark3 vs Spark2.4 are considerable. See the iceberg docs for an up-to-date support table.","title":"Writing"},{"location":"tools/iceberg/spark/#spark2","text":"Spark2.4 supports reads, appends, overwrites in Iceberg. Nessie tables in iceberg can be written via the Nessie Iceberg Catalog instantiated above. Iceberg in Spark2.4 has no ability to create tables so before a table can be appended to or overwritten the table must be first created via an Iceberg Catalog. This is straightforward in Java but requires addressing jvm objects directly in Python (until the python library for iceberg is released). Java 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // first instantiate the catalog NessieCatalog catalog = new NessieCatalog (); catalog . setConf ( sc . hadoopConfiguration ()); catalog . initialize ( \"nessie\" , ImmutableMap . of ( \"ref\" , ref , \"url\" , url , \"warehouse\" , pathToWarehouse )); // Creating table by first creating a table name with namespace TableIdentifier region_name = TableIdentifier . parse ( \"testing.region\" ); // next create the schema Schema region_schema = Schema ( [ Types . NestedField . optional ( 1 , \"R_REGIONKEY\" , Types . LongType . get ()), Types . NestedField . optional ( 2 , \"R_NAME\" , Types . StringType . get ()), Types . NestedField . optional ( 3 , \"R_COMMENT\" , Types . StringType . get ()), ] ); // and the partition PartitionSpec region_spec = PartitionSpec . unpartitioned (); // finally create the table catalog . createTable ( region_name , region_schema , region_spec ); Python 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 sc = spark . sparkContext jvm = sc . _gateway . jvm # import jvm libraries for iceberg catalogs and schemas java_import ( jvm , \"org.projectnessie.iceberg.NessieCatalog\" ) java_import ( jvm , \"org.apache.iceberg.catalog.TableIdentifier\" ) java_import ( jvm , \"org.apache.iceberg.Schema\" ) java_import ( jvm , \"org.apache.iceberg.types.Types\" ) java_import ( jvm , \"org.apache.iceberg.PartitionSpec\" ) # first instantiate the catalog catalog = jvm . NessieCatalog () catalog . setConf ( sc . _jsc . hadoopConfiguration ()) catalog . initialize ( \"nessie\" , { \"ref\" : ref , \"url\" : url , \"warehouse\" : pathToWarehouse }) # Creating table by first creating a table name with namespace region_name = jvm . TableIdentifier . parse ( \"testing.region\" ) # next create the schema region_schema = jvm . Schema ([ jvm . Types . NestedField . optional ( 1 , \"R_REGIONKEY\" , jvm . Types . LongType . get () ), jvm . Types . NestedField . optional ( 2 , \"R_NAME\" , jvm . Types . StringType . get () ), jvm . Types . NestedField . optional ( 3 , \"R_COMMENT\" , jvm . Types . StringType . get () ), ]) # and the partition region_spec = jvm . PartitionSpec . unpartitioned () # finally create the table region_table = catalog . createTable ( region_name , region_schema , region_spec ) When looking at the Python code above, lines 1-11 are importing jvm objects into pyspark. Lines 12-25 create the table name, schema and partition spec. These actions will be familiar to seasoned iceberg users and are wholly iceberg operations. Line 29 is where our initial iceberg metadata is finally written to disk and a commit takes place on Nessie. Now that we have created an Iceberg table in nessie we can write to it. The iceberg DataSourceV2 allows for either overwrite or append mode in a standard spark.write . Java regionDf = spark . read (). load ( \"data/region.parquet\" ); regionDf . write (). format ( \"iceberg\" ). mode ( \"overwrite\" ) . save ( \"nessie.testing.region\" ); Python region_df = spark . read . load ( \"data/region.parquet\" ) region_df . write . format ( \"iceberg\" ) . mode ( \"overwrite\" ) \\ . save ( \"nessie.testing.region\" ) Here we simply read a file from the default filesystem and write it to an existing nessie iceberg table. This will trigger a commit on current context\u2019s branch. For the examples above we have performed commits on the branch specified when we set our spark configuration. Had we not specified the context in our spark configuration all operations would have defaulted to the default branch defined by the server. This is a strong pattern for a spark job which is for example writing data as part of a wider ETL job. It will only ever need one context or branch to write to. If however you are running an interactive session and would like to write to a specific branch you would have to create a new Spark Conf. Java sparkDev = spark . newSession (); sparkDev . conf . set ( \"spark.sql.catalog.nessie.ref\" , \"dev\" ); regionDf = sparkDev . read (). load ( \"data/region.parquet\" ); regionDf . write (). format ( \"iceberg\" ). mode ( \"overwrite\" ) . save ( \"nessie.testing.region\" ); Python spark_dev = spark . newSession () spark_dev . conf . set ( \"spark.sql.catalog.nessie.ref\" , \"dev\" ) region_df = spark_dev . read . load ( \"data/region.parquet\" ) region_df . write . format ( \"iceberg\" ) . mode ( \"overwrite\" ) \\ . save ( \"nessie.testing.region\" ) Note the extra option clause in the write command. This will ensure the commit happens on the dev branch rather than the default branch.","title":"Spark2"},{"location":"tools/iceberg/spark/#spark3","text":"The write path for Spark3 is slightly different and easier to work with. These changes haven\u2019t made it to pyspark yet so writing dataframes looks much the same there, including having to create the table. Spark3 table creation/insertion is as follows: Java regionDf = spark . read (). load ( ' data / region . parquet ' ); //create regionDf . writeTo ( \"nessie.testing.region\" ). create (); //append regionDf . writeTo ( \"nessie.testing.region\" ). append (); //overwrite partition regionDf . writeTo ( \"nessie.testing.region\" ). overwritePartitions (); Python # same code as the spark2 section above to create the testing.region table region_df = spark . read . load ( \"data/region.parquet\" ) region_df . write . format ( \"iceberg\" ) . mode ( \"overwrite\" ) \\ . save ( \"nessie.testing.region\" ) SQL CREATE TABLE nessie . testing . city ( C_CITYKEY BIGINT , C_NAME STRING , N_NATIONKEY BIGINT , C_COMMENT STRING ) USING iceberg PARTITIONED BY ( N_NATIONKEY ) -- AS SELECT .. can be added to the sql statement to perform a CTAS INSERT INTO nessie . testing . city VALUES ( 1 , 'a' , 1 , 'comment' ) The full list of operations can be found here . Everything that Iceberg supports the Nessie Iceberg Catalog also supports.","title":"Spark3"},{"location":"tools/iceberg/spark/#reading","text":"Reading is more straightforward between spark 2 and spark 3. We will look at both versions together in this section. To read a Nessie table in iceberg simply: Java // Spark2: regionDf = spark . read (). format ( \"iceberg\" ) . load ( \"nessie.testing.region\" ); // Spark3: regionDf = spark . table ( \"nessie.testing.region\" ); Python # same code as above to create the testing.region table region_df = spark . read . format ( \"iceberg\" ) . load ( \"nessie.testing.region\" ) SQL -- Spark3 only SELECT * FROM nessie . testing . city -- Spark3 only, read from the `etl` branch SELECT * FROM nessie . testing . ` city @ etl ` The examples above all use the default branch defined on initialisation. There are several ways to reference specific branches or hashes from within a read statement. We will take a look at a few now from pyspark3, the rules are the same across all environments though. The general pattern is <table>@<branch> . Table must be present and either branch and/or hash are optional. We will throw an error if branch or hash don\u2019t exist. Branch or hash references in the table name will override passed option s and the settings in the Spark/Hadoop configs. 1 2 3 4 5 6 7 # read from branch dev spark . read () . format ( \"iceberg\" ) . load ( \"testing.region@dev\" ) # read specifically from hash spark . read () . format ( \"iceberg\" ) . load ( \"testing.region@<hash>\" ) spark . sql ( \"SELECT * FROM nessie.testing.`region@dev`\" ) spark . sql ( \"SELECT * FROM nessie.testing.`region@<hash>`\" ) Notice in the SQL statements the table@branch must be escaped separately from namespace or catalog arguments. Future versions may add the ability to specify a timestamp to query the data at a specific point in time (time-travel). In the meantime the history can be viewed on the command line or via the python client and a specific hash based on commit time can be extracted for use in the spark catalog. It is recommended to use the time-travel features of Nessie over the Iceberg features as Nessie history is consistent across the entire database.","title":"Reading"},{"location":"try/","text":"Overview \u00b6 For a quick overview of nessie capabilities, several demos which do not require any special setup except for a web browser have been made available: Nessie, Iceberg and Spark via Binder Nessie, Deltalake and Spark via Binder Nessie, Iceberg and Flink via Binder Nessie, Iceberg and Hive via Binder The nessie-demos repository contains a full list of all available Jupyter Notebooks that show how nessie can be used with other technologies. For people who are interested in trying out all nessie features, they can use the docker images published with each release and set up the server by following the instructions available here Note Please refer the compatibility matrix to find the compatible versions to try out manually.","title":"Overview"},{"location":"try/#overview","text":"For a quick overview of nessie capabilities, several demos which do not require any special setup except for a web browser have been made available: Nessie, Iceberg and Spark via Binder Nessie, Deltalake and Spark via Binder Nessie, Iceberg and Flink via Binder Nessie, Iceberg and Hive via Binder The nessie-demos repository contains a full list of all available Jupyter Notebooks that show how nessie can be used with other technologies. For people who are interested in trying out all nessie features, they can use the docker images published with each release and set up the server by following the instructions available here Note Please refer the compatibility matrix to find the compatible versions to try out manually.","title":"Overview"},{"location":"try/authentication/","text":"Authentication \u00b6 By default, Nessie servers run with authentication disabled and all requests are processed under the \u201canonymous\u201d user identity. In Nessie clients this authentication type is known as NONE . When a Nessie server runs as an AWS Lambda, access to its API is controlled by AWS authentication settings. In this case there is no need to configure any additional authentication in the Nessie server. In Nessie clients this authentication type is known as AWS . When a Nessie API is exposed to clients without any external authentication layer, the server itself can be configured to authenticate clients using OpenID tokens as described in the section below. On the client side this authentication type is known as BEARER authentication. For client-side authentication settings refer to the following pages: Nessie CLI Java Client Authentication in Tools OpenID Bearer Tokens \u00b6 Nessie supports bearer tokens and uses OpenID Connect for validating them. To enable bearer authentication the following configuration properties need to be set for the Nessie Server process: nessie.server.authentication.enabled=true quarkus.oidc.auth-server-url=<OpenID Server URL> quarkus.oidc.client-id=<Client ID> When using Nessie Docker images, the authentication options can be specified on the docker command line as environment variables, for example: $ docker run -p 19120 :19120 -e QUARKUS_OIDC_CLIENT_ID = <Client ID> -e QUARKUS_OIDC_AUTH_SERVER_URL = <OpenID Server URL> -e NESSIE_SERVER_AUTHENTICATION_ENABLED = true --network host projectnessie/nessie Note the use of the host Docker network. In this example, it is assumed that the Open ID Server is available on the host network. More advanced network setup is possible, of course.","title":"Authentication"},{"location":"try/authentication/#authentication","text":"By default, Nessie servers run with authentication disabled and all requests are processed under the \u201canonymous\u201d user identity. In Nessie clients this authentication type is known as NONE . When a Nessie server runs as an AWS Lambda, access to its API is controlled by AWS authentication settings. In this case there is no need to configure any additional authentication in the Nessie server. In Nessie clients this authentication type is known as AWS . When a Nessie API is exposed to clients without any external authentication layer, the server itself can be configured to authenticate clients using OpenID tokens as described in the section below. On the client side this authentication type is known as BEARER authentication. For client-side authentication settings refer to the following pages: Nessie CLI Java Client Authentication in Tools","title":"Authentication"},{"location":"try/authentication/#openid-bearer-tokens","text":"Nessie supports bearer tokens and uses OpenID Connect for validating them. To enable bearer authentication the following configuration properties need to be set for the Nessie Server process: nessie.server.authentication.enabled=true quarkus.oidc.auth-server-url=<OpenID Server URL> quarkus.oidc.client-id=<Client ID> When using Nessie Docker images, the authentication options can be specified on the docker command line as environment variables, for example: $ docker run -p 19120 :19120 -e QUARKUS_OIDC_CLIENT_ID = <Client ID> -e QUARKUS_OIDC_AUTH_SERVER_URL = <OpenID Server URL> -e NESSIE_SERVER_AUTHENTICATION_ENABLED = true --network host projectnessie/nessie Note the use of the host Docker network. In this example, it is assumed that the Open ID Server is available on the host network. More advanced network setup is possible, of course.","title":"OpenID Bearer Tokens"},{"location":"try/configuration/","text":"Configuration \u00b6 The Nessie server is configurable via properties as listed in the application.properties file. These properties can be set when starting up the docker image by adding them to the Docker invocation prefixed with -D . For example, if you want to set Nessie to use the INMEMORY version store running on port 8080, you would run the following: docker run -p 8080 :8080 projectnessie/nessie \\ -Dnessie.version.store.type = INMEMORY \\ -Dquarkus.http.port = 8080 Core Nessie Configuration Settings \u00b6 Core Settings \u00b6 Property Default values Type Description nessie.server.default-branch main String Sets the default branch to use if not provided by the user. nessie.server.send-stacktrace-to-client false boolean Sets if server stack trace should be sent to the client in case of error. Version Store Settings \u00b6 Property Default values Type Description nessie.version.store.type INMEMORY VersionStoreType Sets which type of version store to use by Nessie. Possible values are: DYNAMO , INMEMORY , ROCKS , MONGO , \u2018TRANSACTIONAL\u2019. nessie.version.store.trace.enable true boolean Sets whether calls against the version-store are traced with OpenTracing/OpenTelemetry (Jaeger). nessie.version.store.metrics.enable true boolean Sets whether metrics for the version-store are enabled. Transactional Version Store Settings (Since Nessie 0.25.0) \u00b6 When setting nessie.version.store.type=TRANSACTIONAL which enables transactional/RDBMS as the version store used by the Nessie server, the following configurations are applicable in combination with nessie.version.store.type : Info A complete set of JDBC configuration options for Quarkus can be found on quarkus.io RocksDB Version Store Settings \u00b6 When setting nessie.version.store.type=ROCKS which enables RockDB as the version store used by the Nessie server, the following configurations are applicable in combination with nessie.version.store.type : Property Default values Type Description nessie.version.store.rocks.db-path /tmp/nessie-rocksdb String Sets RocksDB storage path, e.g: /tmp/rocks-nessie . MongoDB Version Store Settings \u00b6 When setting nessie.version.store.type=MONGO which enables MongoDB as the version store used by the Nessie server, the following configurations are applicable in combination with nessie.version.store.type : Property Default values Type Description quarkus.mongodb.database String Sets MongoDB database name. quarkus.mongodb.connection-string String Sets MongoDB connection string. Info A complete set of MongoDB configuration options for Quarkus can be found on quarkus.io DynamoDB Version Store Settings \u00b6 When setting nessie.version.store.type=DYNAMO which enables DynamoDB as the version store used by the Nessie server, the following configurations are applicable in combination with nessie.version.store.type : Property Default values Type Description quarkus.dynamodb.aws.region String Sets DynamoDB AWS region. quarkus.dynamodb.aws.credentials.type Sets the credentials provider that should be used to authenticate with AWS. quarkus.dynamodb.endpoint-override URI Sets the endpoint URI with which the SDK should communicate. If not specified, an appropriate endpoint to be used for the given service and region. quarkus.dynamodb.sync-client.type url url, apache Sets the type of the sync HTTP client implementation Info A complete set of DynamoDB configuration options for Quarkus can be found on quarkiverse.github.io Version Store Advanced Settings \u00b6 The following configurations are advanced configurations to configure how Nessie will store the data into the configured data store: Property Default values Type Description nessie.version.store.advanced.repository-id String Sets Nessie repository ID (optional). This ID can be used to distinguish multiple Nessie repositories that reside in the same storage instance. nessie.version.store.advanced.parent-per-commit 20 int Sets the number of parent-commit-hashes stored in Nessie store. nessie.version.store.advanced.key-list-distance 20 int Each n-th CommitLogEntry , where n == value of this parameter, will contain a \u201cfull\u201d KeyList. nessie.version.store.advanced.max-key-list-size 250_000 int Sets the maximum size of a database object/row. This parameter is respected for the key list in CommitLogEntry . This value must not be \u201con the edge\u201d - means: it must leave enough room for a somewhat large-ish list nessie.version.store.advanced.max-key-list-entity-size 1_000_000 int Sets the maximum size of a database object/row. This parameter is respected for KeyListEntity . This value must not be \u201con the edge\u201d - means: it must leave enough room for a somewhat large-ish list nessie.version.store.advanced.commit-timeout 500 int Sets the timeout for CAS-like operations in milliseconds. nessie.version.store.advanced.commit-retries Integer.MAX_VALUE int Sets the maximum retries for CAS-like operations. nessie.version.store.advanced.tx.batch-size 20 int Sets the DML batch size, used when writing multiple commits to a branch during a transplant or merge operation or when writing \u201coverflow full key-lists\u201d. nessie.version.store.advanced.tx.jdbc.catalog String Sets the catalog name to use via JDBC. nessie.version.store.advanced.tx.jdbc.schema String Sets the schema name to use via JDBC. nessie.version.store.advanced.references.segment.prefetch 1 int Sets the number of reference name segments to prefetch. nessie.version.store.advanced.references.segment.size 250_000 int Sets the size of a reference name segments. nessie.version.store.advanced.reference.names.batch.size 25 int Sets the number of references to resolve at once when fetching all references. nessie.version.store.advanced.ref-log.stripes 8 int Sets the number of stripes for the ref-log. nessie.version.store.advanced.commit-log-scan-prefetch 25 int Sets the amount of commits to ask the database to pre-fetch during a full commits scan. nessie.version.store.advanced.assumed-wall-clock-drift-micros 5_000_000 long Sets the assumed wall-clock drift between multiple Nessie instances, in microseconds. Authentication settings \u00b6 Property Default values Type Description nessie.server.authentication.enabled false boolean Sets whether authentication should be enabled on the Nessie server. quarkus.oidc.auth-server-url String Sets the base URL of the OpenID Connect (OIDC) server if nessie.server.authentication.enabled=true quarkus.oidc.client-id String Sets client-id of the application if nessie.server.authentication.enabled=true . Each application has a client-id that is used to identify the application. Authorization settings \u00b6 Property Default values Type Description nessie.server.authorization.enabled false boolean Sets whether authorization should be enabled on the Nessie server. nessie.server.authorization.rules.<ruleId> Map Sets the authorization rules that can be used in CEL format. Quarkus Server Settings Related to Nessie \u00b6 Property Default values Type Description quarkus.http.port 19120 int Sets the HTTP port quarkus.http.auth.basic boolean Sets if basic auth should be enabled. Info A complete set of configuration options for Quarkus can be found on quarkus.io Metrics \u00b6 Metrics are published using prometheus and can be collected via standard methods. See: Prometheus . Swagger UI \u00b6 The Swagger UI allows for testing the REST API and reading the API docs. It is available via localhost:19120/q/swagger-ui","title":"Configuration"},{"location":"try/configuration/#configuration","text":"The Nessie server is configurable via properties as listed in the application.properties file. These properties can be set when starting up the docker image by adding them to the Docker invocation prefixed with -D . For example, if you want to set Nessie to use the INMEMORY version store running on port 8080, you would run the following: docker run -p 8080 :8080 projectnessie/nessie \\ -Dnessie.version.store.type = INMEMORY \\ -Dquarkus.http.port = 8080","title":"Configuration"},{"location":"try/configuration/#core-nessie-configuration-settings","text":"","title":"Core Nessie Configuration Settings"},{"location":"try/configuration/#core-settings","text":"Property Default values Type Description nessie.server.default-branch main String Sets the default branch to use if not provided by the user. nessie.server.send-stacktrace-to-client false boolean Sets if server stack trace should be sent to the client in case of error.","title":"Core Settings"},{"location":"try/configuration/#version-store-settings","text":"Property Default values Type Description nessie.version.store.type INMEMORY VersionStoreType Sets which type of version store to use by Nessie. Possible values are: DYNAMO , INMEMORY , ROCKS , MONGO , \u2018TRANSACTIONAL\u2019. nessie.version.store.trace.enable true boolean Sets whether calls against the version-store are traced with OpenTracing/OpenTelemetry (Jaeger). nessie.version.store.metrics.enable true boolean Sets whether metrics for the version-store are enabled.","title":"Version Store Settings"},{"location":"try/configuration/#transactional-version-store-settings-since-nessie-0250","text":"When setting nessie.version.store.type=TRANSACTIONAL which enables transactional/RDBMS as the version store used by the Nessie server, the following configurations are applicable in combination with nessie.version.store.type : Info A complete set of JDBC configuration options for Quarkus can be found on quarkus.io","title":"Transactional Version Store Settings (Since Nessie 0.25.0)"},{"location":"try/configuration/#rocksdb-version-store-settings","text":"When setting nessie.version.store.type=ROCKS which enables RockDB as the version store used by the Nessie server, the following configurations are applicable in combination with nessie.version.store.type : Property Default values Type Description nessie.version.store.rocks.db-path /tmp/nessie-rocksdb String Sets RocksDB storage path, e.g: /tmp/rocks-nessie .","title":"RocksDB Version Store Settings"},{"location":"try/configuration/#mongodb-version-store-settings","text":"When setting nessie.version.store.type=MONGO which enables MongoDB as the version store used by the Nessie server, the following configurations are applicable in combination with nessie.version.store.type : Property Default values Type Description quarkus.mongodb.database String Sets MongoDB database name. quarkus.mongodb.connection-string String Sets MongoDB connection string. Info A complete set of MongoDB configuration options for Quarkus can be found on quarkus.io","title":"MongoDB Version Store Settings"},{"location":"try/configuration/#dynamodb-version-store-settings","text":"When setting nessie.version.store.type=DYNAMO which enables DynamoDB as the version store used by the Nessie server, the following configurations are applicable in combination with nessie.version.store.type : Property Default values Type Description quarkus.dynamodb.aws.region String Sets DynamoDB AWS region. quarkus.dynamodb.aws.credentials.type Sets the credentials provider that should be used to authenticate with AWS. quarkus.dynamodb.endpoint-override URI Sets the endpoint URI with which the SDK should communicate. If not specified, an appropriate endpoint to be used for the given service and region. quarkus.dynamodb.sync-client.type url url, apache Sets the type of the sync HTTP client implementation Info A complete set of DynamoDB configuration options for Quarkus can be found on quarkiverse.github.io","title":"DynamoDB Version Store Settings"},{"location":"try/configuration/#version-store-advanced-settings","text":"The following configurations are advanced configurations to configure how Nessie will store the data into the configured data store: Property Default values Type Description nessie.version.store.advanced.repository-id String Sets Nessie repository ID (optional). This ID can be used to distinguish multiple Nessie repositories that reside in the same storage instance. nessie.version.store.advanced.parent-per-commit 20 int Sets the number of parent-commit-hashes stored in Nessie store. nessie.version.store.advanced.key-list-distance 20 int Each n-th CommitLogEntry , where n == value of this parameter, will contain a \u201cfull\u201d KeyList. nessie.version.store.advanced.max-key-list-size 250_000 int Sets the maximum size of a database object/row. This parameter is respected for the key list in CommitLogEntry . This value must not be \u201con the edge\u201d - means: it must leave enough room for a somewhat large-ish list nessie.version.store.advanced.max-key-list-entity-size 1_000_000 int Sets the maximum size of a database object/row. This parameter is respected for KeyListEntity . This value must not be \u201con the edge\u201d - means: it must leave enough room for a somewhat large-ish list nessie.version.store.advanced.commit-timeout 500 int Sets the timeout for CAS-like operations in milliseconds. nessie.version.store.advanced.commit-retries Integer.MAX_VALUE int Sets the maximum retries for CAS-like operations. nessie.version.store.advanced.tx.batch-size 20 int Sets the DML batch size, used when writing multiple commits to a branch during a transplant or merge operation or when writing \u201coverflow full key-lists\u201d. nessie.version.store.advanced.tx.jdbc.catalog String Sets the catalog name to use via JDBC. nessie.version.store.advanced.tx.jdbc.schema String Sets the schema name to use via JDBC. nessie.version.store.advanced.references.segment.prefetch 1 int Sets the number of reference name segments to prefetch. nessie.version.store.advanced.references.segment.size 250_000 int Sets the size of a reference name segments. nessie.version.store.advanced.reference.names.batch.size 25 int Sets the number of references to resolve at once when fetching all references. nessie.version.store.advanced.ref-log.stripes 8 int Sets the number of stripes for the ref-log. nessie.version.store.advanced.commit-log-scan-prefetch 25 int Sets the amount of commits to ask the database to pre-fetch during a full commits scan. nessie.version.store.advanced.assumed-wall-clock-drift-micros 5_000_000 long Sets the assumed wall-clock drift between multiple Nessie instances, in microseconds.","title":"Version Store Advanced Settings"},{"location":"try/configuration/#authentication-settings","text":"Property Default values Type Description nessie.server.authentication.enabled false boolean Sets whether authentication should be enabled on the Nessie server. quarkus.oidc.auth-server-url String Sets the base URL of the OpenID Connect (OIDC) server if nessie.server.authentication.enabled=true quarkus.oidc.client-id String Sets client-id of the application if nessie.server.authentication.enabled=true . Each application has a client-id that is used to identify the application.","title":"Authentication settings"},{"location":"try/configuration/#authorization-settings","text":"Property Default values Type Description nessie.server.authorization.enabled false boolean Sets whether authorization should be enabled on the Nessie server. nessie.server.authorization.rules.<ruleId> Map Sets the authorization rules that can be used in CEL format.","title":"Authorization settings"},{"location":"try/configuration/#quarkus-server-settings-related-to-nessie","text":"Property Default values Type Description quarkus.http.port 19120 int Sets the HTTP port quarkus.http.auth.basic boolean Sets if basic auth should be enabled. Info A complete set of configuration options for Quarkus can be found on quarkus.io","title":"Quarkus Server Settings Related to Nessie"},{"location":"try/configuration/#metrics","text":"Metrics are published using prometheus and can be collected via standard methods. See: Prometheus .","title":"Metrics"},{"location":"try/configuration/#swagger-ui","text":"The Swagger UI allows for testing the REST API and reading the API docs. It is available via localhost:19120/q/swagger-ui","title":"Swagger UI"},{"location":"try/docker/","text":"Setting Up Nessie \u00b6 As part of each release, Nessie is made available as a fast-start docker image. This is the easiest and fastest way to try out nessie locally and test all its capabilities. The image is relatively small and builds on top of standard base images. To get started: $ docker pull projectnessie/nessie Pulling from projectnessie/nessie 0fd3b5213a9b: Already exists aebb8c556853: Already exists a50558612231: Pull complete Digest: sha256:bda3dead4eb51a4c0ff87c7ce5a81ad49a37dd17d785f2549f4559f06cbf24d6 Status: Downloaded newer image for projectnessie/nessie $ docker run -p 19120 :19120 projectnessie/nessie __ ____ __ _____ ___ __ ____ ______ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ -/ /_/ / /_/ / __ | / , _/ ,< / /_/ / \\ \\ -- \\_ __ \\_\\_ ___/_/ | _/_/ | _/_/ | _ | \\_ ___/___/ 2020 -10-01 21 :50:27,166 INFO [ io.quarkus ] ( main ) nessie-quarkus 0 .1-SNAPSHOT native ( powered by Quarkus 1 .8.1.Final ) started in 0 .025s. Listening on: http://0.0.0.0:19120 2020 -10-01 21 :50:27,166 INFO [ io.quarkus ] ( main ) Profile prod activated. 2020 -10-01 21 :50:27,166 INFO [ io.quarkus ] ( main ) Installed features: [ amazon-dynamodb, cdi, hibernate-validator, jaeger, resteasy, resteasy-jackson, security, security-properties-file, sentry, smallrye-health, smallrye-metrics, smallrye-openapi, smallrye-opentracing ] Once the docker image is up and running, you can install the Nessie cli . $ pip install pynessie You\u2019re now ready to start using Nessie. To create a new branch, you can do the following: # create a branch pointing to the same hash as # the current default branch (typically the main branch) $ nessie branch my_branch From there, you can use one of the three main Nessie integrations of: Take a look at your current empty repository in the Web UI NessieCatalog for Spark via Iceberg integration Nessie Log Handle for Spark via Delta Lake integration","title":"Setting Up Nessie"},{"location":"try/docker/#setting-up-nessie","text":"As part of each release, Nessie is made available as a fast-start docker image. This is the easiest and fastest way to try out nessie locally and test all its capabilities. The image is relatively small and builds on top of standard base images. To get started: $ docker pull projectnessie/nessie Pulling from projectnessie/nessie 0fd3b5213a9b: Already exists aebb8c556853: Already exists a50558612231: Pull complete Digest: sha256:bda3dead4eb51a4c0ff87c7ce5a81ad49a37dd17d785f2549f4559f06cbf24d6 Status: Downloaded newer image for projectnessie/nessie $ docker run -p 19120 :19120 projectnessie/nessie __ ____ __ _____ ___ __ ____ ______ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ -/ /_/ / /_/ / __ | / , _/ ,< / /_/ / \\ \\ -- \\_ __ \\_\\_ ___/_/ | _/_/ | _/_/ | _ | \\_ ___/___/ 2020 -10-01 21 :50:27,166 INFO [ io.quarkus ] ( main ) nessie-quarkus 0 .1-SNAPSHOT native ( powered by Quarkus 1 .8.1.Final ) started in 0 .025s. Listening on: http://0.0.0.0:19120 2020 -10-01 21 :50:27,166 INFO [ io.quarkus ] ( main ) Profile prod activated. 2020 -10-01 21 :50:27,166 INFO [ io.quarkus ] ( main ) Installed features: [ amazon-dynamodb, cdi, hibernate-validator, jaeger, resteasy, resteasy-jackson, security, security-properties-file, sentry, smallrye-health, smallrye-metrics, smallrye-openapi, smallrye-opentracing ] Once the docker image is up and running, you can install the Nessie cli . $ pip install pynessie You\u2019re now ready to start using Nessie. To create a new branch, you can do the following: # create a branch pointing to the same hash as # the current default branch (typically the main branch) $ nessie branch my_branch From there, you can use one of the three main Nessie integrations of: Take a look at your current empty repository in the Web UI NessieCatalog for Spark via Iceberg integration Nessie Log Handle for Spark via Delta Lake integration","title":"Setting Up Nessie"},{"location":"try/grafana/","text":"Nessie Grafana Dashboard \u00b6 Nessie provides a Grafana Dashboard which can be used to gain insight into different metrics. Additional docs can be found in the Nessie source code repository .","title":"Nessie Grafana Dashboard"},{"location":"try/grafana/#nessie-grafana-dashboard","text":"Nessie provides a Grafana Dashboard which can be used to gain insight into different metrics. Additional docs can be found in the Nessie source code repository .","title":"Nessie Grafana Dashboard"},{"location":"try/helm/","text":"Nessie Helm Chart \u00b6 The easiest way to get started with Nessie is to use the Helm chart. Add the Nessie Helm repo: helm repo add nessie-helm https://charts.projectnessie.org helm repo update Install the Helm chart: helm install -n nessie-ns nessie nessie-helm/nessie Additional docs (incl. configuration settings) can be found here .","title":"Nessie Helm Chart"},{"location":"try/helm/#nessie-helm-chart","text":"The easiest way to get started with Nessie is to use the Helm chart. Add the Nessie Helm repo: helm repo add nessie-helm https://charts.projectnessie.org helm repo update Install the Helm chart: helm install -n nessie-ns nessie nessie-helm/nessie Additional docs (incl. configuration settings) can be found here .","title":"Nessie Helm Chart"},{"location":"try/releases/","text":"Releases \u00b6 See Nessie Server upgrade notes for supported upgrade paths. 0.30.0 Release (May 13, 2022) \u00b6 Add commit-ID to KeyListEntry when writing new key-lists Do not process old key-lists when retrieving values Helm: Fix k8s version detection in ingress template Database-adapter: commit optimizations Remove the configurable default for the configurable values for getDefaultMaxKeyListSize Dynamo/Mongo/TX: use bulk/batch requests where possible 0.29.0 Release (May 5, 2022) \u00b6 Spark SQL: Configure ref.hash for NessieCatalog only when explicitly requested Escape all column names in SQL DML+DDL statements Use hashOnRef when fetching Namespaces Helm: Add ingress support for Kubernetes >=1.22 Fix CockroachDB transaction-retry behavior 0.28.0 Release (April 26, 2022) \u00b6 Generate unique content IDs for explicitly created namespaces Fix patterns for metrics Various test improvements (CI + build) Various minor code fixes (fixes for errorprone warnings) 0.27.0 Release (April 14, 2022) \u00b6 Support for Namespace properties Make NessieContentGenerator extensible 0.26.0 Release (April 12, 2022) \u00b6 Rolling upgrades from an older Nessie release to 0.26.0 or newer are not supported. Remove global state for Iceberg tables + views Internal optimizations in database adapters, version store and API endpoints Change \u2018marker\u2019 character to indicate . in namespace/table identifiers from ASCII 0 to \\u001D Opt-in to force-merge or not merge specific content keys (also for transplant) Squash merged and transplanted commits by default (with opt-out) 0.25.0 Release (April 6, 2022) \u00b6 Nessie Quarkus Server can use Postgres as its backend database Explicitly define behavior of multiple commit-operations in a commit Load correct view metadata for a given ref 0.24.0 Release (March 31, 2022) \u00b6 Prevent explicit creation of empty namespaces Add content-id to BatchAccessChecker.canReadContentKey() 0.23.1 Release (March 23, 2022) \u00b6 Support Namespaces CI \u201cperf tests\u201d improvements SQL Extension: Fix Create reference from a hash on non-default reference Enhance authorization checks Support custom annotations on Nessie Helm service 0.23.0 Release (March 23, 2022) \u00b6 (not properly released) 0.22.0 Release (March 11, 2022) \u00b6 Improve performance of getValues Global-log compaction Store-level maintenance CLI Reduce number of tags for micrometer Grafana Dashboard for Nessie service Add new commands to generate-content tool 0.21.2 Release (March 2, 2022) \u00b6 Fix serialization issue 0.21.1 Release (March 2, 2022) \u00b6 (no user visible changes) 0.21.0 Release (March 1, 2022) \u00b6 Add tracing to database-adapter internals Introduce compatibility and upgrade tests Refactor StreamingUtil class Support for Spark 3.1 + 3.2.1 in Nessie SQL extensions Proper usage of commit-id in Spark SQL extensions Add DELETE_DEFAULT_BRANCH access check 0.20.1 Release (February 17, 2022) \u00b6 (no user visible changes) 0.20.0 Release (February 16, 2022) \u00b6 Enable metrics for MongoDB by default Make try-loop-state configurable and add metrics Reorganize routes in UI Improve error reporting in Nessie Java client Various test improvements 0.19.0 Release (February 7, 2022) \u00b6 Reads using \u201cdetached\u201d commit-ids w/o specifying a branch or tag name Bump Nessie client version in Nessie Spark-Extensions Support for Iceberg views (experimental) Diff endpoint supports named-references + commit-on-reference as well Add filtering for ref-log Rework and simplification of the Nessie UI code 0.18.0 Release (January 13, 2022) \u00b6 Add reflog support Uses commit-timestamp \u201cnow\u201d for merged/transplanted commits Add new reflog command to the CLI Add support for Python 3.10 Drop support for Python 3.6 0.17.0 Release (December 08, 2021) \u00b6 Rename \u2018query_expression\u2019 query param to \u2018filter\u2019 Rename \u2018max\u2019 query param to \u2018maxRecords\u2019 Rename \u2018fetchAdditionalInfo\u2019 query param to \u2018fetch\u2019 for better extensibility 0.16.0 Release (December 03, 2021) \u00b6 Mark optional fields as @Nullable / add validation for required fields in param classes Add CEL-filter to get-all-references Fix NPE for unchanged operation for fetching commit log with additional metadata Allow CEL-filtering on optional operations in get-commit-log 0.15.1 Release (December 01, 2021) \u00b6 Fix wrongly placed validation annotation 0.15.0 Release (December 01, 2021) \u00b6 Enhance commit log to optionally return original commit operations Optionally return commits ahead/behind, HEAD commit-meta, commit count, common ancestor for named references Add missing REST endpoint to retrieve diff between two references Web UI improvements 0.14.0 Release (November 12, 2021) \u00b6 Updated IcebergTable to track more information UI dependencies cleanup OpenAPI/REST API cleanup (breaking change) 0.12.1 Release (November 3, 2021) \u00b6 Test code improvements Swagger examples fixes Web UI improvements Faster local builds w/ ./mvnw -Dquickly 0.12.0 Release (October 25, 2021) \u00b6 Specialize and document Nessie exceptions Adopt Helm chart with new Nessie server settings Bump to GraalVM 21.3 0.11.0 Release (October 20, 2021) \u00b6 Various doc + site improvements Fix Nessie\u2019s representation of global and on-reference state (Iceberg tables) Fix CLI log -n option Spark SQL extension improvements 0.10.1 Release (October 8, 2021) \u00b6 Spark SQL extension changes Various (Open)API and client (Java, Python) implementation changes to prepare for better backwards compatibility. JUnit extension based test support against different database/store types and configurations Unified version-store implementations into a part w/ the Nessie logic and a tier implementing database access (MongoDB, DynamoDB, RocksDB, PostgreSQL). Remove JGit 0.9.2 Release (August 26, 2021) \u00b6 Cleanup & fixes to OpenAPI examples, for Swagger UI Update Deltalake client to use version 1.0.0 Drop Deltalake support for Spark 2 Remove Hive-Metastore bridge Preparations for backwards-compatible Client-API Spark SQL Extensions: Introduce IF NOT EXISTS for CREATE BRANCH / CREATE TAG Spark SQL Extensions: Updates to work with Iceberg 0.12.0 0.9.0 Release (August 9, 2021) \u00b6 Support for the upcoming Iceberg 0.12.0 release for both Spark 3.0 + 3.1 Add docs for Nessie\u2019s metadata authorization Add SPI for Nessie authorization with Reference implementation Create Helm chart for Nessie 0.8.3 Release (July 19, 2021) \u00b6 Fix issue in spark sql extensions Python CLI: Fix ser/de of DeltaLakeTable when listing contents 0.8.2 Release (July 15, 2021) \u00b6 Add JAX-RS server implementation based on Glassfish/Jersey/Weld for integration testing in Iceberg REST-API change: only accept named-references REST-API change: support time-travel on named-references REST-API change: Server-side commit range filtering OpenAPI: more explicit constraints on parameters OpenAPI: include OpenAPI yaml+json files in nessie-model artifact Remove already deprecated methods from ContentsApi Commit-log filtering on all fields of CommitMeta Use \u201cCommon Expression Language\u201d for commit-log and entries filtering Spark-extensions for Iceberg Prepare for multi-tenancy Gatling support + simulations Python CLI: Fix ser/de of DeltaLakeTable when listing contents 0.7.0 Release (June 15, 2021) \u00b6 Server-side filtering improvements for entries-listing and log-listing Distinguish between author & committer in the Python CLI Allow setting author when committing via Python CLI Loosen pins for client install on Python cli Fix edge case when merging using in memory + jgit stores Gradle plugin improvements (Development) change to Google Code Style, add spotless plugin (CI) Add OWASP Dependency Check 0.6.1 Release (May 25, 2021) \u00b6 Gradle plugin improvements 0.6.0 Release (May 12, 2021) \u00b6 TreeApi.createReference() + commitMultipleOperations() return commit information Iceberg GC actions and a process to execute GC algorithm 0.5.1 Release (April 9, 2021) \u00b6 Fix Gradle plugin (non-deterministic order of dependencies causing failures) Fix Web-UI 0.5.0 Release (April 8, 2021) \u00b6 Iceberg table GC support Consistency fixes under high load Breaking changes to the backend to support richer commit metadata and data types Performance, metrics and tracing improvements Gradle plugin improvement for incremental builds 0.4.0 Release (March 8, 2020) \u00b6 rename base package to org.projectnessie NessieClient is now an interface and some easier builders initial implementation of GC algorithm major refactor of tiered classes for better modularity and extensibility observability improvements including better DynamoDB metrics and opentracing support for the client 0.3.0 Release (December 30, 2020) \u00b6 118 commits since 0.2.1 Replace jax-rs client with one based on HttpURLConnection Update Quarkus to 1.10.5 Improvements to Server including better UI routing, validation checks on inputs etc Various improvements to python client and cli. Including python3.9 support 0.2.1 Release (October 30, 2020) \u00b6 Fix missing dateutil requirement for pynessie install Address path discovery in Gradle plugin (for testing in external integrations) 0.2.0 Release (October 29, 2020) \u00b6 Update Nessie CLI commands to better match git syntax Update REST Apis to be more consistent and better Add support for merge & cherry-pick in DynamoDB storage backend Add WebUI Introduce new DynamoDB optimizations to support faster log and entry retrieval Update to Quarkus 1.9.1 Expose the new Store interface for low level storage implementations Introduce Quarkus Gradle runner plugin for easier third-party testing (e.g. Iceberg) Enable swagger-ui by default in Nessie service 0.1.0 Release (October 1, 2020) \u00b6 Initial release","title":"Releases"},{"location":"try/releases/#releases","text":"See Nessie Server upgrade notes for supported upgrade paths.","title":"Releases"},{"location":"try/releases/#0300-release-may-13-2022","text":"Add commit-ID to KeyListEntry when writing new key-lists Do not process old key-lists when retrieving values Helm: Fix k8s version detection in ingress template Database-adapter: commit optimizations Remove the configurable default for the configurable values for getDefaultMaxKeyListSize Dynamo/Mongo/TX: use bulk/batch requests where possible","title":"0.30.0 Release (May 13, 2022)"},{"location":"try/releases/#0290-release-may-5-2022","text":"Spark SQL: Configure ref.hash for NessieCatalog only when explicitly requested Escape all column names in SQL DML+DDL statements Use hashOnRef when fetching Namespaces Helm: Add ingress support for Kubernetes >=1.22 Fix CockroachDB transaction-retry behavior","title":"0.29.0 Release (May 5, 2022)"},{"location":"try/releases/#0280-release-april-26-2022","text":"Generate unique content IDs for explicitly created namespaces Fix patterns for metrics Various test improvements (CI + build) Various minor code fixes (fixes for errorprone warnings)","title":"0.28.0 Release (April 26, 2022)"},{"location":"try/releases/#0270-release-april-14-2022","text":"Support for Namespace properties Make NessieContentGenerator extensible","title":"0.27.0 Release (April 14, 2022)"},{"location":"try/releases/#0260-release-april-12-2022","text":"Rolling upgrades from an older Nessie release to 0.26.0 or newer are not supported. Remove global state for Iceberg tables + views Internal optimizations in database adapters, version store and API endpoints Change \u2018marker\u2019 character to indicate . in namespace/table identifiers from ASCII 0 to \\u001D Opt-in to force-merge or not merge specific content keys (also for transplant) Squash merged and transplanted commits by default (with opt-out)","title":"0.26.0 Release (April 12, 2022)"},{"location":"try/releases/#0250-release-april-6-2022","text":"Nessie Quarkus Server can use Postgres as its backend database Explicitly define behavior of multiple commit-operations in a commit Load correct view metadata for a given ref","title":"0.25.0 Release (April 6, 2022)"},{"location":"try/releases/#0240-release-march-31-2022","text":"Prevent explicit creation of empty namespaces Add content-id to BatchAccessChecker.canReadContentKey()","title":"0.24.0 Release (March 31, 2022)"},{"location":"try/releases/#0231-release-march-23-2022","text":"Support Namespaces CI \u201cperf tests\u201d improvements SQL Extension: Fix Create reference from a hash on non-default reference Enhance authorization checks Support custom annotations on Nessie Helm service","title":"0.23.1 Release (March 23, 2022)"},{"location":"try/releases/#0230-release-march-23-2022","text":"(not properly released)","title":"0.23.0 Release (March 23, 2022)"},{"location":"try/releases/#0220-release-march-11-2022","text":"Improve performance of getValues Global-log compaction Store-level maintenance CLI Reduce number of tags for micrometer Grafana Dashboard for Nessie service Add new commands to generate-content tool","title":"0.22.0 Release (March 11, 2022)"},{"location":"try/releases/#0212-release-march-2-2022","text":"Fix serialization issue","title":"0.21.2 Release (March 2, 2022)"},{"location":"try/releases/#0211-release-march-2-2022","text":"(no user visible changes)","title":"0.21.1 Release (March 2, 2022)"},{"location":"try/releases/#0210-release-march-1-2022","text":"Add tracing to database-adapter internals Introduce compatibility and upgrade tests Refactor StreamingUtil class Support for Spark 3.1 + 3.2.1 in Nessie SQL extensions Proper usage of commit-id in Spark SQL extensions Add DELETE_DEFAULT_BRANCH access check","title":"0.21.0 Release (March 1, 2022)"},{"location":"try/releases/#0201-release-february-17-2022","text":"(no user visible changes)","title":"0.20.1 Release (February 17, 2022)"},{"location":"try/releases/#0200-release-february-16-2022","text":"Enable metrics for MongoDB by default Make try-loop-state configurable and add metrics Reorganize routes in UI Improve error reporting in Nessie Java client Various test improvements","title":"0.20.0 Release (February 16, 2022)"},{"location":"try/releases/#0190-release-february-7-2022","text":"Reads using \u201cdetached\u201d commit-ids w/o specifying a branch or tag name Bump Nessie client version in Nessie Spark-Extensions Support for Iceberg views (experimental) Diff endpoint supports named-references + commit-on-reference as well Add filtering for ref-log Rework and simplification of the Nessie UI code","title":"0.19.0 Release (February 7, 2022)"},{"location":"try/releases/#0180-release-january-13-2022","text":"Add reflog support Uses commit-timestamp \u201cnow\u201d for merged/transplanted commits Add new reflog command to the CLI Add support for Python 3.10 Drop support for Python 3.6","title":"0.18.0 Release (January 13, 2022)"},{"location":"try/releases/#0170-release-december-08-2021","text":"Rename \u2018query_expression\u2019 query param to \u2018filter\u2019 Rename \u2018max\u2019 query param to \u2018maxRecords\u2019 Rename \u2018fetchAdditionalInfo\u2019 query param to \u2018fetch\u2019 for better extensibility","title":"0.17.0 Release (December 08, 2021)"},{"location":"try/releases/#0160-release-december-03-2021","text":"Mark optional fields as @Nullable / add validation for required fields in param classes Add CEL-filter to get-all-references Fix NPE for unchanged operation for fetching commit log with additional metadata Allow CEL-filtering on optional operations in get-commit-log","title":"0.16.0 Release (December 03, 2021)"},{"location":"try/releases/#0151-release-december-01-2021","text":"Fix wrongly placed validation annotation","title":"0.15.1 Release (December 01, 2021)"},{"location":"try/releases/#0150-release-december-01-2021","text":"Enhance commit log to optionally return original commit operations Optionally return commits ahead/behind, HEAD commit-meta, commit count, common ancestor for named references Add missing REST endpoint to retrieve diff between two references Web UI improvements","title":"0.15.0 Release (December 01, 2021)"},{"location":"try/releases/#0140-release-november-12-2021","text":"Updated IcebergTable to track more information UI dependencies cleanup OpenAPI/REST API cleanup (breaking change)","title":"0.14.0 Release (November 12, 2021)"},{"location":"try/releases/#0121-release-november-3-2021","text":"Test code improvements Swagger examples fixes Web UI improvements Faster local builds w/ ./mvnw -Dquickly","title":"0.12.1 Release (November 3, 2021)"},{"location":"try/releases/#0120-release-october-25-2021","text":"Specialize and document Nessie exceptions Adopt Helm chart with new Nessie server settings Bump to GraalVM 21.3","title":"0.12.0 Release (October 25, 2021)"},{"location":"try/releases/#0110-release-october-20-2021","text":"Various doc + site improvements Fix Nessie\u2019s representation of global and on-reference state (Iceberg tables) Fix CLI log -n option Spark SQL extension improvements","title":"0.11.0 Release (October 20, 2021)"},{"location":"try/releases/#0101-release-october-8-2021","text":"Spark SQL extension changes Various (Open)API and client (Java, Python) implementation changes to prepare for better backwards compatibility. JUnit extension based test support against different database/store types and configurations Unified version-store implementations into a part w/ the Nessie logic and a tier implementing database access (MongoDB, DynamoDB, RocksDB, PostgreSQL). Remove JGit","title":"0.10.1 Release (October 8, 2021)"},{"location":"try/releases/#092-release-august-26-2021","text":"Cleanup & fixes to OpenAPI examples, for Swagger UI Update Deltalake client to use version 1.0.0 Drop Deltalake support for Spark 2 Remove Hive-Metastore bridge Preparations for backwards-compatible Client-API Spark SQL Extensions: Introduce IF NOT EXISTS for CREATE BRANCH / CREATE TAG Spark SQL Extensions: Updates to work with Iceberg 0.12.0","title":"0.9.2 Release (August 26, 2021)"},{"location":"try/releases/#090-release-august-9-2021","text":"Support for the upcoming Iceberg 0.12.0 release for both Spark 3.0 + 3.1 Add docs for Nessie\u2019s metadata authorization Add SPI for Nessie authorization with Reference implementation Create Helm chart for Nessie","title":"0.9.0 Release (August 9, 2021)"},{"location":"try/releases/#083-release-july-19-2021","text":"Fix issue in spark sql extensions Python CLI: Fix ser/de of DeltaLakeTable when listing contents","title":"0.8.3 Release (July 19, 2021)"},{"location":"try/releases/#082-release-july-15-2021","text":"Add JAX-RS server implementation based on Glassfish/Jersey/Weld for integration testing in Iceberg REST-API change: only accept named-references REST-API change: support time-travel on named-references REST-API change: Server-side commit range filtering OpenAPI: more explicit constraints on parameters OpenAPI: include OpenAPI yaml+json files in nessie-model artifact Remove already deprecated methods from ContentsApi Commit-log filtering on all fields of CommitMeta Use \u201cCommon Expression Language\u201d for commit-log and entries filtering Spark-extensions for Iceberg Prepare for multi-tenancy Gatling support + simulations Python CLI: Fix ser/de of DeltaLakeTable when listing contents","title":"0.8.2 Release (July 15, 2021)"},{"location":"try/releases/#070-release-june-15-2021","text":"Server-side filtering improvements for entries-listing and log-listing Distinguish between author & committer in the Python CLI Allow setting author when committing via Python CLI Loosen pins for client install on Python cli Fix edge case when merging using in memory + jgit stores Gradle plugin improvements (Development) change to Google Code Style, add spotless plugin (CI) Add OWASP Dependency Check","title":"0.7.0 Release (June 15, 2021)"},{"location":"try/releases/#061-release-may-25-2021","text":"Gradle plugin improvements","title":"0.6.1 Release (May 25, 2021)"},{"location":"try/releases/#060-release-may-12-2021","text":"TreeApi.createReference() + commitMultipleOperations() return commit information Iceberg GC actions and a process to execute GC algorithm","title":"0.6.0 Release (May 12, 2021)"},{"location":"try/releases/#051-release-april-9-2021","text":"Fix Gradle plugin (non-deterministic order of dependencies causing failures) Fix Web-UI","title":"0.5.1 Release (April 9, 2021)"},{"location":"try/releases/#050-release-april-8-2021","text":"Iceberg table GC support Consistency fixes under high load Breaking changes to the backend to support richer commit metadata and data types Performance, metrics and tracing improvements Gradle plugin improvement for incremental builds","title":"0.5.0 Release (April 8, 2021)"},{"location":"try/releases/#040-release-march-8-2020","text":"rename base package to org.projectnessie NessieClient is now an interface and some easier builders initial implementation of GC algorithm major refactor of tiered classes for better modularity and extensibility observability improvements including better DynamoDB metrics and opentracing support for the client","title":"0.4.0 Release (March 8, 2020)"},{"location":"try/releases/#030-release-december-30-2020","text":"118 commits since 0.2.1 Replace jax-rs client with one based on HttpURLConnection Update Quarkus to 1.10.5 Improvements to Server including better UI routing, validation checks on inputs etc Various improvements to python client and cli. Including python3.9 support","title":"0.3.0 Release (December 30, 2020)"},{"location":"try/releases/#021-release-october-30-2020","text":"Fix missing dateutil requirement for pynessie install Address path discovery in Gradle plugin (for testing in external integrations)","title":"0.2.1 Release (October 30, 2020)"},{"location":"try/releases/#020-release-october-29-2020","text":"Update Nessie CLI commands to better match git syntax Update REST Apis to be more consistent and better Add support for merge & cherry-pick in DynamoDB storage backend Add WebUI Introduce new DynamoDB optimizations to support faster log and entry retrieval Update to Quarkus 1.9.1 Expose the new Store interface for low level storage implementations Introduce Quarkus Gradle runner plugin for easier third-party testing (e.g. Iceberg) Enable swagger-ui by default in Nessie service","title":"0.2.0 Release (October 29, 2020)"},{"location":"try/releases/#010-release-october-1-2020","text":"Initial release","title":"0.1.0 Release (October 1, 2020)"},{"location":"try/server-upgrade/","text":"Nessie Server upgrade notes \u00b6 The following table lists the upgrade types from one Nessie version to another Nessie version. A check-mark in the Rolling Upgrade column means that it is okay to run Nessie instances running versions in the From column during the limited time of a rolling-upgrade with Nessie versions in the To column. A red cross in the Rolling Upgrade column means that rolling upgrades for the mentioned versions are not supported and must be avoided. Rolling Upgrade From Nessie version To Nessie version 0.26.0 to 0.29.0 0.27.0 to 0.30.0 0.25.0 or older 0.26.0 or newer 0.18.0 to 0.24.0 0.19.0 to 0.25.0 Older releases than 0.18.0 are not supported. See Releases for release notes.","title":"Nessie Server upgrade notes"},{"location":"try/server-upgrade/#nessie-server-upgrade-notes","text":"The following table lists the upgrade types from one Nessie version to another Nessie version. A check-mark in the Rolling Upgrade column means that it is okay to run Nessie instances running versions in the From column during the limited time of a rolling-upgrade with Nessie versions in the To column. A red cross in the Rolling Upgrade column means that rolling upgrades for the mentioned versions are not supported and must be avoided. Rolling Upgrade From Nessie version To Nessie version 0.26.0 to 0.29.0 0.27.0 to 0.30.0 0.25.0 or older 0.26.0 or newer 0.18.0 to 0.24.0 0.19.0 to 0.25.0 Older releases than 0.18.0 are not supported. See Releases for release notes.","title":"Nessie Server upgrade notes"}]}